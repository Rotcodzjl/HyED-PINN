{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T15:34:40.573228Z",
     "start_time": "2025-04-12T15:34:37.203941Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import matplotlib.cm as cm\n",
    "import pandas as pd\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from d2l import torch as d2l\n",
    "d2l.use_svg_display()\n",
    "from torch.utils.data import Dataset,TensorDataset,DataLoader,random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88699ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def add_column_with_variable_length(df, new_column, column_name, fill_value=None):\n",
    "    \"\"\"\n",
    "    向DataFrame添加长度可能不同的新列，保持总行数只增不减\n",
    "    \n",
    "    参数:\n",
    "        df (pd.DataFrame): 原始DataFrame\n",
    "        new_column (list/array): 要添加的新列数据\n",
    "        column_name (str): 新列的名称\n",
    "        fill_value: 用于填充不足部分的默认值（默认为None）\n",
    "    \n",
    "    返回:\n",
    "        pd.DataFrame: 包含新列的DataFrame\n",
    "    \"\"\"\n",
    "    # 确保输入是DataFrame\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(\"输入df必须是pandas DataFrame\")\n",
    "    \n",
    "    # 将新列转换为可迭代形式\n",
    "    new_data = list(new_column)\n",
    "    \n",
    "    # 计算新旧长度\n",
    "    original_length = len(df)\n",
    "    new_data_length = len(new_data)\n",
    "    \n",
    "    # 情况1：新数据比原DataFrame长 - 扩展DataFrame\n",
    "    if new_data_length > original_length:\n",
    "        # 创建扩展部分（保持原有列的结构）\n",
    "        extension = pd.DataFrame(index=range(original_length, new_data_length))\n",
    "        # 合并扩展部分\n",
    "        extended_df = pd.concat([df, extension], axis=0)\n",
    "        # 添加新列\n",
    "        extended_df[column_name] = new_data\n",
    "        return extended_df\n",
    "    \n",
    "    # 情况2：新数据比原DataFrame短或等长 - 直接添加列\n",
    "    else:\n",
    "        # 复制DataFrame避免修改原对象\n",
    "        result_df = df.copy()\n",
    "        # 添加新列并用fill_value填充不足部分\n",
    "        result_df[column_name] = new_data + [fill_value] * (original_length - new_data_length)\n",
    "        return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a26a17f8d80b5e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T15:44:09.549953Z",
     "start_time": "2025-04-12T15:44:09.466265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.204342563758486\n",
      "2.225305901976459\n",
      "2.2043066049683677\n",
      "2.2124153249919782\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"351.581478pt\" height=\"281.513281pt\" viewBox=\"0 0 351.581478 281.513281\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2025-05-13T09:06:01.170155</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 281.513281 \n",
       "L 351.581478 281.513281 \n",
       "L 351.581478 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 64.856875 234.278906 \n",
       "L 343.856875 234.278906 \n",
       "L 343.856875 12.518906 \n",
       "L 64.856875 12.518906 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"m5207825fac\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m5207825fac\" x=\"77.538693\" y=\"234.278906\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(73.084943 251.916719) scale(0.14 -0.14)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m5207825fac\" x=\"142.022514\" y=\"234.278906\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 15 -->\n",
       "      <g transform=\"translate(133.115014 251.916719) scale(0.14 -0.14)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m5207825fac\" x=\"206.506336\" y=\"234.278906\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 30 -->\n",
       "      <g transform=\"translate(197.598836 251.916719) scale(0.14 -0.14)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \n",
       "Q 3050 2419 3304 2112 \n",
       "Q 3559 1806 3559 1356 \n",
       "Q 3559 666 3084 287 \n",
       "Q 2609 -91 1734 -91 \n",
       "Q 1441 -91 1130 -33 \n",
       "Q 819 25 488 141 \n",
       "L 488 750 \n",
       "Q 750 597 1062 519 \n",
       "Q 1375 441 1716 441 \n",
       "Q 2309 441 2620 675 \n",
       "Q 2931 909 2931 1356 \n",
       "Q 2931 1769 2642 2001 \n",
       "Q 2353 2234 1838 2234 \n",
       "L 1294 2234 \n",
       "L 1294 2753 \n",
       "L 1863 2753 \n",
       "Q 2328 2753 2575 2939 \n",
       "Q 2822 3125 2822 3475 \n",
       "Q 2822 3834 2567 4026 \n",
       "Q 2313 4219 1838 4219 \n",
       "Q 1578 4219 1281 4162 \n",
       "Q 984 4106 628 3988 \n",
       "L 628 4550 \n",
       "Q 988 4650 1302 4700 \n",
       "Q 1616 4750 1894 4750 \n",
       "Q 2613 4750 3031 4423 \n",
       "Q 3450 4097 3450 3541 \n",
       "Q 3450 3153 3228 2886 \n",
       "Q 3006 2619 2597 2516 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m5207825fac\" x=\"270.990157\" y=\"234.278906\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 45 -->\n",
       "      <g transform=\"translate(262.082657 251.916719) scale(0.14 -0.14)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m5207825fac\" x=\"335.473978\" y=\"234.278906\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 60 -->\n",
       "      <g transform=\"translate(326.566478 251.916719) scale(0.14 -0.14)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
       "Q 1688 2584 1439 2293 \n",
       "Q 1191 2003 1191 1497 \n",
       "Q 1191 994 1439 701 \n",
       "Q 1688 409 2113 409 \n",
       "Q 2538 409 2786 701 \n",
       "Q 3034 994 3034 1497 \n",
       "Q 3034 2003 2786 2293 \n",
       "Q 2538 2584 2113 2584 \n",
       "z\n",
       "M 3366 4563 \n",
       "L 3366 3988 \n",
       "Q 3128 4100 2886 4159 \n",
       "Q 2644 4219 2406 4219 \n",
       "Q 1781 4219 1451 3797 \n",
       "Q 1122 3375 1075 2522 \n",
       "Q 1259 2794 1537 2939 \n",
       "Q 1816 3084 2150 3084 \n",
       "Q 2853 3084 3261 2657 \n",
       "Q 3669 2231 3669 1497 \n",
       "Q 3669 778 3244 343 \n",
       "Q 2819 -91 2113 -91 \n",
       "Q 1303 -91 875 529 \n",
       "Q 447 1150 447 2328 \n",
       "Q 447 3434 972 4092 \n",
       "Q 1497 4750 2381 4750 \n",
       "Q 2619 4750 2861 4703 \n",
       "Q 3103 4656 3366 4563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-36\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_6\">\n",
       "     <!-- Cycle -->\n",
       "     <g transform=\"translate(182.491875 270.985781) scale(0.16 -0.16)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-43\" d=\"M 4122 4306 \n",
       "L 4122 3641 \n",
       "Q 3803 3938 3442 4084 \n",
       "Q 3081 4231 2675 4231 \n",
       "Q 1875 4231 1450 3742 \n",
       "Q 1025 3253 1025 2328 \n",
       "Q 1025 1406 1450 917 \n",
       "Q 1875 428 2675 428 \n",
       "Q 3081 428 3442 575 \n",
       "Q 3803 722 4122 1019 \n",
       "L 4122 359 \n",
       "Q 3791 134 3420 21 \n",
       "Q 3050 -91 2638 -91 \n",
       "Q 1578 -91 968 557 \n",
       "Q 359 1206 359 2328 \n",
       "Q 359 3453 968 4101 \n",
       "Q 1578 4750 2638 4750 \n",
       "Q 3056 4750 3426 4639 \n",
       "Q 3797 4528 4122 4306 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-79\" d=\"M 2059 -325 \n",
       "Q 1816 -950 1584 -1140 \n",
       "Q 1353 -1331 966 -1331 \n",
       "L 506 -1331 \n",
       "L 506 -850 \n",
       "L 844 -850 \n",
       "Q 1081 -850 1212 -737 \n",
       "Q 1344 -625 1503 -206 \n",
       "L 1606 56 \n",
       "L 191 3500 \n",
       "L 800 3500 \n",
       "L 1894 763 \n",
       "L 2988 3500 \n",
       "L 3597 3500 \n",
       "L 2059 -325 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
       "L 3122 2828 \n",
       "Q 2878 2963 2633 3030 \n",
       "Q 2388 3097 2138 3097 \n",
       "Q 1578 3097 1268 2742 \n",
       "Q 959 2388 959 1747 \n",
       "Q 959 1106 1268 751 \n",
       "Q 1578 397 2138 397 \n",
       "Q 2388 397 2633 464 \n",
       "Q 2878 531 3122 666 \n",
       "L 3122 134 \n",
       "Q 2881 22 2623 -34 \n",
       "Q 2366 -91 2075 -91 \n",
       "Q 1284 -91 818 406 \n",
       "Q 353 903 353 1747 \n",
       "Q 353 2603 823 3093 \n",
       "Q 1294 3584 2113 3584 \n",
       "Q 2378 3584 2631 3529 \n",
       "Q 2884 3475 3122 3366 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-43\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-79\" x=\"69.824219\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"129.003906\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" x=\"183.984375\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"211.767578\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <defs>\n",
       "       <path id=\"mc2330d1a2d\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc2330d1a2d\" x=\"64.856875\" y=\"191.503614\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 0.80 -->\n",
       "      <g transform=\"translate(26.685 196.82252) scale(0.14 -0.14)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
       "L 1344 794 \n",
       "L 1344 0 \n",
       "L 684 0 \n",
       "L 684 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \n",
       "Q 1584 2216 1326 1975 \n",
       "Q 1069 1734 1069 1313 \n",
       "Q 1069 891 1326 650 \n",
       "Q 1584 409 2034 409 \n",
       "Q 2484 409 2743 651 \n",
       "Q 3003 894 3003 1313 \n",
       "Q 3003 1734 2745 1975 \n",
       "Q 2488 2216 2034 2216 \n",
       "z\n",
       "M 1403 2484 \n",
       "Q 997 2584 770 2862 \n",
       "Q 544 3141 544 3541 \n",
       "Q 544 4100 942 4425 \n",
       "Q 1341 4750 2034 4750 \n",
       "Q 2731 4750 3128 4425 \n",
       "Q 3525 4100 3525 3541 \n",
       "Q 3525 3141 3298 2862 \n",
       "Q 3072 2584 2669 2484 \n",
       "Q 3125 2378 3379 2068 \n",
       "Q 3634 1759 3634 1313 \n",
       "Q 3634 634 3220 271 \n",
       "Q 2806 -91 2034 -91 \n",
       "Q 1263 -91 848 271 \n",
       "Q 434 634 434 1313 \n",
       "Q 434 1759 690 2068 \n",
       "Q 947 2378 1403 2484 \n",
       "z\n",
       "M 1172 3481 \n",
       "Q 1172 3119 1398 2916 \n",
       "Q 1625 2713 2034 2713 \n",
       "Q 2441 2713 2670 2916 \n",
       "Q 2900 3119 2900 3481 \n",
       "Q 2900 3844 2670 4047 \n",
       "Q 2441 4250 2034 4250 \n",
       "Q 1625 4250 1398 4047 \n",
       "Q 1172 3844 1172 3481 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc2330d1a2d\" x=\"64.856875\" y=\"146.757437\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.85 -->\n",
       "      <g transform=\"translate(26.685 152.076343) scale(0.14 -0.14)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc2330d1a2d\" x=\"64.856875\" y=\"102.01126\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.90 -->\n",
       "      <g transform=\"translate(26.685 107.330166) scale(0.14 -0.14)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-39\" d=\"M 703 97 \n",
       "L 703 672 \n",
       "Q 941 559 1184 500 \n",
       "Q 1428 441 1663 441 \n",
       "Q 2288 441 2617 861 \n",
       "Q 2947 1281 2994 2138 \n",
       "Q 2813 1869 2534 1725 \n",
       "Q 2256 1581 1919 1581 \n",
       "Q 1219 1581 811 2004 \n",
       "Q 403 2428 403 3163 \n",
       "Q 403 3881 828 4315 \n",
       "Q 1253 4750 1959 4750 \n",
       "Q 2769 4750 3195 4129 \n",
       "Q 3622 3509 3622 2328 \n",
       "Q 3622 1225 3098 567 \n",
       "Q 2575 -91 1691 -91 \n",
       "Q 1453 -91 1209 -44 \n",
       "Q 966 3 703 97 \n",
       "z\n",
       "M 1959 2075 \n",
       "Q 2384 2075 2632 2365 \n",
       "Q 2881 2656 2881 3163 \n",
       "Q 2881 3666 2632 3958 \n",
       "Q 2384 4250 1959 4250 \n",
       "Q 1534 4250 1286 3958 \n",
       "Q 1038 3666 1038 3163 \n",
       "Q 1038 2656 1286 2365 \n",
       "Q 1534 2075 1959 2075 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-39\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc2330d1a2d\" x=\"64.856875\" y=\"57.265083\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.95 -->\n",
       "      <g transform=\"translate(26.685 62.583989) scale(0.14 -0.14)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-39\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc2330d1a2d\" x=\"64.856875\" y=\"12.518906\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 1.00 -->\n",
       "      <g transform=\"translate(26.685 17.837812) scale(0.14 -0.14)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_12\">\n",
       "     <!-- SOH -->\n",
       "     <g transform=\"translate(19.3575 140.791406) rotate(-90) scale(0.16 -0.16)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-53\" d=\"M 3425 4513 \n",
       "L 3425 3897 \n",
       "Q 3066 4069 2747 4153 \n",
       "Q 2428 4238 2131 4238 \n",
       "Q 1616 4238 1336 4038 \n",
       "Q 1056 3838 1056 3469 \n",
       "Q 1056 3159 1242 3001 \n",
       "Q 1428 2844 1947 2747 \n",
       "L 2328 2669 \n",
       "Q 3034 2534 3370 2195 \n",
       "Q 3706 1856 3706 1288 \n",
       "Q 3706 609 3251 259 \n",
       "Q 2797 -91 1919 -91 \n",
       "Q 1588 -91 1214 -16 \n",
       "Q 841 59 441 206 \n",
       "L 441 856 \n",
       "Q 825 641 1194 531 \n",
       "Q 1563 422 1919 422 \n",
       "Q 2459 422 2753 634 \n",
       "Q 3047 847 3047 1241 \n",
       "Q 3047 1584 2836 1778 \n",
       "Q 2625 1972 2144 2069 \n",
       "L 1759 2144 \n",
       "Q 1053 2284 737 2584 \n",
       "Q 422 2884 422 3419 \n",
       "Q 422 4038 858 4394 \n",
       "Q 1294 4750 2059 4750 \n",
       "Q 2388 4750 2728 4690 \n",
       "Q 3069 4631 3425 4513 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-4f\" d=\"M 2522 4238 \n",
       "Q 1834 4238 1429 3725 \n",
       "Q 1025 3213 1025 2328 \n",
       "Q 1025 1447 1429 934 \n",
       "Q 1834 422 2522 422 \n",
       "Q 3209 422 3611 934 \n",
       "Q 4013 1447 4013 2328 \n",
       "Q 4013 3213 3611 3725 \n",
       "Q 3209 4238 2522 4238 \n",
       "z\n",
       "M 2522 4750 \n",
       "Q 3503 4750 4090 4092 \n",
       "Q 4678 3434 4678 2328 \n",
       "Q 4678 1225 4090 567 \n",
       "Q 3503 -91 2522 -91 \n",
       "Q 1538 -91 948 565 \n",
       "Q 359 1222 359 2328 \n",
       "Q 359 3434 948 4092 \n",
       "Q 1538 4750 2522 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-48\" d=\"M 628 4666 \n",
       "L 1259 4666 \n",
       "L 1259 2753 \n",
       "L 3553 2753 \n",
       "L 3553 4666 \n",
       "L 4184 4666 \n",
       "L 4184 0 \n",
       "L 3553 0 \n",
       "L 3553 2222 \n",
       "L 1259 2222 \n",
       "L 1259 0 \n",
       "L 628 0 \n",
       "L 628 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-53\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-4f\" x=\"63.476562\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-48\" x=\"142.1875\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_11\">\n",
       "    <path d=\"M 77.538693 30.150585 \n",
       "L 81.837615 33.629573 \n",
       "L 86.136536 39.568033 \n",
       "L 90.435457 43.758005 \n",
       "L 94.734379 47.909225 \n",
       "L 99.0333 52.595476 \n",
       "L 103.332222 57.617066 \n",
       "L 107.631143 61.795854 \n",
       "L 111.930065 65.735924 \n",
       "L 116.228986 69.705673 \n",
       "L 120.527907 73.562156 \n",
       "L 124.826829 77.482487 \n",
       "L 129.12575 81.048115 \n",
       "L 133.424672 88.090816 \n",
       "L 137.723593 96.136665 \n",
       "L 142.022514 100.075436 \n",
       "L 146.321436 103.980085 \n",
       "L 150.620357 107.694177 \n",
       "L 154.919279 111.470478 \n",
       "L 159.2182 115.49952 \n",
       "L 163.517122 118.781682 \n",
       "L 167.816043 122.192761 \n",
       "L 172.114964 125.888403 \n",
       "L 176.413886 128.893519 \n",
       "L 180.712807 132.12315 \n",
       "L 185.011729 136.120496 \n",
       "L 189.31065 138.172857 \n",
       "L 193.609571 141.226797 \n",
       "L 197.908493 144.53234 \n",
       "L 202.207414 146.949116 \n",
       "L 206.506336 151.901384 \n",
       "L 210.805257 153.90477 \n",
       "L 215.104179 159.490544 \n",
       "L 219.4031 160.806672 \n",
       "L 223.702021 162.367008 \n",
       "L 228.000943 164.79529 \n",
       "L 232.299864 168.044126 \n",
       "L 236.598786 169.989479 \n",
       "L 240.897707 173.224493 \n",
       "L 245.196628 175.892319 \n",
       "L 249.49555 179.068078 \n",
       "L 253.794471 180.644474 \n",
       "L 258.093393 185.367404 \n",
       "L 262.392314 191.132704 \n",
       "L 266.691236 193.511835 \n",
       "L 270.990157 196.177709 \n",
       "L 275.289078 197.126861 \n",
       "L 279.588 199.519972 \n",
       "L 283.886921 204.276721 \n",
       "L 288.185843 204.683459 \n",
       "L 292.484764 206.96056 \n",
       "L 296.783685 209.455484 \n",
       "L 301.082607 211.615944 \n",
       "L 305.381528 213.458612 \n",
       "L 309.68045 216.558151 \n",
       "L 313.979371 216.596193 \n",
       "L 318.278293 218.761933 \n",
       "L 322.577214 222.723629 \n",
       "L 326.876135 222.232479 \n",
       "L 331.175057 224.505256 \n",
       "\" clip-path=\"url(#pdc023bc8d6)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_12\">\n",
       "    <path d=\"M 77.538693 29.03225 \n",
       "L 81.837615 31.921644 \n",
       "L 86.136536 37.525054 \n",
       "L 90.435457 41.389481 \n",
       "L 94.734379 44.994201 \n",
       "L 99.0333 47.09235 \n",
       "L 103.332222 51.299795 \n",
       "L 107.631143 54.390104 \n",
       "L 111.930065 57.416573 \n",
       "L 116.228986 60.333107 \n",
       "L 120.527907 63.360074 \n",
       "L 124.826829 66.556862 \n",
       "L 129.12575 69.753425 \n",
       "L 133.424672 75.896872 \n",
       "L 137.723593 83.260135 \n",
       "L 142.022514 86.862866 \n",
       "L 146.321436 90.507731 \n",
       "L 150.620357 94.071709 \n",
       "L 154.919279 97.752559 \n",
       "L 159.2182 101.128183 \n",
       "L 163.517122 104.226852 \n",
       "L 167.816043 107.76877 \n",
       "L 172.114964 111.278681 \n",
       "L 176.413886 114.039565 \n",
       "L 180.712807 117.463302 \n",
       "L 185.011729 121.425787 \n",
       "L 189.31065 123.879148 \n",
       "L 193.609571 127.042211 \n",
       "L 197.908493 130.869922 \n",
       "L 202.207414 138.659134 \n",
       "L 206.506336 140.577677 \n",
       "L 210.805257 145.087514 \n",
       "L 215.104179 146.497898 \n",
       "L 219.4031 148.535618 \n",
       "L 223.702021 151.545206 \n",
       "L 228.000943 154.687794 \n",
       "L 232.299864 156.639912 \n",
       "L 236.598786 159.850564 \n",
       "L 240.897707 162.541013 \n",
       "L 245.196628 166.189976 \n",
       "L 249.49555 168.622692 \n",
       "L 253.794471 173.690651 \n",
       "L 258.093393 179.633572 \n",
       "L 262.392314 182.341478 \n",
       "L 266.691236 185.037964 \n",
       "L 270.990157 186.199377 \n",
       "L 275.289078 188.829734 \n",
       "L 279.588 192.432631 \n",
       "L 283.886921 192.965494 \n",
       "L 288.185843 195.260384 \n",
       "L 292.484764 197.796451 \n",
       "L 296.783685 200.569748 \n",
       "L 301.082607 203.053456 \n",
       "L 305.381528 206.646311 \n",
       "L 309.68045 207.56512 \n",
       "L 313.979371 209.840821 \n",
       "L 318.278293 213.053853 \n",
       "L 322.577214 213.457555 \n",
       "L 326.876135 215.664771 \n",
       "L 331.175057 215.013521 \n",
       "\" clip-path=\"url(#pdc023bc8d6)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_13\">\n",
       "    <path d=\"M 77.538693 29.956773 \n",
       "L 81.837615 31.714931 \n",
       "L 86.136536 37.169327 \n",
       "L 90.435457 40.958561 \n",
       "L 94.734379 44.376357 \n",
       "L 99.0333 44.980353 \n",
       "L 103.332222 49.031064 \n",
       "L 107.631143 51.793738 \n",
       "L 111.930065 54.608992 \n",
       "L 116.228986 57.234909 \n",
       "L 120.527907 59.894552 \n",
       "L 124.826829 62.42754 \n",
       "L 129.12575 64.900456 \n",
       "L 133.424672 69.491153 \n",
       "L 137.723593 75.254371 \n",
       "L 142.022514 78.065817 \n",
       "L 146.321436 81.010314 \n",
       "L 150.620357 83.781488 \n",
       "L 154.919279 86.453068 \n",
       "L 159.2182 89.234568 \n",
       "L 163.517122 92.116943 \n",
       "L 167.816043 94.961954 \n",
       "L 172.114964 98.192752 \n",
       "L 176.413886 100.813673 \n",
       "L 180.712807 103.453037 \n",
       "L 185.011729 106.722405 \n",
       "L 189.31065 108.919815 \n",
       "L 193.609571 111.723386 \n",
       "L 197.908493 115.028181 \n",
       "L 202.207414 117.295693 \n",
       "L 206.506336 120.989307 \n",
       "L 210.805257 123.073985 \n",
       "L 215.104179 129.250269 \n",
       "L 219.4031 127.841113 \n",
       "L 223.702021 129.689327 \n",
       "L 228.000943 132.14525 \n",
       "L 232.299864 135.271615 \n",
       "L 236.598786 137.063296 \n",
       "L 240.897707 139.837801 \n",
       "L 245.196628 142.087714 \n",
       "L 249.49555 144.894338 \n",
       "L 253.794471 146.828437 \n",
       "L 258.093393 151.446772 \n",
       "L 262.392314 156.120799 \n",
       "L 266.691236 158.70285 \n",
       "L 270.990157 161.32983 \n",
       "L 275.289078 162.648762 \n",
       "L 279.588 164.879948 \n",
       "L 283.886921 168.044248 \n",
       "L 288.185843 168.920582 \n",
       "L 292.484764 171.112273 \n",
       "L 296.783685 172.919617 \n",
       "L 301.082607 175.211314 \n",
       "L 305.381528 177.185818 \n",
       "L 309.68045 179.971708 \n",
       "L 313.979371 181.033543 \n",
       "L 318.278293 182.974762 \n",
       "L 322.577214 185.855022 \n",
       "L 326.876135 186.292597 \n",
       "L 331.175057 188.112837 \n",
       "\" clip-path=\"url(#pdc023bc8d6)\" style=\"fill: none; stroke: #2ca02c; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_14\">\n",
       "    <path d=\"M 77.538693 31.386504 \n",
       "L 81.837615 37.248114 \n",
       "L 86.136536 41.266243 \n",
       "L 90.435457 45.055897 \n",
       "L 94.734379 45.435532 \n",
       "L 99.0333 50.055108 \n",
       "L 103.332222 52.999641 \n",
       "L 107.631143 55.726795 \n",
       "L 111.930065 58.449492 \n",
       "L 116.228986 61.094626 \n",
       "L 120.527907 63.777632 \n",
       "L 124.826829 66.269241 \n",
       "L 129.12575 70.694976 \n",
       "L 133.424672 76.214025 \n",
       "L 137.723593 79.225013 \n",
       "L 142.022514 82.154109 \n",
       "L 146.321436 85.141083 \n",
       "L 150.620357 87.857038 \n",
       "L 154.919279 90.687179 \n",
       "L 159.2182 94.405337 \n",
       "L 163.517122 97.926132 \n",
       "L 167.816043 101.866947 \n",
       "L 172.114964 104.79748 \n",
       "L 176.413886 108.300734 \n",
       "L 180.712807 112.530456 \n",
       "L 185.011729 115.094981 \n",
       "L 189.31065 118.379694 \n",
       "L 193.609571 122.111032 \n",
       "L 197.908493 124.544672 \n",
       "L 202.207414 129.681312 \n",
       "L 206.506336 132.008201 \n",
       "L 210.805257 139.160584 \n",
       "L 215.104179 139.163258 \n",
       "L 219.4031 141.446033 \n",
       "L 223.702021 144.633198 \n",
       "L 228.000943 148.547453 \n",
       "L 232.299864 150.602042 \n",
       "L 236.598786 154.000814 \n",
       "L 240.897707 157.031426 \n",
       "L 245.196628 160.735427 \n",
       "L 249.49555 162.749527 \n",
       "L 253.794471 168.436541 \n",
       "L 258.093393 174.46711 \n",
       "L 262.392314 177.517876 \n",
       "L 266.691236 181.765302 \n",
       "L 270.990157 182.746974 \n",
       "L 275.289078 185.512467 \n",
       "L 279.588 190.038943 \n",
       "L 283.886921 190.652765 \n",
       "L 288.185843 193.390449 \n",
       "L 292.484764 195.886102 \n",
       "L 296.783685 198.83831 \n",
       "L 301.082607 201.510784 \n",
       "L 305.381528 205.871296 \n",
       "L 309.68045 206.253049 \n",
       "L 313.979371 208.859583 \n",
       "L 318.278293 213.705318 \n",
       "L 322.577214 212.623055 \n",
       "L 326.876135 215.056521 \n",
       "L 331.175057 214.796703 \n",
       "\" clip-path=\"url(#pdc023bc8d6)\" style=\"fill: none; stroke: #d62728; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 64.856875 234.278906 \n",
       "L 64.856875 12.518906 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 343.856875 234.278906 \n",
       "L 343.856875 12.518906 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 64.856875 234.278906 \n",
       "L 343.856875 234.278906 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 64.856875 12.518906 \n",
       "L 343.856875 12.518906 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pdc023bc8d6\">\n",
       "   <rect x=\"64.856875\" y=\"12.518906\" width=\"279\" height=\"221.76\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Battery_list = ['Cell1','Cell3','Cell7','Cell8' ]\n",
    "data_root='../data/OXFORD_data/pinn_path/'\n",
    "def smooth_data(sequence, window_size):\n",
    "    \"\"\"数据平滑\"\"\"\n",
    "    if window_size < 1:\n",
    "        raise ValueError(\"窗口大小必须大于等于1\")\n",
    "    # 初始化平滑后的数据列表\n",
    "    smoothed_sequence = []\n",
    "    # 计算窗口内的平均值\n",
    "    for i in range(len(sequence)):\n",
    "        # 计算窗口的起始和结束索引\n",
    "        start_index = max(0, i - window_size + 1)\n",
    "        end_index = i + 1\n",
    "        # 计算窗口内的数据平均值\n",
    "        window_average = sum(sequence[start_index:end_index]) / (end_index - start_index)\n",
    "        # 将平均值添加到平滑后的数据列表中\n",
    "        smoothed_sequence.append(window_average)\n",
    "    return smoothed_sequence\n",
    "def drop_outlier(array,count,bins):\n",
    "    \"\"\"离群值提取--用3sigma方法\"\"\"\n",
    "    index = []\n",
    "    range_n = np.arange(1,count,bins)\n",
    "    for i in range_n[:-1]:\n",
    "        array_lim = array[i:i+bins]\n",
    "        sigma = np.std(array_lim)\n",
    "        mean = np.mean(array_lim)\n",
    "        th_max,th_min = mean + sigma*2, mean - sigma*2\n",
    "        idx = np.where((array_lim < th_max) & (array_lim > th_min))\n",
    "        idx = idx[0] + i\n",
    "        index.extend(list(idx))\n",
    "    return np.array(index)\n",
    "def clean_data(array_figs,array_labels):\n",
    "    index_keep=drop_outlier(array_labels,len(array_labels),35)\n",
    "    array_figs,array_labels=array_figs[index_keep],array_labels[index_keep]\n",
    "    array_figs,array_labels=array_figs[drop_outlier(array_labels,len(array_labels),10)],array_labels[drop_outlier(array_labels,len(array_labels),10)]\n",
    "    return array_figs,array_labels\n",
    "def add_row_index_to_array(arr):\n",
    "    \"\"\"\n",
    "    在输入数组的每一行的第一个元素加上行号，并扩展数组维度。\n",
    "    \n",
    "    参数:\n",
    "    arr (np.ndarray): 形状为 (n, 6) 的输入数组。\n",
    "    \n",
    "    返回:\n",
    "    np.ndarray: 形状为 (n, 7) 的数组。\n",
    "    \"\"\"\n",
    "    # 检查输入数组形状是否为 (n, 6)\n",
    "    if arr.shape[1] != 6:\n",
    "        raise ValueError(\"输入数组必须是形状为 (n, 6) 的数组。\")\n",
    "\n",
    "    # 创建一个新数组，其形状为 (n, 7)，初始化为输入数组\n",
    "    new_arr = np.zeros((arr.shape[0], 7))\n",
    "    new_arr[:, 1:] = arr  # 将输入数组的数据复制到新数组的后面六个列\n",
    "    # 在新数组的每一行的第一个元素加上行号\n",
    "    new_arr[:, 0] = np.arange(arr.shape[0])\n",
    "    return new_arr\n",
    "plt.figure(figsize=(5, 4))\n",
    "df=pd.DataFrame()\n",
    "for name in Battery_list:\n",
    "    path=data_root+name+'.npz'\n",
    "    arrays=np.load(path)\n",
    "    features,SOHs=clean_data(arrays['array1'],arrays['array2'])\n",
    "    df=add_column_with_variable_length(df,SOHs,name)\n",
    "    plt.plot(SOHs)\n",
    "    # \"\"\"抛弃异常值处理\"\"\"\n",
    "    # index_keep=drop_outlier(SOHs,len(SOHs),35)\n",
    "    # plt.plot(SOHs[index_keep][drop_outlier(SOHs[index_keep],len(SOHs[index_keep]),10)])\n",
    "    # plt.plot(process_sequence(SOHs,1))\n",
    "    plt.yticks([0.8,0.85,0.9,0.95,1],fontsize=14)\n",
    "    plt.xticks([0,15,30,45,60],fontsize=14)\n",
    "    plt.xlabel('Cycle', fontsize=16)\n",
    "    plt.ylabel('SOH',fontsize=16)\n",
    "    print(features[1][0])\n",
    "plt.show()\n",
    "df.to_csv('../2origin/ox_soh.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f6594d47f16187",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T00:47:11.171889Z",
     "start_time": "2025-03-31T00:47:11.141611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 7])\n",
      "torch.Size([16, 7])\n",
      "torch.Size([16, 7])\n",
      "torch.Size([16, 7])\n",
      "torch.Size([16, 7])\n",
      "torch.Size([16, 7])\n"
     ]
    }
   ],
   "source": [
    "def setup_seed(seed):\n",
    "    \"\"\"set random seed\"\"\"\n",
    "    np.random.seed(seed)  # Numpy module.\n",
    "    random.seed(seed)  # Python random module.\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed) \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def evaluation(y_test, y_predict):\n",
    "    mse = mean_squared_error(y_test, y_predict)\n",
    "    rmse = sqrt(mean_squared_error(y_test, y_predict))\n",
    "    return rmse\n",
    "def get_data():\n",
    "    \"\"\"获取训练集，测试集，验证集\"\"\"\n",
    "    train_list = Battery_list\n",
    "    train_data=[]\n",
    "    for b_n in train_list:\n",
    "        path = '../data/OXFORD_data/pinn_path/' + b_n + '.npz'\n",
    "        arrays = np.load(path)\n",
    "        a,b=clean_data(arrays['array1'],arrays['array2'])\n",
    "        a=add_row_index_to_array(a)\n",
    "        train_data.append([a,b])\n",
    "    train_valid_features=torch.from_numpy(np.concatenate((train_data[0][0],train_data[2][0]),axis=0)).float()\n",
    "    train_valid_labels=torch.from_numpy(np.concatenate((train_data[0][1],train_data[2][1]),axis=0)).float()\n",
    "    dataset=TensorDataset(train_valid_features,train_valid_labels)\n",
    "    # 确定训练集和验证集的大小\n",
    "    train_size = int(0.2 * len(dataset))  # 80%的训练集\n",
    "    val_size = len(dataset) - train_size   # 剩余的20%作为验证集\n",
    "    # 随机分割数据集\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "    # 创建DataLoader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    test_7_data,test_8_data=[train_data[1][0],train_data[1][1]],[train_data[3][0],train_data[3][1]]\n",
    "    return train_loader, val_loader, test_7_data,test_8_data\n",
    "\n",
    "a,b,_,_,=get_data()\n",
    "for x,y in b:\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "142d8228f31e1fff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T00:47:11.221222Z",
     "start_time": "2025-03-31T00:47:11.171889Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, input_dim=7, output_dim=12, num_heads=4, head_dim=24, dropout=0):\n",
    "        \"\"\"用多头注意力进行解码\"\"\"\n",
    "        \"\"\"\n",
    "        多头注意力模块。\n",
    "        :param input_dim: 输入特征维度\n",
    "        :param output_dim: 输出特征维度\n",
    "        :param num_heads: 注意力头的数量\n",
    "        :param head_dim: 每个注意力头的维度\n",
    "        :param dropout: Dropout 概率\n",
    "        \"\"\"\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.input_dim = input_dim-1\n",
    "        self.output_dim = output_dim-1\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = head_dim\n",
    "        self.dropout = dropout\n",
    "        # 线性变换层，将输入映射到 Q, K, V\n",
    "        self.query = nn.Linear(input_dim-1, num_heads * head_dim)\n",
    "        self.key = nn.Linear(input_dim-1, num_heads * head_dim)\n",
    "        self.value = nn.Linear(input_dim-1, num_heads * head_dim)\n",
    "        # 输出线性层\n",
    "        self.fc_out = nn.Linear(num_heads * head_dim, output_dim-1)\n",
    "        # Dropout 层\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播。\n",
    "        :param x: 输入张量，形状为 (batch_size, input_dim)\n",
    "        :return: 输出张量，形状为 (batch_size, output_dim)\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        x_t=x[:,0].unsqueeze(1)\n",
    "        x=x[:,1:]\n",
    "        # 线性变换，得到 Q, K, V\n",
    "        Q = self.query(x).view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)  # (batch_size, num_heads, seq_len, head_dim)\n",
    "        K = self.key(x).view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)    # (batch_size, num_heads, seq_len, head_dim)\n",
    "        V = self.value(x).view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)  # (batch_size, num_heads, seq_len, head_dim)\n",
    "        # 计算注意力分数\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(self.head_dim, dtype=torch.float32))  # (batch_size, num_heads, seq_len, seq_len)\n",
    "        attention_weights = F.softmax(scores, dim=-1)  # (batch_size, num_heads, seq_len, seq_len)\n",
    "        attention_weights = self.dropout_layer(attention_weights)\n",
    "        # 计算加权和\n",
    "        attention_output = torch.matmul(attention_weights, V)  # (batch_size, num_heads, seq_len, head_dim)\n",
    "        # 拼接多头输出\n",
    "        attention_output = attention_output.transpose(1, 2).contiguous().view(batch_size, -1, self.num_heads * self.head_dim)  # (batch_size, seq_len, num_heads * head_dim)\n",
    "        # 通过线性层映射到输出维度\n",
    "        output = self.fc_out(attention_output)  # (batch_size, seq_len, output_dim)\n",
    "        output=torch.cat((x_t,output.squeeze(1)),dim=-1)\n",
    "        return output  # (batch_size, output_dim)\n",
    "\"\"\"--------------------------------------------------------多物理场混合专家模型-------------------------------------------------------\"\"\"\n",
    "class MixtureOfExperts(nn.Module):\n",
    "    def __init__(self, input_dim, num_experts, expert_hidden_dim):\n",
    "        super(MixtureOfExperts, self).__init__()\n",
    "        self.num_experts = num_experts\n",
    "        # 专家网络\n",
    "        self.experts = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(input_dim, 2*expert_hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(2*expert_hidden_dim, 4*expert_hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(4*expert_hidden_dim, 8*expert_hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(8*expert_hidden_dim, 16*expert_hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(16*expert_hidden_dim, 32*expert_hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(32*expert_hidden_dim,64*expert_hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64*expert_hidden_dim,32*expert_hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(32*expert_hidden_dim,16*expert_hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(16*expert_hidden_dim, 8*expert_hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(8*expert_hidden_dim, 4*expert_hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(4*expert_hidden_dim,expert_hidden_dim ),\n",
    "            )\n",
    "            for _ in range(num_experts)\n",
    "        ])\n",
    "        # 门控网络\n",
    "        self.gating_network = nn.Linear(input_dim, num_experts)\n",
    "        # 输出层\n",
    "        self.output_layer = nn.Linear(expert_hidden_dim, 1)\n",
    "    def initialize_weights(self):\n",
    "        nn.init.xavier_uniform_(self.gating_network.weight)\n",
    "        nn.init.xavier_uniform_(self.output_layer.weight)\n",
    "    def forward(self, x):\n",
    "        # 计算所有专家的输出\n",
    "        expert_outputs = torch.stack([expert(x) for expert in self.experts], dim=1)\n",
    "        #shape(batch_size,num_expert,expert_hidden_dim)\n",
    "        # 计算门控网络的输出并应用softmax得到权重\n",
    "        gate_works=torch.exp(self.gating_network(x)/10)\n",
    "        gating_outputs = F.softmax(gate_works, dim=1)\n",
    "        # 将门控网络的输出（权重）与专家网络的输出相乘并求和\n",
    "        combined_output = torch.sum(expert_outputs * gating_outputs.unsqueeze(-1), dim=1)\n",
    "        # 通过输出层得到最终输出\n",
    "        final_output = self.output_layer(combined_output)\n",
    "        return final_output,expert_outputs      #返回总输出和每个专家输出\n",
    "    \n",
    "class PINN_MOE(nn.Module):\n",
    "    def __init__(self,input_dim=7, output_dim=12, num_heads=4, head_dim=24, dropout=0,expert_input_dim=12, num_experts=3,expert_hidden_dim=2):\n",
    "        super(PINN_MOE, self).__init__()\n",
    "        self.Decoupling=MultiHeadAttention(input_dim, output_dim, num_heads, head_dim, dropout)\n",
    "        self.multi_physics=MixtureOfExperts(expert_input_dim, num_experts,expert_hidden_dim)\n",
    "        self.physics=nn.Sequential(\n",
    "            nn.Linear(6, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1),\n",
    "        )\n",
    "        # self.electricity=nn.Sequential(nn.Linear(expert_hidden_dim, 2*expert_hidden_dim),nn.ReLU(),nn.Linear(2*expert_hidden_dim,expert_hidden_dim),nn.ReLU(),nn.Linear(expert_hidden_dim,2))\n",
    "        # self.heat=nn.Sequential(nn.Linear(expert_hidden_dim, 2*expert_hidden_dim),nn.ReLU(),nn.Linear(2*expert_hidden_dim,expert_hidden_dim),nn.ReLU(),nn.Linear(expert_hidden_dim,2))\n",
    "        # self.mechine=nn.Sequential(nn.Linear(expert_hidden_dim, 2*expert_hidden_dim),nn.ReLU(),nn.Linear(2*expert_hidden_dim,expert_hidden_dim),nn.ReLU(),nn.Linear(expert_hidden_dim,2))\n",
    "        self.parameter_heat=nn.Parameter(torch.tensor(1, dtype=torch.float32))\n",
    "        self.parameter_electricity1=nn.Parameter(torch.tensor(1, dtype=torch.float32))\n",
    "        self.parameter_electricity2=nn.Parameter(torch.tensor(1, dtype=torch.float32))\n",
    "    def  initialize_weights(self):\n",
    "        nn.init.xavier_uniform_(self.Decoupling.parameters)\n",
    "        nn.init.xavier_uniform_(self.multi_physics.parameters)\n",
    "        # nn.init.xavier_uniform_(self.heat.parameters)\n",
    "        # nn.init.xavier_uniform_(self.mechine.parameters)\n",
    "        # nn.init.xavier_uniform_(self.electricity.parameters)\n",
    "        nn.init.xavier_uniform_(self.physics.parameters)\n",
    "        nn.init.xavier_uniform_(self.parameter_heat)\n",
    "        nn.init.xavier_uniform_(self.parameter_electricity1)\n",
    "        nn.init.xavier_uniform_(self.parameter_electricity2)\n",
    "    def forward(self, tx):\n",
    "        tx.requires_grad_(True)\n",
    "        # 解耦输入\n",
    "        t_x = self.Decoupling(tx)\n",
    "        t=t_x[:,0:1]\n",
    "        x=t_x[:,1:]\n",
    "        # 预测物理量\n",
    "        s_pred,experts = self.multi_physics(torch.cat((t,x),dim=1))\n",
    "        # 计算 s_pred 对 t 和 x 的偏导数\n",
    "        \"\"\"综合损失\"\"\"\n",
    "        s_t = grad(s_pred.sum(),t,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "        s_x = grad(s_pred.sum(),x,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "        \"\"\"热效应损失\"\"\"\n",
    "        T_Q=experts[:,0:1,:].squeeze(1)\n",
    "        # print(T_Q.shape)\n",
    "        T=T_Q[:,0:1]\n",
    "        Q=T_Q[:,1:2]\n",
    "        T_t=grad(T.sum(),t,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "        T_x=grad(T.sum(),x,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "        T_laplace=grad(T_t.sum(),t,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "        loss_heat=torch.mean((T_t - (self.parameter_heat) * T_laplace - Q) ** 2, dim=1).unsqueeze(1)\n",
    "        \"\"\"电化学效应损失\"\"\"\n",
    "        phi_c=experts[:,1:2,:].squeeze(1)\n",
    "        phi=phi_c[:,0:1]\n",
    "        c=phi_c[:,1:2]\n",
    "        phi_t=grad(phi.sum(),t,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "        phi_x=grad(phi.sum(),x,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "        c_x=grad(c.sum(),x,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "        c_t=grad(c.sum(),t,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "        phi_laplace=grad(phi_x.sum(),x,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "        c_laplace=grad(c_x.sum(),x,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "        loss_electricity=torch.mean((c_t -self.parameter_electricity1 * c_laplace -self.parameter_electricity2) ** 2,dim=1).unsqueeze(1)+torch.mean(phi_laplace** 2,dim=1).unsqueeze(1)\n",
    "        \"\"\"机械应力损失\"\"\"\n",
    "        sigma_f=experts[:,2:3,:].squeeze(1)\n",
    "        sigma=sigma_f[:,0:1]\n",
    "        f=sigma_f[:,1:2]\n",
    "        sigma_x=grad(sigma.sum(),x,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "        sigma_laplace=grad(sigma_x.sum(),x,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "        loss_mechine=torch.mean((sigma_laplace + f) ** 2,dim=1).unsqueeze(1)\n",
    "        # 打印 s_t 和 s_x，确保它们不为 None\n",
    "        # 计算物理约束 F\n",
    "        F_input = torch.cat([phi,c,T,Q,sigma,f], dim=1)\n",
    "        soh = self.physics(F_input)\n",
    "        # 计算残差 f\n",
    "        loss_all = 0.01*loss_electricity+0.01*loss_heat+0.01*loss_mechine\n",
    "        return soh, loss_all,[phi,c,T,Q,sigma,f]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "db647fbe2596f867",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T00:47:11.237220Z",
     "start_time": "2025-03-31T00:47:11.224223Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(lr=0.003,epochs=200, weight_decay=1e-4, seed=0, metric='rmse', device='cpu'):\n",
    "    \"\"\"function for train\"\"\"\n",
    "    setup_seed(seed)\n",
    "    print(\"training seed \"+str(seed)+':\\n')\n",
    "    train_loader, val_loader, test_35_data, test_36_data=get_data()\n",
    "    test_data=[test_35_data, test_36_data]\n",
    "    model = PINN_MOE()\n",
    "    model=model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.MSELoss()\n",
    "    len_dataloader = len(train_loader)\n",
    "    test_results=[]\n",
    "    lists=[]\n",
    "    \"\"\"早停止获取最佳模型\"\"\"\n",
    "    val_mse=10\n",
    "    train_loss=10\n",
    "    for epoch in range(epochs):\n",
    "        loss_epoch=0\n",
    "        for X,y in train_loader:\n",
    "            X,y = X.to(device), y.to(device)\n",
    "            y_pred,f,_= model(X)\n",
    "            f_target = torch.zeros_like(f)\n",
    "            y_pred = y_pred.squeeze(1)\n",
    "            loss = criterion(y_pred,y)+0.3*criterion(f,f_target)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_epoch += loss\n",
    "        if (epoch+1)%5==0 and epoch!=0:\n",
    "            print('Epoch:',epoch+1,'Train_RMSELoss:',loss_epoch/len_dataloader,'\\n')\n",
    "            train_loss=loss_epoch/len_dataloader\n",
    "        if (epoch+1)%5==0 and epoch!=0:\n",
    "            val_loss=0\n",
    "            for val_x,val_y in val_loader:\n",
    "                val_x,val_y=val_x.to(device),val_y.to(device)\n",
    "                pre,_,_=model(val_x)\n",
    "                val_loss+=criterion(pre.squeeze(1),val_y).detach()    \n",
    "            print('Epoch:',epoch+1,'valid_RMSELoss:',val_loss/len(val_loader),'\\n')\n",
    "            val_mse=val_loss/len(val_loader)\n",
    "                \n",
    "        if (val_mse<1e-4 and train_loss<2e-4)or (epoch+1)==epochs:\n",
    "            model=model.cpu()\n",
    "            torch.save(model.state_dict(), '../pretrained/ox_model.pth')\n",
    "            for name in test_data:\n",
    "                X=torch.from_numpy(name[0]).float()\n",
    "                y=name[1]\n",
    "                y_pred,_,list=model(X)\n",
    "                for i in range(len(list)):\n",
    "                    list[i]=list[i].detach().cpu().numpy()\n",
    "                lists.append(list)\n",
    "                y_pred= y_pred.squeeze(0).detach().numpy()\n",
    "                test_results.append([y,y_pred])\n",
    "            break\n",
    "    return test_results,lists\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7313fe0583afc62a",
   "metadata": {},
   "source": [
    "## 五个随机种子训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70dd4bd49d8e0865",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T00:47:14.922348Z",
     "start_time": "2025-03-31T00:47:11.238220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training seed 0:\n",
      "\n",
      "Epoch: 5 Train_RMSELoss: tensor(0.6768, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 5 valid_RMSELoss: tensor(0.6594, device='cuda:0') \n",
      "\n",
      "Epoch: 10 Train_RMSELoss: tensor(0.2927, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 10 valid_RMSELoss: tensor(0.1901, device='cuda:0') \n",
      "\n",
      "Epoch: 15 Train_RMSELoss: tensor(0.0264, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 15 valid_RMSELoss: tensor(0.0431, device='cuda:0') \n",
      "\n",
      "Epoch: 20 Train_RMSELoss: tensor(0.0149, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 20 valid_RMSELoss: tensor(0.0115, device='cuda:0') \n",
      "\n",
      "Epoch: 25 Train_RMSELoss: tensor(0.0098, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 25 valid_RMSELoss: tensor(0.0089, device='cuda:0') \n",
      "\n",
      "Epoch: 30 Train_RMSELoss: tensor(0.0050, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 30 valid_RMSELoss: tensor(0.0043, device='cuda:0') \n",
      "\n",
      "Epoch: 35 Train_RMSELoss: tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 35 valid_RMSELoss: tensor(0.0027, device='cuda:0') \n",
      "\n",
      "Epoch: 40 Train_RMSELoss: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 40 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 45 Train_RMSELoss: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 45 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 50 Train_RMSELoss: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 50 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 55 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 55 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 60 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 60 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 65 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 65 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 70 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 70 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 75 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 75 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 80 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 80 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 85 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 85 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 90 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 90 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 95 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 95 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 100 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 100 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 105 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 105 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 110 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 110 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 115 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 115 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 120 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 120 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 125 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 125 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 130 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 130 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 135 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 135 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 140 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 140 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 145 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 145 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 150 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 150 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 155 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 155 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 160 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 160 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 165 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 165 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 170 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 170 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 175 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 175 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 180 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 180 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 185 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 185 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 190 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 190 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 195 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 195 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 200 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 200 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "training seed 1:\n",
      "\n",
      "Epoch: 5 Train_RMSELoss: tensor(0.4315, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 5 valid_RMSELoss: tensor(0.3640, device='cuda:0') \n",
      "\n",
      "Epoch: 10 Train_RMSELoss: tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 10 valid_RMSELoss: tensor(0.0465, device='cuda:0') \n",
      "\n",
      "Epoch: 15 Train_RMSELoss: tensor(0.0254, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 15 valid_RMSELoss: tensor(0.0139, device='cuda:0') \n",
      "\n",
      "Epoch: 20 Train_RMSELoss: tensor(0.0092, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 20 valid_RMSELoss: tensor(0.0083, device='cuda:0') \n",
      "\n",
      "Epoch: 25 Train_RMSELoss: tensor(0.0045, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 25 valid_RMSELoss: tensor(0.0044, device='cuda:0') \n",
      "\n",
      "Epoch: 30 Train_RMSELoss: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 30 valid_RMSELoss: tensor(0.0010, device='cuda:0') \n",
      "\n",
      "Epoch: 35 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 35 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 40 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 40 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 45 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 45 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 50 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 50 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 55 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 55 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 60 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 60 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 65 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 65 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 70 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 70 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 75 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 75 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 80 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 80 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 85 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 85 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 90 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 90 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 95 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 95 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 100 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 100 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 105 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 105 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 110 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 110 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 115 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 115 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 120 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 120 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 125 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 125 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 130 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 130 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 135 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 135 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 140 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 140 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 145 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 145 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 150 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 150 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 155 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 155 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 160 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 160 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 165 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 165 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 170 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 170 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 175 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 175 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 180 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 180 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 185 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 185 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 190 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 190 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 195 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 195 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 200 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 200 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "training seed 2:\n",
      "\n",
      "Epoch: 5 Train_RMSELoss: tensor(0.4681, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 5 valid_RMSELoss: tensor(0.3646, device='cuda:0') \n",
      "\n",
      "Epoch: 10 Train_RMSELoss: tensor(0.0393, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 10 valid_RMSELoss: tensor(0.3182, device='cuda:0') \n",
      "\n",
      "Epoch: 15 Train_RMSELoss: tensor(0.0395, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 15 valid_RMSELoss: tensor(0.0166, device='cuda:0') \n",
      "\n",
      "Epoch: 20 Train_RMSELoss: tensor(0.0081, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 20 valid_RMSELoss: tensor(0.0288, device='cuda:0') \n",
      "\n",
      "Epoch: 25 Train_RMSELoss: tensor(0.0058, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 25 valid_RMSELoss: tensor(0.0063, device='cuda:0') \n",
      "\n",
      "Epoch: 30 Train_RMSELoss: tensor(0.0047, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 30 valid_RMSELoss: tensor(0.0098, device='cuda:0') \n",
      "\n",
      "Epoch: 35 Train_RMSELoss: tensor(0.0047, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 35 valid_RMSELoss: tensor(0.0073, device='cuda:0') \n",
      "\n",
      "Epoch: 40 Train_RMSELoss: tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 40 valid_RMSELoss: tensor(0.0070, device='cuda:0') \n",
      "\n",
      "Epoch: 45 Train_RMSELoss: tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 45 valid_RMSELoss: tensor(0.0053, device='cuda:0') \n",
      "\n",
      "Epoch: 50 Train_RMSELoss: tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 50 valid_RMSELoss: tensor(0.0064, device='cuda:0') \n",
      "\n",
      "Epoch: 55 Train_RMSELoss: tensor(0.0028, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 55 valid_RMSELoss: tensor(0.0038, device='cuda:0') \n",
      "\n",
      "Epoch: 60 Train_RMSELoss: tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 60 valid_RMSELoss: tensor(0.0019, device='cuda:0') \n",
      "\n",
      "Epoch: 65 Train_RMSELoss: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 65 valid_RMSELoss: tensor(0.0010, device='cuda:0') \n",
      "\n",
      "Epoch: 70 Train_RMSELoss: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 70 valid_RMSELoss: tensor(0.0006, device='cuda:0') \n",
      "\n",
      "Epoch: 75 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 75 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 80 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 80 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 85 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 85 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 90 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 90 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 95 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 95 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 100 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 100 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 105 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 105 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 110 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 110 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 115 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 115 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 120 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 120 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 125 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 125 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 130 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 130 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 135 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 135 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 140 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 140 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 145 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 145 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 150 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 150 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 155 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 155 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 160 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 160 valid_RMSELoss: tensor(0.0005, device='cuda:0') \n",
      "\n",
      "Epoch: 165 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 165 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 170 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 170 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 175 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 175 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 180 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 180 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 185 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 185 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 190 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 190 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 195 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 195 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 200 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 200 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "training seed 3:\n",
      "\n",
      "Epoch: 5 Train_RMSELoss: tensor(0.2780, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 5 valid_RMSELoss: tensor(0.2495, device='cuda:0') \n",
      "\n",
      "Epoch: 10 Train_RMSELoss: tensor(0.0138, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 10 valid_RMSELoss: tensor(0.0302, device='cuda:0') \n",
      "\n",
      "Epoch: 15 Train_RMSELoss: tensor(0.0069, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 15 valid_RMSELoss: tensor(0.0101, device='cuda:0') \n",
      "\n",
      "Epoch: 20 Train_RMSELoss: tensor(0.0029, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 20 valid_RMSELoss: tensor(0.0046, device='cuda:0') \n",
      "\n",
      "Epoch: 25 Train_RMSELoss: tensor(0.0024, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 25 valid_RMSELoss: tensor(0.0041, device='cuda:0') \n",
      "\n",
      "Epoch: 30 Train_RMSELoss: tensor(0.0027, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 30 valid_RMSELoss: tensor(0.0040, device='cuda:0') \n",
      "\n",
      "Epoch: 35 Train_RMSELoss: tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 35 valid_RMSELoss: tensor(0.0039, device='cuda:0') \n",
      "\n",
      "Epoch: 40 Train_RMSELoss: tensor(0.0025, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 40 valid_RMSELoss: tensor(0.0038, device='cuda:0') \n",
      "\n",
      "Epoch: 45 Train_RMSELoss: tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 45 valid_RMSELoss: tensor(0.0035, device='cuda:0') \n",
      "\n",
      "Epoch: 50 Train_RMSELoss: tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 50 valid_RMSELoss: tensor(0.0026, device='cuda:0') \n",
      "\n",
      "Epoch: 55 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 55 valid_RMSELoss: tensor(0.0006, device='cuda:0') \n",
      "\n",
      "Epoch: 60 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 60 valid_RMSELoss: tensor(0.0006, device='cuda:0') \n",
      "\n",
      "Epoch: 65 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 65 valid_RMSELoss: tensor(0.0006, device='cuda:0') \n",
      "\n",
      "Epoch: 70 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 70 valid_RMSELoss: tensor(0.0005, device='cuda:0') \n",
      "\n",
      "Epoch: 75 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 75 valid_RMSELoss: tensor(0.0005, device='cuda:0') \n",
      "\n",
      "Epoch: 80 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 80 valid_RMSELoss: tensor(0.0006, device='cuda:0') \n",
      "\n",
      "Epoch: 85 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 85 valid_RMSELoss: tensor(0.0005, device='cuda:0') \n",
      "\n",
      "Epoch: 90 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 90 valid_RMSELoss: tensor(0.0005, device='cuda:0') \n",
      "\n",
      "Epoch: 95 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 95 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 100 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 100 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 105 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 105 valid_RMSELoss: tensor(0.0005, device='cuda:0') \n",
      "\n",
      "Epoch: 110 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 110 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 115 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 115 valid_RMSELoss: tensor(0.0005, device='cuda:0') \n",
      "\n",
      "Epoch: 120 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 120 valid_RMSELoss: tensor(0.0005, device='cuda:0') \n",
      "\n",
      "Epoch: 125 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 125 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 130 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 130 valid_RMSELoss: tensor(0.0005, device='cuda:0') \n",
      "\n",
      "Epoch: 135 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 135 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 140 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 140 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 145 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 145 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 150 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 150 valid_RMSELoss: tensor(0.0005, device='cuda:0') \n",
      "\n",
      "Epoch: 155 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 155 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 160 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 160 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 165 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 165 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 170 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 170 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 175 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 175 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 180 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 180 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 185 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 185 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 190 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 190 valid_RMSELoss: tensor(0.0005, device='cuda:0') \n",
      "\n",
      "Epoch: 195 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 195 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 200 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 200 valid_RMSELoss: tensor(0.0005, device='cuda:0') \n",
      "\n",
      "training seed 4:\n",
      "\n",
      "Epoch: 5 Train_RMSELoss: tensor(0.4399, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 5 valid_RMSELoss: tensor(0.3636, device='cuda:0') \n",
      "\n",
      "Epoch: 10 Train_RMSELoss: tensor(0.0318, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 10 valid_RMSELoss: tensor(0.2912, device='cuda:0') \n",
      "\n",
      "Epoch: 15 Train_RMSELoss: tensor(0.0436, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 15 valid_RMSELoss: tensor(0.0294, device='cuda:0') \n",
      "\n",
      "Epoch: 20 Train_RMSELoss: tensor(0.0087, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 20 valid_RMSELoss: tensor(0.0222, device='cuda:0') \n",
      "\n",
      "Epoch: 25 Train_RMSELoss: tensor(0.0052, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 25 valid_RMSELoss: tensor(0.0059, device='cuda:0') \n",
      "\n",
      "Epoch: 30 Train_RMSELoss: tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 30 valid_RMSELoss: tensor(0.0057, device='cuda:0') \n",
      "\n",
      "Epoch: 35 Train_RMSELoss: tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 35 valid_RMSELoss: tensor(0.0046, device='cuda:0') \n",
      "\n",
      "Epoch: 40 Train_RMSELoss: tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 40 valid_RMSELoss: tensor(0.0027, device='cuda:0') \n",
      "\n",
      "Epoch: 45 Train_RMSELoss: tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 45 valid_RMSELoss: tensor(0.0026, device='cuda:0') \n",
      "\n",
      "Epoch: 50 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 50 valid_RMSELoss: tensor(0.0008, device='cuda:0') \n",
      "\n",
      "Epoch: 55 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 55 valid_RMSELoss: tensor(0.0006, device='cuda:0') \n",
      "\n",
      "Epoch: 60 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 60 valid_RMSELoss: tensor(0.0008, device='cuda:0') \n",
      "\n",
      "Epoch: 65 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 65 valid_RMSELoss: tensor(0.0008, device='cuda:0') \n",
      "\n",
      "Epoch: 70 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 70 valid_RMSELoss: tensor(0.0008, device='cuda:0') \n",
      "\n",
      "Epoch: 75 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 75 valid_RMSELoss: tensor(0.0007, device='cuda:0') \n",
      "\n",
      "Epoch: 80 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 80 valid_RMSELoss: tensor(0.0007, device='cuda:0') \n",
      "\n",
      "Epoch: 85 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 85 valid_RMSELoss: tensor(0.0006, device='cuda:0') \n",
      "\n",
      "Epoch: 90 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 90 valid_RMSELoss: tensor(0.0006, device='cuda:0') \n",
      "\n",
      "Epoch: 95 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 95 valid_RMSELoss: tensor(0.0006, device='cuda:0') \n",
      "\n",
      "Epoch: 100 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 100 valid_RMSELoss: tensor(0.0006, device='cuda:0') \n",
      "\n",
      "Epoch: 105 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 105 valid_RMSELoss: tensor(0.0006, device='cuda:0') \n",
      "\n",
      "Epoch: 110 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 110 valid_RMSELoss: tensor(0.0006, device='cuda:0') \n",
      "\n",
      "Epoch: 115 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 115 valid_RMSELoss: tensor(0.0006, device='cuda:0') \n",
      "\n",
      "Epoch: 120 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 120 valid_RMSELoss: tensor(0.0006, device='cuda:0') \n",
      "\n",
      "Epoch: 125 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 125 valid_RMSELoss: tensor(0.0006, device='cuda:0') \n",
      "\n",
      "Epoch: 130 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 130 valid_RMSELoss: tensor(0.0006, device='cuda:0') \n",
      "\n",
      "Epoch: 135 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 135 valid_RMSELoss: tensor(0.0006, device='cuda:0') \n",
      "\n",
      "Epoch: 140 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 140 valid_RMSELoss: tensor(0.0007, device='cuda:0') \n",
      "\n",
      "Epoch: 145 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 145 valid_RMSELoss: tensor(0.0006, device='cuda:0') \n",
      "\n",
      "Epoch: 150 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 150 valid_RMSELoss: tensor(0.0006, device='cuda:0') \n",
      "\n",
      "Epoch: 155 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 155 valid_RMSELoss: tensor(0.0006, device='cuda:0') \n",
      "\n",
      "Epoch: 160 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 160 valid_RMSELoss: tensor(0.0006, device='cuda:0') \n",
      "\n",
      "Epoch: 165 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 165 valid_RMSELoss: tensor(0.0006, device='cuda:0') \n",
      "\n",
      "Epoch: 170 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 170 valid_RMSELoss: tensor(0.0006, device='cuda:0') \n",
      "\n",
      "Epoch: 175 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 175 valid_RMSELoss: tensor(0.0006, device='cuda:0') \n",
      "\n",
      "Epoch: 180 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 180 valid_RMSELoss: tensor(0.0006, device='cuda:0') \n",
      "\n",
      "Epoch: 185 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 185 valid_RMSELoss: tensor(0.0006, device='cuda:0') \n",
      "\n",
      "Epoch: 190 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 190 valid_RMSELoss: tensor(0.0006, device='cuda:0') \n",
      "\n",
      "Epoch: 195 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 195 valid_RMSELoss: tensor(0.0006, device='cuda:0') \n",
      "\n",
      "Epoch: 200 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 200 valid_RMSELoss: tensor(0.0006, device='cuda:0') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tests=[]\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "for i in range(5):\n",
    "    test_result,_=train(seed=i,device=device)\n",
    "    tests.append(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1e8c3bae3ef48291",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T11:03:46.475508Z",
     "start_time": "2025-03-20T11:03:46.462915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 0.05466666666666666\n"
     ]
    }
   ],
   "source": [
    "def calculate_mae(actual, predicted):\n",
    "    \"\"\"\n",
    "    计算两个序列的MAE（平均绝对误差）\n",
    "    \n",
    "    参数:\n",
    "    actual (list or numpy array): 实际值序列\n",
    "    predicted (list or numpy array): 预测值序列\n",
    "    \n",
    "    返回:\n",
    "    float: MAE值\n",
    "    \"\"\"\n",
    "    # 确保输入序列长度一致\n",
    "    if len(actual) != len(predicted):\n",
    "        raise ValueError(\"实际值序列和预测值序列长度必须一致\")\n",
    "    \n",
    "    # 计算绝对误差\n",
    "    absolute_errors = [abs(a - p) for a, p in zip(actual, predicted)]\n",
    "    \n",
    "    # 计算平均绝对误差\n",
    "    mae = sum(absolute_errors) / len(actual)\n",
    "    \n",
    "    return mae\n",
    "def mape(sequence_true, sequence_pred):\n",
    "    \"\"\"\n",
    "    计算两个序列的MAPE（Mean Absolute Percentage Error）\n",
    "\n",
    "    参数:\n",
    "    sequence_true: 实际值序列\n",
    "    sequence_pred: 预测值序列\n",
    "\n",
    "    返回:\n",
    "    mape: 平均绝对百分比误差\n",
    "    \"\"\"\n",
    "    if len(sequence_true) != len(sequence_pred):\n",
    "        raise ValueError(\"两个序列的长度必须相同\")\n",
    "\n",
    "    # 计算绝对百分比误差\n",
    "    ape = [abs((true - pred) / true) for true, pred in zip(sequence_true, sequence_pred) if true != 0]\n",
    "\n",
    "    # 计算平均绝对百分比误差\n",
    "    mape = sum(ape) / len(ape)\n",
    "\n",
    "    return mape\n",
    "\n",
    "# 示例使用\n",
    "sequence_true = [100, 200, 300, 400, 500]\n",
    "sequence_pred = [90, 210, 310, 380, 480]\n",
    "print(\"MAPE:\", mape(sequence_true, sequence_pred))\n",
    "def r_squared(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    计算两个序列的R方（R-squared）\n",
    "\n",
    "    参数:\n",
    "    y_true: 实际值序列\n",
    "    y_pred: 预测值序列\n",
    "\n",
    "    返回:\n",
    "    r2: R方值\n",
    "    \"\"\"\n",
    "    # 计算实际值的平均值\n",
    "    y_mean = sum(y_true) / len(y_true)\n",
    "    \n",
    "    # 计算总平方和（Total Sum of Squares, TSS）\n",
    "    ss_total = sum((y_true - y_mean) ** 2)\n",
    "    \n",
    "    # 计算回归平方和（Regression Sum of Squares, RSS）\n",
    "    ss_residual = sum((y_true - y_pred) ** 2)\n",
    "    \n",
    "    # 计算R方\n",
    "    r2 = 1 - (ss_residual / ss_total)\n",
    "    \n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "61c15df4631cf951",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T11:04:07.430722Z",
     "start_time": "2025-03-20T11:04:07.406049Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: [0.009035501213406948, 0.009203396028787825, 0.011884223302984255, 0.010538888236915497, 0.0038347635417812507, 0.005108984410698255, 0.019858782420318084, 0.01739257866776374]\n",
      "test: [0.9620776, 0.9620893, 0.96225613, 0.9624123, 0.96188647, 0.96027964, 0.9565991, 0.95277315, 0.94887537, 0.94487256, 0.9408409, 0.9368008, 0.9327764, 0.9287266, 0.92463714, 0.92060894, 0.9165837, 0.9125674, 0.90857, 0.90457696, 0.9005371, 0.8965587, 0.8925211, 0.88856477, 0.8845709, 0.8805106, 0.8765778, 0.87259907, 0.86853784, 0.8645172, 0.86055464, 0.8564843, 0.85245967, 0.8484803, 0.844546, 0.840756, 0.8370822, 0.83336943, 0.8297266, 0.8258897, 0.8221585, 0.8183448, 0.814575, 0.8108339, 0.80706435, 0.8041478, 0.8021347, 0.80099684, 0.80020636, 0.79998845, 0.79991025, 0.79986715, 0.7998282, 0.79978675, 0.7997536, 0.7997234, 0.79968786, 0.79965955, 0.79963714, 0.79961604, 0.96206087, 0.96208376, 0.9622396, 0.96239984, 0.9618735, 0.9602409, 0.9565419, 0.9527113, 0.94884914, 0.94479936, 0.94079965, 0.9367765, 0.93269676, 0.9287025, 0.924642, 0.92061335, 0.9166096, 0.9125563, 0.90858406, 0.9045532, 0.9005788, 0.8965276, 0.89257675, 0.8886058, 0.8845534, 0.8806022, 0.8766137, 0.8725385, 0.86860746, 0.86459154, 0.8606027, 0.8565284, 0.85249096, 0.8485146, 0.84456813, 0.8407743, 0.83711565, 0.83341795, 0.82975465, 0.8259419, 0.8222, 0.8184522, 0.8146411, 0.81088924, 0.8070841, 0.804156, 0.8021396, 0.80099726, 0.8002064, 0.79998845, 0.79991025, 0.7998703, 0.79982984, 0.7997882, 0.79975635, 0.7997242, 0.7996866, 0.7996598, 0.7996387, 0.79961413, 0.97097504, 0.96704346, 0.96518123, 0.96150976, 0.9584751, 0.9547375, 0.9523765, 0.9496751, 0.945577, 0.9431007, 0.9396023, 0.9356976, 0.9324177, 0.9280982, 0.92195433, 0.9185524, 0.91532695, 0.9122561, 0.90999556, 0.90704274, 0.90179825, 0.8993548, 0.8942485, 0.8928424, 0.88974935, 0.883662, 0.8832963, 0.8808013, 0.8746631, 0.8703255, 0.8691953, 0.86384773, 0.86064374, 0.85950136, 0.85665387, 0.85101587, 0.8486718, 0.8433094, 0.84253174, 0.8341884, 0.8326272, 0.8256403, 0.82152236, 0.8195659, 0.8114626, 0.8123387, 0.80867326, 0.8019443, 0.80333114, 0.80287635, 0.8020399, 0.80157816, 0.80125415, 0.80161643, 0.80282307, 0.80393595, 0.80469775, 0.8060113, 0.8071556, 0.808134, 0.96836233, 0.96611977, 0.9624115, 0.9593879, 0.9572208, 0.9523362, 0.94968307, 0.9468491, 0.9443393, 0.93993115, 0.9377812, 0.9346076, 0.9289229, 0.92709017, 0.9221711, 0.91880643, 0.916404, 0.9117062, 0.9105603, 0.90590566, 0.9037876, 0.8979478, 0.89682364, 0.89468294, 0.88895077, 0.8877426, 0.8848667, 0.8781175, 0.87780416, 0.8736599, 0.8713573, 0.8657957, 0.86207324, 0.8610362, 0.85777485, 0.8522213, 0.8508705, 0.84649634, 0.8443166, 0.83753777, 0.8352346, 0.83254, 0.82578164, 0.82279766, 0.8127951, 0.8134819, 0.8113723, 0.8030399, 0.803856, 0.8028284, 0.8020092, 0.8027191, 0.80173486, 0.8017599, 0.80308205, 0.8040184, 0.80461097, 0.80603236, 0.8072758, 0.80798376, 0.97457993, 0.9718658, 0.96938276, 0.9663085, 0.9634075, 0.9597568, 0.9562609, 0.95262843, 0.94838816, 0.9448222, 0.9408319, 0.9366674, 0.93276376, 0.9284243, 0.92330855, 0.9191936, 0.9150091, 0.91089267, 0.90714025, 0.90307045, 0.8979618, 0.8941143, 0.8890694, 0.8858514, 0.882361, 0.8778807, 0.8754931, 0.8723237, 0.8678246, 0.86398286, 0.8613152, 0.8571051, 0.8536872, 0.85105217, 0.8477998, 0.84398186, 0.8411233, 0.8373553, 0.8345707, 0.82864887, 0.8251468, 0.8197084, 0.81529504, 0.8115333, 0.8053517, 0.80267334, 0.79826397, 0.7927298, 0.7906663, 0.78894645, 0.7874473, 0.78615505, 0.7852137, 0.7847063, 0.78424364, 0.783963, 0.7838045, 0.78361386, 0.7834794, 0.7833843, 0.9736654, 0.9715715, 0.96849936, 0.9656305, 0.9629434, 0.95873946, 0.95511955, 0.9514342, 0.9478601, 0.9434842, 0.94006103, 0.936205, 0.93128586, 0.9280008, 0.9234004, 0.91931164, 0.9154917, 0.9106414, 0.9073915, 0.9025554, 0.8988632, 0.89348096, 0.89023167, 0.8865569, 0.88206846, 0.8793718, 0.87606543, 0.87134355, 0.8689739, 0.8652023, 0.86210686, 0.8578169, 0.8542046, 0.8516063, 0.84820503, 0.8443102, 0.8417207, 0.8382525, 0.83520365, 0.8298426, 0.82607347, 0.82216746, 0.8168135, 0.81279296, 0.8058638, 0.80311555, 0.7992975, 0.7931153, 0.79072624, 0.7889562, 0.7874536, 0.7859645, 0.7851512, 0.7846672, 0.7841998, 0.78395295, 0.7838153, 0.7836117, 0.78346974, 0.7833974, 0.9582839, 0.9586524, 0.9589164, 0.9587331, 0.95849824, 0.95764077, 0.95569515, 0.9527564, 0.9492248, 0.94550025, 0.94175816, 0.9379772, 0.93418086, 0.9303824, 0.9265803, 0.92278373, 0.9189874, 0.9151914, 0.9113971, 0.9076015, 0.9038011, 0.9000064, 0.89620626, 0.89241374, 0.8887447, 0.8854238, 0.8823278, 0.87939847, 0.8764925, 0.8735895, 0.87069154, 0.8677871, 0.8648859, 0.8619697, 0.8589933, 0.8560711, 0.8535013, 0.8511249, 0.8487619, 0.84639215, 0.844025, 0.84165347, 0.8392811, 0.83690906, 0.83453083, 0.83216155, 0.8297876, 0.8274108, 0.8250767, 0.8228121, 0.8211745, 0.8197479, 0.8185444, 0.8175081, 0.8165916, 0.8157308, 0.814962, 0.81431854, 0.81373644, 0.81321764, 0.95828414, 0.9586524, 0.9589156, 0.9587326, 0.9584979, 0.95763886, 0.9556918, 0.95275104, 0.94922256, 0.9454938, 0.9417546, 0.93797505, 0.9341738, 0.93038034, 0.92658067, 0.9227841, 0.91898966, 0.91519034, 0.9113983, 0.9075992, 0.903805, 0.90000355, 0.8962115, 0.8924173, 0.88874316, 0.8854308, 0.8823303, 0.8793943, 0.87649727, 0.87359464, 0.87069476, 0.86779, 0.86488795, 0.8619721, 0.85899496, 0.8560723, 0.85350335, 0.8511276, 0.84876347, 0.84639513, 0.8440274, 0.84165967, 0.8392849, 0.8369123, 0.83453214, 0.8321626, 0.82979035, 0.8274119, 0.8250772, 0.82281196, 0.8211744, 0.8197495, 0.8185451, 0.8175087, 0.8165926, 0.81573105, 0.8149617, 0.81431854, 0.8137368, 0.8132173]\n",
      "real: [0.981547760081002, 0.9783191107815529, 0.9720577829193665, 0.9677396187742875, 0.9637116538750307, 0.9613671533599215, 0.9566656962781115, 0.953212542304319, 0.9498307232149187, 0.9465717478639696, 0.9431893727029631, 0.9396172370027812, 0.9360453538976621, 0.9291805798075792, 0.9209527681953381, 0.9169270262172543, 0.9128542038766607, 0.9088717651351773, 0.9047587318552943, 0.9009867628597049, 0.8975242670665129, 0.89356647886204, 0.889644455237089, 0.886559405548693, 0.882733673476862, 0.8783059377512253, 0.8755645180191589, 0.8720300673473934, 0.8677529298076447, 0.859049156094731, 0.8569053494588545, 0.8518659950843436, 0.8502900122036473, 0.8480130356323287, 0.8446500805166606, 0.841138508684198, 0.8389571854909209, 0.8353695575997965, 0.8323632134517919, 0.828285810677856, 0.8255674607740809, 0.8199044530181538, 0.8132637498839883, 0.8102378979509867, 0.8072248070938493, 0.8059270278970738, 0.8029878307438708, 0.7989619033515942, 0.7983664753623245, 0.795802133196813, 0.7929682964599739, 0.7898693760651792, 0.787094046764988, 0.7830793400015471, 0.7820526502569298, 0.7795097506490353, 0.7759194636010017, 0.7754683610116903, 0.7730019872724594, 0.7737297038317591, 0.9789170845010232, 0.9723672398307521, 0.9678773262663203, 0.9636427140275626, 0.9632185045488699, 0.9580565260869475, 0.9547662648076788, 0.9517189050078657, 0.9486765256146883, 0.9457208157871942, 0.9427227872812818, 0.9399386291466334, 0.9349932513640985, 0.9288261894143705, 0.9254616695294128, 0.9221886563805027, 0.9188509699068458, 0.915816124993008, 0.9126536853065345, 0.9084989643628255, 0.9045647794981047, 0.9001612571956726, 0.8968866389327226, 0.8929720540671963, 0.8882457041155193, 0.8853800684167759, 0.8817096842753251, 0.8775402352158715, 0.8748208528209546, 0.8690810995476573, 0.8664810011514761, 0.8584888288239728, 0.858485841898706, 0.8559350369552029, 0.8523736538708621, 0.8479998113360429, 0.8457039847828337, 0.8419061496798198, 0.8385197021325397, 0.8343807998896714, 0.8321302164642305, 0.8257754683189632, 0.8190368263008624, 0.8156278584531853, 0.8108817253184123, 0.8097847912294613, 0.8066945905966949, 0.8016366439768062, 0.8009507504538506, 0.7978916242141426, 0.7951029470395748, 0.7918041093370152, 0.7888178498047248, 0.7839453521484476, 0.7835187764569512, 0.7806061992059281, 0.7751915070668952, 0.776400843070294, 0.7736816546951972, 0.7739719787425552, 0.981547760081002, 0.9783191107815529, 0.9720577829193665, 0.9677396187742875, 0.9637116538750307, 0.9613671533599215, 0.9566656962781115, 0.953212542304319, 0.9498307232149187, 0.9465717478639696, 0.9431893727029631, 0.9396172370027812, 0.9360453538976621, 0.9291805798075792, 0.9209527681953381, 0.9169270262172543, 0.9128542038766607, 0.9088717651351773, 0.9047587318552943, 0.9009867628597049, 0.8975242670665129, 0.89356647886204, 0.889644455237089, 0.886559405548693, 0.882733673476862, 0.8783059377512253, 0.8755645180191589, 0.8720300673473934, 0.8677529298076447, 0.859049156094731, 0.8569053494588545, 0.8518659950843436, 0.8502900122036473, 0.8480130356323287, 0.8446500805166606, 0.841138508684198, 0.8389571854909209, 0.8353695575997965, 0.8323632134517919, 0.828285810677856, 0.8255674607740809, 0.8199044530181538, 0.8132637498839883, 0.8102378979509867, 0.8072248070938493, 0.8059270278970738, 0.8029878307438708, 0.7989619033515942, 0.7983664753623245, 0.795802133196813, 0.7929682964599739, 0.7898693760651792, 0.787094046764988, 0.7830793400015471, 0.7820526502569298, 0.7795097506490353, 0.7759194636010017, 0.7754683610116903, 0.7730019872724594, 0.7737297038317591, 0.9789170845010232, 0.9723672398307521, 0.9678773262663203, 0.9636427140275626, 0.9632185045488699, 0.9580565260869475, 0.9547662648076788, 0.9517189050078657, 0.9486765256146883, 0.9457208157871942, 0.9427227872812818, 0.9399386291466334, 0.9349932513640985, 0.9288261894143705, 0.9254616695294128, 0.9221886563805027, 0.9188509699068458, 0.915816124993008, 0.9126536853065345, 0.9084989643628255, 0.9045647794981047, 0.9001612571956726, 0.8968866389327226, 0.8929720540671963, 0.8882457041155193, 0.8853800684167759, 0.8817096842753251, 0.8775402352158715, 0.8748208528209546, 0.8690810995476573, 0.8664810011514761, 0.8584888288239728, 0.858485841898706, 0.8559350369552029, 0.8523736538708621, 0.8479998113360429, 0.8457039847828337, 0.8419061496798198, 0.8385197021325397, 0.8343807998896714, 0.8321302164642305, 0.8257754683189632, 0.8190368263008624, 0.8156278584531853, 0.8108817253184123, 0.8097847912294613, 0.8066945905966949, 0.8016366439768062, 0.8009507504538506, 0.7978916242141426, 0.7951029470395748, 0.7918041093370152, 0.7888178498047248, 0.7839453521484476, 0.7835187764569512, 0.7806061992059281, 0.7751915070668952, 0.776400843070294, 0.7736816546951972, 0.7739719787425552, 0.981547760081002, 0.9783191107815529, 0.9720577829193665, 0.9677396187742875, 0.9637116538750307, 0.9613671533599215, 0.9566656962781115, 0.953212542304319, 0.9498307232149187, 0.9465717478639696, 0.9431893727029631, 0.9396172370027812, 0.9360453538976621, 0.9291805798075792, 0.9209527681953381, 0.9169270262172543, 0.9128542038766607, 0.9088717651351773, 0.9047587318552943, 0.9009867628597049, 0.8975242670665129, 0.89356647886204, 0.889644455237089, 0.886559405548693, 0.882733673476862, 0.8783059377512253, 0.8755645180191589, 0.8720300673473934, 0.8677529298076447, 0.859049156094731, 0.8569053494588545, 0.8518659950843436, 0.8502900122036473, 0.8480130356323287, 0.8446500805166606, 0.841138508684198, 0.8389571854909209, 0.8353695575997965, 0.8323632134517919, 0.828285810677856, 0.8255674607740809, 0.8199044530181538, 0.8132637498839883, 0.8102378979509867, 0.8072248070938493, 0.8059270278970738, 0.8029878307438708, 0.7989619033515942, 0.7983664753623245, 0.795802133196813, 0.7929682964599739, 0.7898693760651792, 0.787094046764988, 0.7830793400015471, 0.7820526502569298, 0.7795097506490353, 0.7759194636010017, 0.7754683610116903, 0.7730019872724594, 0.7737297038317591, 0.9789170845010232, 0.9723672398307521, 0.9678773262663203, 0.9636427140275626, 0.9632185045488699, 0.9580565260869475, 0.9547662648076788, 0.9517189050078657, 0.9486765256146883, 0.9457208157871942, 0.9427227872812818, 0.9399386291466334, 0.9349932513640985, 0.9288261894143705, 0.9254616695294128, 0.9221886563805027, 0.9188509699068458, 0.915816124993008, 0.9126536853065345, 0.9084989643628255, 0.9045647794981047, 0.9001612571956726, 0.8968866389327226, 0.8929720540671963, 0.8882457041155193, 0.8853800684167759, 0.8817096842753251, 0.8775402352158715, 0.8748208528209546, 0.8690810995476573, 0.8664810011514761, 0.8584888288239728, 0.858485841898706, 0.8559350369552029, 0.8523736538708621, 0.8479998113360429, 0.8457039847828337, 0.8419061496798198, 0.8385197021325397, 0.8343807998896714, 0.8321302164642305, 0.8257754683189632, 0.8190368263008624, 0.8156278584531853, 0.8108817253184123, 0.8097847912294613, 0.8066945905966949, 0.8016366439768062, 0.8009507504538506, 0.7978916242141426, 0.7951029470395748, 0.7918041093370152, 0.7888178498047248, 0.7839453521484476, 0.7835187764569512, 0.7806061992059281, 0.7751915070668952, 0.776400843070294, 0.7736816546951972, 0.7739719787425552, 0.981547760081002, 0.9783191107815529, 0.9720577829193665, 0.9677396187742875, 0.9637116538750307, 0.9613671533599215, 0.9566656962781115, 0.953212542304319, 0.9498307232149187, 0.9465717478639696, 0.9431893727029631, 0.9396172370027812, 0.9360453538976621, 0.9291805798075792, 0.9209527681953381, 0.9169270262172543, 0.9128542038766607, 0.9088717651351773, 0.9047587318552943, 0.9009867628597049, 0.8975242670665129, 0.89356647886204, 0.889644455237089, 0.886559405548693, 0.882733673476862, 0.8783059377512253, 0.8755645180191589, 0.8720300673473934, 0.8677529298076447, 0.859049156094731, 0.8569053494588545, 0.8518659950843436, 0.8502900122036473, 0.8480130356323287, 0.8446500805166606, 0.841138508684198, 0.8389571854909209, 0.8353695575997965, 0.8323632134517919, 0.828285810677856, 0.8255674607740809, 0.8199044530181538, 0.8132637498839883, 0.8102378979509867, 0.8072248070938493, 0.8059270278970738, 0.8029878307438708, 0.7989619033515942, 0.7983664753623245, 0.795802133196813, 0.7929682964599739, 0.7898693760651792, 0.787094046764988, 0.7830793400015471, 0.7820526502569298, 0.7795097506490353, 0.7759194636010017, 0.7754683610116903, 0.7730019872724594, 0.7737297038317591, 0.9789170845010232, 0.9723672398307521, 0.9678773262663203, 0.9636427140275626, 0.9632185045488699, 0.9580565260869475, 0.9547662648076788, 0.9517189050078657, 0.9486765256146883, 0.9457208157871942, 0.9427227872812818, 0.9399386291466334, 0.9349932513640985, 0.9288261894143705, 0.9254616695294128, 0.9221886563805027, 0.9188509699068458, 0.915816124993008, 0.9126536853065345, 0.9084989643628255, 0.9045647794981047, 0.9001612571956726, 0.8968866389327226, 0.8929720540671963, 0.8882457041155193, 0.8853800684167759, 0.8817096842753251, 0.8775402352158715, 0.8748208528209546, 0.8690810995476573, 0.8664810011514761, 0.8584888288239728, 0.858485841898706, 0.8559350369552029, 0.8523736538708621, 0.8479998113360429, 0.8457039847828337, 0.8419061496798198, 0.8385197021325397, 0.8343807998896714, 0.8321302164642305, 0.8257754683189632, 0.8190368263008624, 0.8156278584531853, 0.8108817253184123, 0.8097847912294613, 0.8066945905966949, 0.8016366439768062, 0.8009507504538506, 0.7978916242141426, 0.7951029470395748, 0.7918041093370152, 0.7888178498047248, 0.7839453521484476, 0.7835187764569512, 0.7806061992059281, 0.7751915070668952, 0.776400843070294, 0.7736816546951972, 0.7739719787425552]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_all=[]\n",
    "mae_all=[]\n",
    "mape_all=[]\n",
    "r2=[]\n",
    "num=0\n",
    "test_csv_p=[]\n",
    "real_csv_p=[]\n",
    "for i in range(4):\n",
    "    for j in range(len(tests[0])):\n",
    "        real,pred=tests[i][j][0],tests[i][j][1].reshape(-1)\n",
    "        rmse=evaluation(real,pred)\n",
    "        if rmse>=0.00:\n",
    "            rmse_all.append(rmse)\n",
    "            for pre,rea in zip(pred,real):\n",
    "                test_csv_p.append(pre)\n",
    "                real_csv_p.append(rea)\n",
    "        mae_all.append(calculate_mae(real,pred))\n",
    "        mape_all.append(mape(real,pred))\n",
    "        r2.append(r_squared(real,pred))\n",
    "        num+=1\n",
    "print(\"RMSE:\",rmse_all)\n",
    "print(\"test:\",test_csv_p)\n",
    "print('real:',real_csv_p)\n",
    "len(test_csv_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ea986337148414",
   "metadata": {},
   "source": [
    "## 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da6f2989d8f7ac21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T02:53:39.934343Z",
     "start_time": "2025-03-20T02:53:39.920516Z"
    }
   },
   "outputs": [],
   "source": [
    "# rmse_all=0\n",
    "# mae_all=0\n",
    "# num=0\n",
    "# for i in range(len(tests)):\n",
    "#     for j in range(len(tests[0])):\n",
    "#         real,pred=tests[i][j][0],tests[i][j][1]\n",
    "#         rmse=evaluation(real,pred)\n",
    "#         rmse_all+=(rmse)\n",
    "#         mae_all+=calculate_mae(real,pred)\n",
    "#         num+=1\n",
    "# print('RMSE:',[rmse_all/num])\n",
    "# print('MAE:',mae_all/num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "391f385c610660e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T00:47:46.292777Z",
     "start_time": "2025-03-31T00:47:19.434174Z"
    }
   },
   "outputs": [],
   "source": [
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# test_results,lists=train(seed=0,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe649e148ccd599e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T00:50:20.711716Z",
     "start_time": "2025-03-31T00:50:20.691455Z"
    }
   },
   "outputs": [],
   "source": [
    "reals=[]\n",
    "preds=[]\n",
    "for i in range(2):\n",
    "    real,pred=test_results[i][0],test_results[i][1]\n",
    "    reals.append(real)\n",
    "    preds.append(pred)\n",
    "reals=np.concatenate(reals,axis=0)\n",
    "preds=np.concatenate(preds,axis=0).squeeze()\n",
    "path='D:/Pywork/CNN_ATTENTION_PINN/new/results/preds/oxford.npz'\n",
    "np.savez(path,reals=reals,preds=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f67b9c8a0abe9ba5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T02:46:09.204705Z",
     "start_time": "2025-03-20T02:46:09.194693Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003178889350747312\n",
      "0.004840268991179267\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    real,pred=test_results[i][0],test_results[i][1]\n",
    "    rmse=evaluation(real,pred)\n",
    "    print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3e4fb2ae5c569a6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T11:04:53.946070Z",
     "start_time": "2025-03-20T11:04:53.921583Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size=7, output_size=1):\n",
    "        super(MLP, self).__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(input_size, 32),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(32, 64),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(64, 128),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(128, 256),\n",
    "                                 nn.Linear(256, 512),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(512, 128),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(128, 64),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(64, output_size))\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "def train_mlp(lr=0.001,epochs=200, weight_decay=1e-4, seed=0, metric='rmse', device='cpu'):\n",
    "    \"\"\"function for train\"\"\"\n",
    "    setup_seed(seed)\n",
    "    print(\"training seed \"+str(seed)+':\\n')\n",
    "    train_loader, val_loader, test_35_data, test_36_data=get_data()\n",
    "    test_data=[test_35_data, test_36_data]\n",
    "    model = MLP()\n",
    "    model=model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.MSELoss()\n",
    "    len_dataloader = len(train_loader)\n",
    "    test_results=[]\n",
    "    \"\"\"早停止获取最佳模型\"\"\"\n",
    "    val_mse=10\n",
    "    for epoch in range(epochs):\n",
    "        loss_epoch=0\n",
    "        for X,y in train_loader:\n",
    "            X,y = X.to(device), y.to(device)\n",
    "            y_pred= model(X)\n",
    "            y_pred = y_pred.squeeze(1)\n",
    "            loss = criterion(y_pred,y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_epoch += loss\n",
    "        if (epoch+1)%5==0 and epoch!=0:\n",
    "            print('Epoch:',epoch+1,'Train_RMSELoss:',loss_epoch/len_dataloader,'\\n')\n",
    "        if (epoch+1)%5==0 and epoch!=0:\n",
    "            val_loss=0\n",
    "            for val_x,val_y in val_loader:\n",
    "                val_x,val_y=val_x.to(device),val_y.to(device)\n",
    "                pre=model(val_x)\n",
    "                val_loss+=criterion(pre.squeeze(1),val_y).detach()    \n",
    "            print('Epoch:',epoch+1,'valid_RMSELoss:',val_loss/len(val_loader),'\\n')\n",
    "            val_mse=val_loss/len(val_loader)\n",
    "                \n",
    "        if (val_mse<1e-3 and epoch>=35)or (epoch+1)==epochs:\n",
    "            model=model.cpu()\n",
    "            for name in test_data:\n",
    "                X=torch.from_numpy(name[0]).float()\n",
    "                y=name[1]\n",
    "                y_pred=model(X)\n",
    "                y_pred= y_pred.squeeze(0).detach().numpy()\n",
    "                test_results.append([y,y_pred])\n",
    "            break\n",
    "    return test_results\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a751d70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T11:05:00.204937Z",
     "start_time": "2025-03-20T11:04:58.521784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training seed 0:\n",
      "\n",
      "Epoch: 5 Train_RMSELoss: tensor(0.1899, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 5 valid_RMSELoss: tensor(0.2229, device='cuda:0') \n",
      "\n",
      "Epoch: 10 Train_RMSELoss: tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 10 valid_RMSELoss: tensor(0.1424, device='cuda:0') \n",
      "\n",
      "Epoch: 15 Train_RMSELoss: tensor(0.0758, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 15 valid_RMSELoss: tensor(0.0617, device='cuda:0') \n",
      "\n",
      "Epoch: 20 Train_RMSELoss: tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 20 valid_RMSELoss: tensor(0.0080, device='cuda:0') \n",
      "\n",
      "Epoch: 25 Train_RMSELoss: tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 25 valid_RMSELoss: tensor(0.0030, device='cuda:0') \n",
      "\n",
      "Epoch: 30 Train_RMSELoss: tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 30 valid_RMSELoss: tensor(0.0027, device='cuda:0') \n",
      "\n",
      "Epoch: 35 Train_RMSELoss: tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 35 valid_RMSELoss: tensor(0.0015, device='cuda:0') \n",
      "\n",
      "Epoch: 40 Train_RMSELoss: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 40 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "training seed 1:\n",
      "\n",
      "Epoch: 5 Train_RMSELoss: tensor(0.2266, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 5 valid_RMSELoss: tensor(0.1544, device='cuda:0') \n",
      "\n",
      "Epoch: 10 Train_RMSELoss: tensor(0.1089, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 10 valid_RMSELoss: tensor(0.0856, device='cuda:0') \n",
      "\n",
      "Epoch: 15 Train_RMSELoss: tensor(0.0098, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 15 valid_RMSELoss: tensor(0.0070, device='cuda:0') \n",
      "\n",
      "Epoch: 20 Train_RMSELoss: tensor(0.0027, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 20 valid_RMSELoss: tensor(0.0078, device='cuda:0') \n",
      "\n",
      "Epoch: 25 Train_RMSELoss: tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 25 valid_RMSELoss: tensor(0.0014, device='cuda:0') \n",
      "\n",
      "Epoch: 30 Train_RMSELoss: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 30 valid_RMSELoss: tensor(0.0005, device='cuda:0') \n",
      "\n",
      "Epoch: 35 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 35 valid_RMSELoss: tensor(0.0005, device='cuda:0') \n",
      "\n",
      "training seed 2:\n",
      "\n",
      "Epoch: 5 Train_RMSELoss: tensor(0.4812, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 5 valid_RMSELoss: tensor(0.6849, device='cuda:0') \n",
      "\n",
      "Epoch: 10 Train_RMSELoss: tensor(0.1908, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 10 valid_RMSELoss: tensor(0.4046, device='cuda:0') \n",
      "\n",
      "Epoch: 15 Train_RMSELoss: tensor(0.0469, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 15 valid_RMSELoss: tensor(0.1320, device='cuda:0') \n",
      "\n",
      "Epoch: 20 Train_RMSELoss: tensor(0.0475, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 20 valid_RMSELoss: tensor(0.0120, device='cuda:0') \n",
      "\n",
      "Epoch: 25 Train_RMSELoss: tensor(0.0258, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 25 valid_RMSELoss: tensor(0.0368, device='cuda:0') \n",
      "\n",
      "Epoch: 30 Train_RMSELoss: tensor(0.0092, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 30 valid_RMSELoss: tensor(0.0057, device='cuda:0') \n",
      "\n",
      "Epoch: 35 Train_RMSELoss: tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 35 valid_RMSELoss: tensor(0.0010, device='cuda:0') \n",
      "\n",
      "training seed 3:\n",
      "\n",
      "Epoch: 5 Train_RMSELoss: tensor(0.2208, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 5 valid_RMSELoss: tensor(0.2131, device='cuda:0') \n",
      "\n",
      "Epoch: 10 Train_RMSELoss: tensor(0.1472, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 10 valid_RMSELoss: tensor(0.1846, device='cuda:0') \n",
      "\n",
      "Epoch: 15 Train_RMSELoss: tensor(0.0928, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 15 valid_RMSELoss: tensor(0.1222, device='cuda:0') \n",
      "\n",
      "Epoch: 20 Train_RMSELoss: tensor(0.0370, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 20 valid_RMSELoss: tensor(0.0455, device='cuda:0') \n",
      "\n",
      "Epoch: 25 Train_RMSELoss: tensor(0.0058, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 25 valid_RMSELoss: tensor(0.0092, device='cuda:0') \n",
      "\n",
      "Epoch: 30 Train_RMSELoss: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 30 valid_RMSELoss: tensor(0.0090, device='cuda:0') \n",
      "\n",
      "Epoch: 35 Train_RMSELoss: tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 35 valid_RMSELoss: tensor(0.0048, device='cuda:0') \n",
      "\n",
      "Epoch: 40 Train_RMSELoss: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 40 valid_RMSELoss: tensor(0.0022, device='cuda:0') \n",
      "\n",
      "Epoch: 45 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 45 valid_RMSELoss: tensor(0.0027, device='cuda:0') \n",
      "\n",
      "Epoch: 50 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 50 valid_RMSELoss: tensor(0.0022, device='cuda:0') \n",
      "\n",
      "Epoch: 55 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 55 valid_RMSELoss: tensor(0.0028, device='cuda:0') \n",
      "\n",
      "Epoch: 60 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 60 valid_RMSELoss: tensor(0.0022, device='cuda:0') \n",
      "\n",
      "Epoch: 65 Train_RMSELoss: tensor(8.5100e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 65 valid_RMSELoss: tensor(0.0022, device='cuda:0') \n",
      "\n",
      "Epoch: 70 Train_RMSELoss: tensor(7.5994e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 70 valid_RMSELoss: tensor(0.0021, device='cuda:0') \n",
      "\n",
      "Epoch: 75 Train_RMSELoss: tensor(7.7221e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 75 valid_RMSELoss: tensor(0.0022, device='cuda:0') \n",
      "\n",
      "Epoch: 80 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 80 valid_RMSELoss: tensor(0.0021, device='cuda:0') \n",
      "\n",
      "Epoch: 85 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 85 valid_RMSELoss: tensor(0.0024, device='cuda:0') \n",
      "\n",
      "Epoch: 90 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 90 valid_RMSELoss: tensor(0.0024, device='cuda:0') \n",
      "\n",
      "Epoch: 95 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 95 valid_RMSELoss: tensor(0.0027, device='cuda:0') \n",
      "\n",
      "Epoch: 100 Train_RMSELoss: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 100 valid_RMSELoss: tensor(0.0027, device='cuda:0') \n",
      "\n",
      "Epoch: 105 Train_RMSELoss: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 105 valid_RMSELoss: tensor(0.0023, device='cuda:0') \n",
      "\n",
      "Epoch: 110 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 110 valid_RMSELoss: tensor(0.0021, device='cuda:0') \n",
      "\n",
      "Epoch: 115 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 115 valid_RMSELoss: tensor(0.0022, device='cuda:0') \n",
      "\n",
      "Epoch: 120 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 120 valid_RMSELoss: tensor(0.0024, device='cuda:0') \n",
      "\n",
      "Epoch: 125 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 125 valid_RMSELoss: tensor(0.0019, device='cuda:0') \n",
      "\n",
      "Epoch: 130 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 130 valid_RMSELoss: tensor(0.0020, device='cuda:0') \n",
      "\n",
      "Epoch: 135 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 135 valid_RMSELoss: tensor(0.0020, device='cuda:0') \n",
      "\n",
      "Epoch: 140 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 140 valid_RMSELoss: tensor(0.0024, device='cuda:0') \n",
      "\n",
      "Epoch: 145 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 145 valid_RMSELoss: tensor(0.0020, device='cuda:0') \n",
      "\n",
      "Epoch: 150 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 150 valid_RMSELoss: tensor(0.0022, device='cuda:0') \n",
      "\n",
      "Epoch: 155 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 155 valid_RMSELoss: tensor(0.0025, device='cuda:0') \n",
      "\n",
      "Epoch: 160 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 160 valid_RMSELoss: tensor(0.0021, device='cuda:0') \n",
      "\n",
      "Epoch: 165 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 165 valid_RMSELoss: tensor(0.0022, device='cuda:0') \n",
      "\n",
      "Epoch: 170 Train_RMSELoss: tensor(7.0260e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 170 valid_RMSELoss: tensor(0.0020, device='cuda:0') \n",
      "\n",
      "Epoch: 175 Train_RMSELoss: tensor(7.4515e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 175 valid_RMSELoss: tensor(0.0019, device='cuda:0') \n",
      "\n",
      "Epoch: 180 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 180 valid_RMSELoss: tensor(0.0021, device='cuda:0') \n",
      "\n",
      "Epoch: 185 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 185 valid_RMSELoss: tensor(0.0019, device='cuda:0') \n",
      "\n",
      "Epoch: 190 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 190 valid_RMSELoss: tensor(0.0020, device='cuda:0') \n",
      "\n",
      "Epoch: 195 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 195 valid_RMSELoss: tensor(0.0020, device='cuda:0') \n",
      "\n",
      "Epoch: 200 Train_RMSELoss: tensor(6.5972e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 200 valid_RMSELoss: tensor(0.0019, device='cuda:0') \n",
      "\n",
      "training seed 4:\n",
      "\n",
      "Epoch: 5 Train_RMSELoss: tensor(0.2585, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 5 valid_RMSELoss: tensor(0.1902, device='cuda:0') \n",
      "\n",
      "Epoch: 10 Train_RMSELoss: tensor(0.0926, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 10 valid_RMSELoss: tensor(0.0658, device='cuda:0') \n",
      "\n",
      "Epoch: 15 Train_RMSELoss: tensor(0.0286, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 15 valid_RMSELoss: tensor(0.0147, device='cuda:0') \n",
      "\n",
      "Epoch: 20 Train_RMSELoss: tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 20 valid_RMSELoss: tensor(0.0205, device='cuda:0') \n",
      "\n",
      "Epoch: 25 Train_RMSELoss: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 25 valid_RMSELoss: tensor(0.0010, device='cuda:0') \n",
      "\n",
      "Epoch: 30 Train_RMSELoss: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 30 valid_RMSELoss: tensor(0.0013, device='cuda:0') \n",
      "\n",
      "Epoch: 35 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 35 valid_RMSELoss: tensor(0.0005, device='cuda:0') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tests_mlp=[]\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "for i in range(5):\n",
    "    test_result=train_mlp(seed=i,device=device)\n",
    "    tests_mlp.append(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "57f001b0aef9beb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T11:05:12.792277Z",
     "start_time": "2025-03-20T11:05:12.778409Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: [0.015028644268036833, 0.016278189828070704, 0.015725252489676884, 0.01612228968467474, 0.052856361685286235, 0.05595200003216431, 0.037785624352166064, 0.03758387782330728]\n",
      "test: [0.9291835, 0.95185655, 0.9720506, 0.9725435, 0.9674511, 0.96341425, 0.95984614, 0.9539886, 0.945285, 0.9380253, 0.93213636, 0.92642885, 0.92029464, 0.9132666, 0.9035521, 0.8997174, 0.8964899, 0.8933232, 0.8919011, 0.88959056, 0.8843347, 0.88258886, 0.8775242, 0.8771587, 0.8747558, 0.86855555, 0.86943644, 0.86740416, 0.861079, 0.85685647, 0.85666126, 0.85127115, 0.84842557, 0.8482527, 0.8455587, 0.8413082, 0.8403632, 0.83664966, 0.8372312, 0.8305116, 0.83033305, 0.82492095, 0.8223739, 0.8215262, 0.8144943, 0.81631935, 0.81390846, 0.8083315, 0.81097966, 0.8097146, 0.80774575, 0.8068506, 0.8057174, 0.80222744, 0.8042924, 0.8057724, 0.8022147, 0.8050204, 0.80610543, 0.8034734, 0.92639476, 0.95099413, 0.96940345, 0.969689, 0.96546686, 0.96003723, 0.95549864, 0.95075434, 0.9421753, 0.9350762, 0.92995465, 0.92477685, 0.9156096, 0.91227907, 0.9038691, 0.9003084, 0.89770037, 0.89243966, 0.8923755, 0.8879368, 0.887248, 0.88082355, 0.8809926, 0.87944835, 0.87372416, 0.8734898, 0.8711998, 0.8641882, 0.8650232, 0.8609832, 0.85942614, 0.8536226, 0.85034853, 0.8502003, 0.84725755, 0.84255767, 0.84250176, 0.8396246, 0.83874655, 0.8336578, 0.8326158, 0.8313734, 0.82638586, 0.82474, 0.81574744, 0.8175638, 0.81652373, 0.8094001, 0.8115367, 0.80982774, 0.8077696, 0.80972487, 0.80711716, 0.8035403, 0.8068768, 0.80653346, 0.80130285, 0.8053951, 0.807587, 0.80140275, 0.97620165, 0.9765311, 0.96392363, 0.94991434, 0.9483365, 0.94601274, 0.94548106, 0.94669664, 0.94603676, 0.94765115, 0.9449892, 0.940222, 0.93397486, 0.925838, 0.91609293, 0.91078365, 0.9066088, 0.90287226, 0.9002322, 0.8969618, 0.8910931, 0.8882185, 0.88212824, 0.88003767, 0.8759122, 0.868478, 0.86757874, 0.8656349, 0.8600639, 0.85641605, 0.8559497, 0.8512216, 0.8487054, 0.84815013, 0.8462521, 0.8424594, 0.8413237, 0.8379013, 0.83815306, 0.83386385, 0.8337166, 0.8302549, 0.8285541, 0.82798964, 0.8232472, 0.82447714, 0.8226936, 0.81888324, 0.82047457, 0.81934464, 0.8173008, 0.8159249, 0.8141482, 0.81056345, 0.8116399, 0.8120922, 0.80922633, 0.81093323, 0.81160855, 0.80981255, 0.97302353, 0.97543544, 0.9605528, 0.9473084, 0.947147, 0.94352984, 0.9428996, 0.94394165, 0.94521, 0.9442169, 0.9429405, 0.939062, 0.92965627, 0.9243137, 0.9163561, 0.9106469, 0.90823674, 0.9026594, 0.9012997, 0.89612895, 0.8925639, 0.8866604, 0.88459927, 0.8821542, 0.8750989, 0.873315, 0.86964214, 0.8628057, 0.86319256, 0.8597859, 0.85806024, 0.8532413, 0.8500255, 0.84966946, 0.84710586, 0.8432721, 0.8429085, 0.8402748, 0.8393572, 0.8359092, 0.83530414, 0.83446264, 0.8311515, 0.8301434, 0.8241251, 0.8252414, 0.8244889, 0.8196132, 0.8208288, 0.81927115, 0.81725216, 0.81812924, 0.8152447, 0.81156456, 0.8134567, 0.8126644, 0.8085389, 0.81115, 0.81259465, 0.8084809, 0.9561302, 0.9544801, 0.95851606, 0.9559523, 0.9415943, 0.93002135, 0.9219131, 0.91949624, 0.92091715, 0.9246815, 0.923743, 0.9152261, 0.91056025, 0.9017202, 0.8904429, 0.8832178, 0.8754186, 0.8684314, 0.86316687, 0.8571608, 0.8486453, 0.8438341, 0.8349264, 0.8310117, 0.8244455, 0.81166923, 0.8093199, 0.80431294, 0.79165524, 0.78274244, 0.779378, 0.768377, 0.7629219, 0.7618084, 0.7599125, 0.75454324, 0.75362027, 0.74935454, 0.7507321, 0.7455837, 0.74720985, 0.7442232, 0.743977, 0.7458688, 0.74180156, 0.7481714, 0.7494305, 0.7498897, 0.7572988, 0.7614728, 0.764136, 0.7676206, 0.77061754, 0.7711028, 0.7775317, 0.7825358, 0.7832387, 0.79019344, 0.79456025, 0.7955694, 0.95244724, 0.95309013, 0.95505613, 0.95301217, 0.940024, 0.92684084, 0.9185019, 0.91627127, 0.9201923, 0.92062443, 0.92087924, 0.91393244, 0.90497154, 0.8990057, 0.8907492, 0.8825542, 0.87812185, 0.86859393, 0.86511964, 0.85656375, 0.8497787, 0.84184235, 0.8376684, 0.8337632, 0.8234728, 0.8196352, 0.81286997, 0.79881805, 0.79720205, 0.78889066, 0.782989, 0.7721511, 0.7647911, 0.7641177, 0.76063496, 0.7555601, 0.75587136, 0.7528545, 0.75307715, 0.7489083, 0.75025886, 0.7508635, 0.7478632, 0.7491388, 0.7432972, 0.7488706, 0.7520878, 0.750825, 0.75765276, 0.76090467, 0.76390594, 0.77055866, 0.77210504, 0.7725356, 0.7797, 0.7833602, 0.782008, 0.790258, 0.79595643, 0.7938406, 0.76917875, 0.82155645, 0.87548155, 0.9244786, 0.95904166, 0.95988303, 0.958157, 0.9606566, 0.95801276, 0.95468825, 0.9515486, 0.9470893, 0.941873, 0.93645597, 0.9242451, 0.91931707, 0.9162269, 0.9127267, 0.91096073, 0.9072413, 0.8977022, 0.89524674, 0.88705534, 0.8880866, 0.8856848, 0.87598294, 0.87925214, 0.8761165, 0.86657715, 0.8604342, 0.8619075, 0.85418767, 0.85065955, 0.852557, 0.8479133, 0.84247375, 0.8429609, 0.83862656, 0.8421511, 0.8310943, 0.8330566, 0.824545, 0.8221373, 0.8226803, 0.8119821, 0.81639946, 0.8148717, 0.8061195, 0.8114214, 0.8092397, 0.80552477, 0.8027862, 0.798957, 0.7907695, 0.79316366, 0.7958854, 0.79184806, 0.79691875, 0.8006287, 0.7984398, 0.7649326, 0.82011884, 0.8711142, 0.92071724, 0.9555983, 0.95352376, 0.9507152, 0.9548047, 0.95350045, 0.94904304, 0.9474079, 0.9439653, 0.93435955, 0.93574697, 0.9248062, 0.9215486, 0.9171459, 0.90988606, 0.91065824, 0.9029774, 0.90518373, 0.8919043, 0.89465296, 0.8922323, 0.8835502, 0.8844438, 0.88167435, 0.87101084, 0.8738697, 0.8677539, 0.86723167, 0.8580784, 0.85478026, 0.8561975, 0.852457, 0.8452621, 0.84717184, 0.8440129, 0.8441372, 0.8369018, 0.83645064, 0.8363976, 0.82963806, 0.828406, 0.8139702, 0.8192425, 0.8190894, 0.80796623, 0.8126079, 0.81046224, 0.8059764, 0.8077489, 0.80137473, 0.7929675, 0.7977971, 0.7969379, 0.7909791, 0.7976879, 0.8026009, 0.7953277]\n",
      "real: [0.981547760081002, 0.9783191107815529, 0.9720577829193665, 0.9677396187742875, 0.9637116538750307, 0.9613671533599215, 0.9566656962781115, 0.953212542304319, 0.9498307232149187, 0.9465717478639696, 0.9431893727029631, 0.9396172370027812, 0.9360453538976621, 0.9291805798075792, 0.9209527681953381, 0.9169270262172543, 0.9128542038766607, 0.9088717651351773, 0.9047587318552943, 0.9009867628597049, 0.8975242670665129, 0.89356647886204, 0.889644455237089, 0.886559405548693, 0.882733673476862, 0.8783059377512253, 0.8755645180191589, 0.8720300673473934, 0.8677529298076447, 0.859049156094731, 0.8569053494588545, 0.8518659950843436, 0.8502900122036473, 0.8480130356323287, 0.8446500805166606, 0.841138508684198, 0.8389571854909209, 0.8353695575997965, 0.8323632134517919, 0.828285810677856, 0.8255674607740809, 0.8199044530181538, 0.8132637498839883, 0.8102378979509867, 0.8072248070938493, 0.8059270278970738, 0.8029878307438708, 0.7989619033515942, 0.7983664753623245, 0.795802133196813, 0.7929682964599739, 0.7898693760651792, 0.787094046764988, 0.7830793400015471, 0.7820526502569298, 0.7795097506490353, 0.7759194636010017, 0.7754683610116903, 0.7730019872724594, 0.7737297038317591, 0.9789170845010232, 0.9723672398307521, 0.9678773262663203, 0.9636427140275626, 0.9632185045488699, 0.9580565260869475, 0.9547662648076788, 0.9517189050078657, 0.9486765256146883, 0.9457208157871942, 0.9427227872812818, 0.9399386291466334, 0.9349932513640985, 0.9288261894143705, 0.9254616695294128, 0.9221886563805027, 0.9188509699068458, 0.915816124993008, 0.9126536853065345, 0.9084989643628255, 0.9045647794981047, 0.9001612571956726, 0.8968866389327226, 0.8929720540671963, 0.8882457041155193, 0.8853800684167759, 0.8817096842753251, 0.8775402352158715, 0.8748208528209546, 0.8690810995476573, 0.8664810011514761, 0.8584888288239728, 0.858485841898706, 0.8559350369552029, 0.8523736538708621, 0.8479998113360429, 0.8457039847828337, 0.8419061496798198, 0.8385197021325397, 0.8343807998896714, 0.8321302164642305, 0.8257754683189632, 0.8190368263008624, 0.8156278584531853, 0.8108817253184123, 0.8097847912294613, 0.8066945905966949, 0.8016366439768062, 0.8009507504538506, 0.7978916242141426, 0.7951029470395748, 0.7918041093370152, 0.7888178498047248, 0.7839453521484476, 0.7835187764569512, 0.7806061992059281, 0.7751915070668952, 0.776400843070294, 0.7736816546951972, 0.7739719787425552, 0.981547760081002, 0.9783191107815529, 0.9720577829193665, 0.9677396187742875, 0.9637116538750307, 0.9613671533599215, 0.9566656962781115, 0.953212542304319, 0.9498307232149187, 0.9465717478639696, 0.9431893727029631, 0.9396172370027812, 0.9360453538976621, 0.9291805798075792, 0.9209527681953381, 0.9169270262172543, 0.9128542038766607, 0.9088717651351773, 0.9047587318552943, 0.9009867628597049, 0.8975242670665129, 0.89356647886204, 0.889644455237089, 0.886559405548693, 0.882733673476862, 0.8783059377512253, 0.8755645180191589, 0.8720300673473934, 0.8677529298076447, 0.859049156094731, 0.8569053494588545, 0.8518659950843436, 0.8502900122036473, 0.8480130356323287, 0.8446500805166606, 0.841138508684198, 0.8389571854909209, 0.8353695575997965, 0.8323632134517919, 0.828285810677856, 0.8255674607740809, 0.8199044530181538, 0.8132637498839883, 0.8102378979509867, 0.8072248070938493, 0.8059270278970738, 0.8029878307438708, 0.7989619033515942, 0.7983664753623245, 0.795802133196813, 0.7929682964599739, 0.7898693760651792, 0.787094046764988, 0.7830793400015471, 0.7820526502569298, 0.7795097506490353, 0.7759194636010017, 0.7754683610116903, 0.7730019872724594, 0.7737297038317591, 0.9789170845010232, 0.9723672398307521, 0.9678773262663203, 0.9636427140275626, 0.9632185045488699, 0.9580565260869475, 0.9547662648076788, 0.9517189050078657, 0.9486765256146883, 0.9457208157871942, 0.9427227872812818, 0.9399386291466334, 0.9349932513640985, 0.9288261894143705, 0.9254616695294128, 0.9221886563805027, 0.9188509699068458, 0.915816124993008, 0.9126536853065345, 0.9084989643628255, 0.9045647794981047, 0.9001612571956726, 0.8968866389327226, 0.8929720540671963, 0.8882457041155193, 0.8853800684167759, 0.8817096842753251, 0.8775402352158715, 0.8748208528209546, 0.8690810995476573, 0.8664810011514761, 0.8584888288239728, 0.858485841898706, 0.8559350369552029, 0.8523736538708621, 0.8479998113360429, 0.8457039847828337, 0.8419061496798198, 0.8385197021325397, 0.8343807998896714, 0.8321302164642305, 0.8257754683189632, 0.8190368263008624, 0.8156278584531853, 0.8108817253184123, 0.8097847912294613, 0.8066945905966949, 0.8016366439768062, 0.8009507504538506, 0.7978916242141426, 0.7951029470395748, 0.7918041093370152, 0.7888178498047248, 0.7839453521484476, 0.7835187764569512, 0.7806061992059281, 0.7751915070668952, 0.776400843070294, 0.7736816546951972, 0.7739719787425552, 0.981547760081002, 0.9783191107815529, 0.9720577829193665, 0.9677396187742875, 0.9637116538750307, 0.9613671533599215, 0.9566656962781115, 0.953212542304319, 0.9498307232149187, 0.9465717478639696, 0.9431893727029631, 0.9396172370027812, 0.9360453538976621, 0.9291805798075792, 0.9209527681953381, 0.9169270262172543, 0.9128542038766607, 0.9088717651351773, 0.9047587318552943, 0.9009867628597049, 0.8975242670665129, 0.89356647886204, 0.889644455237089, 0.886559405548693, 0.882733673476862, 0.8783059377512253, 0.8755645180191589, 0.8720300673473934, 0.8677529298076447, 0.859049156094731, 0.8569053494588545, 0.8518659950843436, 0.8502900122036473, 0.8480130356323287, 0.8446500805166606, 0.841138508684198, 0.8389571854909209, 0.8353695575997965, 0.8323632134517919, 0.828285810677856, 0.8255674607740809, 0.8199044530181538, 0.8132637498839883, 0.8102378979509867, 0.8072248070938493, 0.8059270278970738, 0.8029878307438708, 0.7989619033515942, 0.7983664753623245, 0.795802133196813, 0.7929682964599739, 0.7898693760651792, 0.787094046764988, 0.7830793400015471, 0.7820526502569298, 0.7795097506490353, 0.7759194636010017, 0.7754683610116903, 0.7730019872724594, 0.7737297038317591, 0.9789170845010232, 0.9723672398307521, 0.9678773262663203, 0.9636427140275626, 0.9632185045488699, 0.9580565260869475, 0.9547662648076788, 0.9517189050078657, 0.9486765256146883, 0.9457208157871942, 0.9427227872812818, 0.9399386291466334, 0.9349932513640985, 0.9288261894143705, 0.9254616695294128, 0.9221886563805027, 0.9188509699068458, 0.915816124993008, 0.9126536853065345, 0.9084989643628255, 0.9045647794981047, 0.9001612571956726, 0.8968866389327226, 0.8929720540671963, 0.8882457041155193, 0.8853800684167759, 0.8817096842753251, 0.8775402352158715, 0.8748208528209546, 0.8690810995476573, 0.8664810011514761, 0.8584888288239728, 0.858485841898706, 0.8559350369552029, 0.8523736538708621, 0.8479998113360429, 0.8457039847828337, 0.8419061496798198, 0.8385197021325397, 0.8343807998896714, 0.8321302164642305, 0.8257754683189632, 0.8190368263008624, 0.8156278584531853, 0.8108817253184123, 0.8097847912294613, 0.8066945905966949, 0.8016366439768062, 0.8009507504538506, 0.7978916242141426, 0.7951029470395748, 0.7918041093370152, 0.7888178498047248, 0.7839453521484476, 0.7835187764569512, 0.7806061992059281, 0.7751915070668952, 0.776400843070294, 0.7736816546951972, 0.7739719787425552, 0.981547760081002, 0.9783191107815529, 0.9720577829193665, 0.9677396187742875, 0.9637116538750307, 0.9613671533599215, 0.9566656962781115, 0.953212542304319, 0.9498307232149187, 0.9465717478639696, 0.9431893727029631, 0.9396172370027812, 0.9360453538976621, 0.9291805798075792, 0.9209527681953381, 0.9169270262172543, 0.9128542038766607, 0.9088717651351773, 0.9047587318552943, 0.9009867628597049, 0.8975242670665129, 0.89356647886204, 0.889644455237089, 0.886559405548693, 0.882733673476862, 0.8783059377512253, 0.8755645180191589, 0.8720300673473934, 0.8677529298076447, 0.859049156094731, 0.8569053494588545, 0.8518659950843436, 0.8502900122036473, 0.8480130356323287, 0.8446500805166606, 0.841138508684198, 0.8389571854909209, 0.8353695575997965, 0.8323632134517919, 0.828285810677856, 0.8255674607740809, 0.8199044530181538, 0.8132637498839883, 0.8102378979509867, 0.8072248070938493, 0.8059270278970738, 0.8029878307438708, 0.7989619033515942, 0.7983664753623245, 0.795802133196813, 0.7929682964599739, 0.7898693760651792, 0.787094046764988, 0.7830793400015471, 0.7820526502569298, 0.7795097506490353, 0.7759194636010017, 0.7754683610116903, 0.7730019872724594, 0.7737297038317591, 0.9789170845010232, 0.9723672398307521, 0.9678773262663203, 0.9636427140275626, 0.9632185045488699, 0.9580565260869475, 0.9547662648076788, 0.9517189050078657, 0.9486765256146883, 0.9457208157871942, 0.9427227872812818, 0.9399386291466334, 0.9349932513640985, 0.9288261894143705, 0.9254616695294128, 0.9221886563805027, 0.9188509699068458, 0.915816124993008, 0.9126536853065345, 0.9084989643628255, 0.9045647794981047, 0.9001612571956726, 0.8968866389327226, 0.8929720540671963, 0.8882457041155193, 0.8853800684167759, 0.8817096842753251, 0.8775402352158715, 0.8748208528209546, 0.8690810995476573, 0.8664810011514761, 0.8584888288239728, 0.858485841898706, 0.8559350369552029, 0.8523736538708621, 0.8479998113360429, 0.8457039847828337, 0.8419061496798198, 0.8385197021325397, 0.8343807998896714, 0.8321302164642305, 0.8257754683189632, 0.8190368263008624, 0.8156278584531853, 0.8108817253184123, 0.8097847912294613, 0.8066945905966949, 0.8016366439768062, 0.8009507504538506, 0.7978916242141426, 0.7951029470395748, 0.7918041093370152, 0.7888178498047248, 0.7839453521484476, 0.7835187764569512, 0.7806061992059281, 0.7751915070668952, 0.776400843070294, 0.7736816546951972, 0.7739719787425552]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_all=[]\n",
    "mae_all=[]\n",
    "mape_all=[]\n",
    "r2=[]\n",
    "num=0\n",
    "test_csv_m=[]\n",
    "real_csv_m=[]\n",
    "for i in range(4):\n",
    "    for j in range(len(tests[0])):\n",
    "        real,pred=tests_mlp[i][j][0],tests_mlp[i][j][1].reshape(-1)\n",
    "        rmse=evaluation(real,pred)\n",
    "        if rmse>=0.00:\n",
    "            rmse_all.append(rmse)\n",
    "            for pre,rea in zip(pred,real):\n",
    "                test_csv_m.append(pre)\n",
    "                real_csv_m.append(rea)\n",
    "        mae_all.append(calculate_mae(real,pred))\n",
    "        mape_all.append(mape(real,pred))\n",
    "        r2.append(r_squared(real,pred))\n",
    "        num+=1\n",
    "print(\"RMSE:\",rmse_all)\n",
    "print(\"test:\",test_csv_m)\n",
    "print('real:',real_csv_m)\n",
    "len(test_csv_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0c75d9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T00:40:57.865380Z",
     "start_time": "2025-03-11T00:40:57.848512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: [0.02895238818411297]\n",
      "MAE: [0.02083116]\n"
     ]
    }
   ],
   "source": [
    "# rmse_all=0\n",
    "# mae_all=0\n",
    "# num=0\n",
    "# for i in range(len(tests_mlp)):\n",
    "#     for j in range(len(tests_mlp[0])):\n",
    "#         real,pred=tests_mlp[i][j][0],tests_mlp[i][j][1]\n",
    "#         rmse=evaluation(real,pred)\n",
    "#         rmse_all+=(rmse)\n",
    "#         mae_all+=calculate_mae(real,pred)\n",
    "#         num+=1\n",
    "# print('RMSE:',[rmse_all/num])\n",
    "# print('MAE:',mae_all/num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15de7dcfa65fd3f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a42eb44efab26c1a",
   "metadata": {},
   "source": [
    "## 挑出来一组画图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f3bd6ff6079a9a84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T02:41:42.838814Z",
     "start_time": "2025-03-05T02:41:42.348829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training seed 1:\n",
      "\n",
      "Epoch: 5 Train_RMSELoss: tensor(0.0638, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 5 valid_RMSELoss: tensor(0.0575, device='cuda:0') \n",
      "\n",
      "Epoch: 10 Train_RMSELoss: tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 10 valid_RMSELoss: tensor(0.0020, device='cuda:0') \n",
      "\n",
      "Epoch: 15 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 15 valid_RMSELoss: tensor(0.0007, device='cuda:0') \n",
      "\n",
      "Epoch: 20 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 20 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 25 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 25 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 30 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 30 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 35 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 35 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_results_mlp=train_mlp(seed=1,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fefd1e359dfe24af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T02:41:57.548694Z",
     "start_time": "2025-03-05T02:41:57.536996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01198461710176137\n",
      "0.014795532963108166\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    real,pred=test_results_mlp[i][0],test_results_mlp[i][1]\n",
    "    rmse=evaluation(real,pred)\n",
    "    print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "842e2cdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T11:05:50.713867Z",
     "start_time": "2025-03-20T11:05:50.690644Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, n_input=7):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # 输入重塑为 (batch, 1, n_input)\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(32 * (n_input // 2), 64)  # 根据池化后的维度调整\n",
    "        self.fc2 = nn.Sequential(nn.Linear(64 , 256),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(256, 64),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(64, 32),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(32, 1),)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 输入 x 的形状: (batch, n_input)\n",
    "        x = x.unsqueeze(1)  # 重塑为 (batch, 1, n_input)\n",
    "        x = self.conv1(x)   # 卷积后形状: (batch, 32, n_input)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)    # 池化后形状: (batch, 32, n_input // 2)\n",
    "        x = x.view(x.size(0), -1)  # 展平为 (batch, 32 * (n_input // 2))\n",
    "        x = self.fc1(x)     # 全连接层\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)     # 输出形状: (batch, 1)\n",
    "        return x\n",
    "def train_conv(lr=0.001,epochs=200, weight_decay=1e-4, seed=0, metric='rmse', device='cpu'):\n",
    "    \"\"\"function for train\"\"\"\n",
    "    setup_seed(seed)\n",
    "    print(\"training seed \"+str(seed)+':\\n')\n",
    "    train_loader, val_loader, test_35_data, test_36_data=get_data()\n",
    "    test_data=[test_35_data, test_36_data]\n",
    "    model = ConvNet()\n",
    "    model=model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.MSELoss()\n",
    "    len_dataloader = len(train_loader)\n",
    "    test_results=[]\n",
    "    \"\"\"早停止获取最佳模型\"\"\"\n",
    "    val_mse=10\n",
    "    for epoch in range(epochs):\n",
    "        loss_epoch=0\n",
    "        for X,y in train_loader:\n",
    "            X,y = X.to(device), y.to(device)\n",
    "            y_pred= model(X)\n",
    "            y_pred = y_pred.squeeze(1)\n",
    "            loss = criterion(y_pred,y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_epoch += loss\n",
    "        if (epoch+1)%5==0 and epoch!=0:\n",
    "            print('Epoch:',epoch+1,'Train_RMSELoss:',loss_epoch/len_dataloader,'\\n')\n",
    "        if (epoch+1)%5==0 and epoch!=0:\n",
    "            val_loss=0\n",
    "            for val_x,val_y in val_loader:\n",
    "                val_x,val_y=val_x.to(device),val_y.to(device)\n",
    "                pre=model(val_x)\n",
    "                val_loss+=criterion(pre.squeeze(1),val_y).detach()    \n",
    "            print('Epoch:',epoch+1,'valid_RMSELoss:',val_loss/len(val_loader),'\\n')\n",
    "            val_mse=val_loss/len(val_loader)\n",
    "                \n",
    "        if (val_mse<0.5e-4 and epoch>=35)or (epoch+1)==epochs:\n",
    "            model=model.cpu()\n",
    "            \n",
    "            for name in test_data:\n",
    "                X=torch.from_numpy(name[0]).float()\n",
    "                y=name[1]\n",
    "                y_pred=model(X)\n",
    "                y_pred= y_pred.squeeze(0).detach().numpy()\n",
    "                test_results.append([y,y_pred])\n",
    "            break\n",
    "    return test_results\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da90816da59349a",
   "metadata": {},
   "source": [
    "## 随机种子训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7af0cfb2fb39fcf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T11:05:57.524595Z",
     "start_time": "2025-03-20T11:05:52.900889Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training seed 0:\n",
      "\n",
      "Epoch: 5 Train_RMSELoss: tensor(0.2231, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 5 valid_RMSELoss: tensor(0.2034, device='cuda:0') \n",
      "\n",
      "Epoch: 10 Train_RMSELoss: tensor(0.1293, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 10 valid_RMSELoss: tensor(0.1216, device='cuda:0') \n",
      "\n",
      "Epoch: 15 Train_RMSELoss: tensor(0.0328, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 15 valid_RMSELoss: tensor(0.0239, device='cuda:0') \n",
      "\n",
      "Epoch: 20 Train_RMSELoss: tensor(0.0094, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 20 valid_RMSELoss: tensor(0.0094, device='cuda:0') \n",
      "\n",
      "Epoch: 25 Train_RMSELoss: tensor(0.0026, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 25 valid_RMSELoss: tensor(0.0048, device='cuda:0') \n",
      "\n",
      "Epoch: 30 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 30 valid_RMSELoss: tensor(0.0005, device='cuda:0') \n",
      "\n",
      "Epoch: 35 Train_RMSELoss: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 35 valid_RMSELoss: tensor(0.0006, device='cuda:0') \n",
      "\n",
      "Epoch: 40 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 40 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 45 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 45 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 50 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 50 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 55 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 55 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 60 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 60 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 65 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 65 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 70 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 70 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 75 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 75 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 80 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 80 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 85 Train_RMSELoss: tensor(8.7977e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 85 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 90 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 90 valid_RMSELoss: tensor(0.0006, device='cuda:0') \n",
      "\n",
      "Epoch: 95 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 95 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 100 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 100 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 105 Train_RMSELoss: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 105 valid_RMSELoss: tensor(0.0005, device='cuda:0') \n",
      "\n",
      "Epoch: 110 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 110 valid_RMSELoss: tensor(0.0009, device='cuda:0') \n",
      "\n",
      "Epoch: 115 Train_RMSELoss: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 115 valid_RMSELoss: tensor(0.0013, device='cuda:0') \n",
      "\n",
      "Epoch: 120 Train_RMSELoss: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 120 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 125 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 125 valid_RMSELoss: tensor(0.0010, device='cuda:0') \n",
      "\n",
      "Epoch: 130 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 130 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 135 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 135 valid_RMSELoss: tensor(0.0005, device='cuda:0') \n",
      "\n",
      "Epoch: 140 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 140 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 145 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 145 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 150 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 150 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 155 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 155 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 160 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 160 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 165 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 165 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 170 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 170 valid_RMSELoss: tensor(0.0005, device='cuda:0') \n",
      "\n",
      "Epoch: 175 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 175 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 180 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 180 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 185 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 185 valid_RMSELoss: tensor(0.0005, device='cuda:0') \n",
      "\n",
      "Epoch: 190 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 190 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 195 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 195 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 200 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 200 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "training seed 1:\n",
      "\n",
      "Epoch: 5 Train_RMSELoss: tensor(0.3663, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 5 valid_RMSELoss: tensor(0.2457, device='cuda:0') \n",
      "\n",
      "Epoch: 10 Train_RMSELoss: tensor(0.2548, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 10 valid_RMSELoss: tensor(0.1855, device='cuda:0') \n",
      "\n",
      "Epoch: 15 Train_RMSELoss: tensor(0.1570, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 15 valid_RMSELoss: tensor(0.1177, device='cuda:0') \n",
      "\n",
      "Epoch: 20 Train_RMSELoss: tensor(0.0439, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 20 valid_RMSELoss: tensor(0.0245, device='cuda:0') \n",
      "\n",
      "Epoch: 25 Train_RMSELoss: tensor(0.0081, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 25 valid_RMSELoss: tensor(0.0134, device='cuda:0') \n",
      "\n",
      "Epoch: 30 Train_RMSELoss: tensor(0.0028, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 30 valid_RMSELoss: tensor(0.0026, device='cuda:0') \n",
      "\n",
      "Epoch: 35 Train_RMSELoss: tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 35 valid_RMSELoss: tensor(0.0018, device='cuda:0') \n",
      "\n",
      "Epoch: 40 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 40 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 45 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 45 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 50 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 50 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 55 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 55 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 60 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 60 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 65 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 65 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 70 Train_RMSELoss: tensor(6.8922e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 70 valid_RMSELoss: tensor(8.7305e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 75 Train_RMSELoss: tensor(5.0907e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 75 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 80 Train_RMSELoss: tensor(3.2434e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 80 valid_RMSELoss: tensor(9.5012e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 85 Train_RMSELoss: tensor(3.0133e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 85 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 90 Train_RMSELoss: tensor(3.4075e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 90 valid_RMSELoss: tensor(6.8875e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 95 Train_RMSELoss: tensor(3.1524e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 95 valid_RMSELoss: tensor(8.5847e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 100 Train_RMSELoss: tensor(3.4514e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 100 valid_RMSELoss: tensor(8.1890e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 105 Train_RMSELoss: tensor(5.0725e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 105 valid_RMSELoss: tensor(6.7878e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 110 Train_RMSELoss: tensor(5.1856e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 110 valid_RMSELoss: tensor(6.9924e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 115 Train_RMSELoss: tensor(3.4855e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 115 valid_RMSELoss: tensor(6.3986e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 120 Train_RMSELoss: tensor(2.9549e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 120 valid_RMSELoss: tensor(7.8177e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 125 Train_RMSELoss: tensor(3.5908e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 125 valid_RMSELoss: tensor(6.4459e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 130 Train_RMSELoss: tensor(3.3552e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 130 valid_RMSELoss: tensor(6.3687e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 135 Train_RMSELoss: tensor(4.4981e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 135 valid_RMSELoss: tensor(7.3523e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 140 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 140 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 145 Train_RMSELoss: tensor(7.0764e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 145 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 150 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 150 valid_RMSELoss: tensor(7.7373e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 155 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 155 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 160 Train_RMSELoss: tensor(3.6714e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 160 valid_RMSELoss: tensor(6.3122e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 165 Train_RMSELoss: tensor(4.1500e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 165 valid_RMSELoss: tensor(6.7144e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 170 Train_RMSELoss: tensor(5.8683e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 170 valid_RMSELoss: tensor(8.6712e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 175 Train_RMSELoss: tensor(5.2978e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 175 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 180 Train_RMSELoss: tensor(3.6665e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 180 valid_RMSELoss: tensor(6.8533e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 185 Train_RMSELoss: tensor(4.5315e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 185 valid_RMSELoss: tensor(6.8897e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 190 Train_RMSELoss: tensor(4.4882e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 190 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 195 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 195 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 200 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 200 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "training seed 2:\n",
      "\n",
      "Epoch: 5 Train_RMSELoss: tensor(0.4086, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 5 valid_RMSELoss: tensor(1.0478, device='cuda:0') \n",
      "\n",
      "Epoch: 10 Train_RMSELoss: tensor(0.3756, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 10 valid_RMSELoss: tensor(0.2270, device='cuda:0') \n",
      "\n",
      "Epoch: 15 Train_RMSELoss: tensor(0.2521, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 15 valid_RMSELoss: tensor(0.4809, device='cuda:0') \n",
      "\n",
      "Epoch: 20 Train_RMSELoss: tensor(0.1344, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 20 valid_RMSELoss: tensor(0.1326, device='cuda:0') \n",
      "\n",
      "Epoch: 25 Train_RMSELoss: tensor(0.0154, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 25 valid_RMSELoss: tensor(0.0158, device='cuda:0') \n",
      "\n",
      "Epoch: 30 Train_RMSELoss: tensor(0.0129, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 30 valid_RMSELoss: tensor(0.0064, device='cuda:0') \n",
      "\n",
      "Epoch: 35 Train_RMSELoss: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 35 valid_RMSELoss: tensor(0.0040, device='cuda:0') \n",
      "\n",
      "Epoch: 40 Train_RMSELoss: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 40 valid_RMSELoss: tensor(0.0013, device='cuda:0') \n",
      "\n",
      "Epoch: 45 Train_RMSELoss: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 45 valid_RMSELoss: tensor(0.0014, device='cuda:0') \n",
      "\n",
      "Epoch: 50 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 50 valid_RMSELoss: tensor(0.0005, device='cuda:0') \n",
      "\n",
      "Epoch: 55 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 55 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 60 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 60 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 65 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 65 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 70 Train_RMSELoss: tensor(8.0183e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 70 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 75 Train_RMSELoss: tensor(5.8888e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 75 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 80 Train_RMSELoss: tensor(8.3435e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 80 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 85 Train_RMSELoss: tensor(6.0758e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 85 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 90 Train_RMSELoss: tensor(8.5436e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 90 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 95 Train_RMSELoss: tensor(5.5357e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 95 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 100 Train_RMSELoss: tensor(8.3101e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 100 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 105 Train_RMSELoss: tensor(8.3633e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 105 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 110 Train_RMSELoss: tensor(4.2372e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 110 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 115 Train_RMSELoss: tensor(9.7351e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 115 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 120 Train_RMSELoss: tensor(6.9863e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 120 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 125 Train_RMSELoss: tensor(4.7783e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 125 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 130 Train_RMSELoss: tensor(5.7690e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 130 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 135 Train_RMSELoss: tensor(4.3764e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 135 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 140 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 140 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 145 Train_RMSELoss: tensor(6.5614e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 145 valid_RMSELoss: tensor(9.3286e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 150 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 150 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 155 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 155 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 160 Train_RMSELoss: tensor(3.7102e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 160 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 165 Train_RMSELoss: tensor(3.8666e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 165 valid_RMSELoss: tensor(8.9693e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 170 Train_RMSELoss: tensor(3.6304e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 170 valid_RMSELoss: tensor(8.8614e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 175 Train_RMSELoss: tensor(3.4245e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 175 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 180 Train_RMSELoss: tensor(3.0690e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 180 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 185 Train_RMSELoss: tensor(2.6302e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 185 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 190 Train_RMSELoss: tensor(2.9682e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 190 valid_RMSELoss: tensor(9.7100e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 195 Train_RMSELoss: tensor(3.6245e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 195 valid_RMSELoss: tensor(8.3290e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 200 Train_RMSELoss: tensor(4.0130e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 200 valid_RMSELoss: tensor(8.3449e-05, device='cuda:0') \n",
      "\n",
      "training seed 3:\n",
      "\n",
      "Epoch: 5 Train_RMSELoss: tensor(0.1635, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 5 valid_RMSELoss: tensor(0.1801, device='cuda:0') \n",
      "\n",
      "Epoch: 10 Train_RMSELoss: tensor(0.0914, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 10 valid_RMSELoss: tensor(0.1240, device='cuda:0') \n",
      "\n",
      "Epoch: 15 Train_RMSELoss: tensor(0.0377, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 15 valid_RMSELoss: tensor(0.0520, device='cuda:0') \n",
      "\n",
      "Epoch: 20 Train_RMSELoss: tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 20 valid_RMSELoss: tensor(0.0029, device='cuda:0') \n",
      "\n",
      "Epoch: 25 Train_RMSELoss: tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 25 valid_RMSELoss: tensor(0.0021, device='cuda:0') \n",
      "\n",
      "Epoch: 30 Train_RMSELoss: tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 30 valid_RMSELoss: tensor(0.0044, device='cuda:0') \n",
      "\n",
      "Epoch: 35 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 35 valid_RMSELoss: tensor(0.0016, device='cuda:0') \n",
      "\n",
      "Epoch: 40 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 40 valid_RMSELoss: tensor(0.0013, device='cuda:0') \n",
      "\n",
      "Epoch: 45 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 45 valid_RMSELoss: tensor(0.0016, device='cuda:0') \n",
      "\n",
      "Epoch: 50 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 50 valid_RMSELoss: tensor(0.0012, device='cuda:0') \n",
      "\n",
      "Epoch: 55 Train_RMSELoss: tensor(8.5672e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 55 valid_RMSELoss: tensor(0.0011, device='cuda:0') \n",
      "\n",
      "Epoch: 60 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 60 valid_RMSELoss: tensor(0.0010, device='cuda:0') \n",
      "\n",
      "Epoch: 65 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 65 valid_RMSELoss: tensor(0.0009, device='cuda:0') \n",
      "\n",
      "Epoch: 70 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 70 valid_RMSELoss: tensor(0.0011, device='cuda:0') \n",
      "\n",
      "Epoch: 75 Train_RMSELoss: tensor(7.1908e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 75 valid_RMSELoss: tensor(0.0009, device='cuda:0') \n",
      "\n",
      "Epoch: 80 Train_RMSELoss: tensor(5.6419e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 80 valid_RMSELoss: tensor(0.0009, device='cuda:0') \n",
      "\n",
      "Epoch: 85 Train_RMSELoss: tensor(7.3148e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 85 valid_RMSELoss: tensor(0.0009, device='cuda:0') \n",
      "\n",
      "Epoch: 90 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 90 valid_RMSELoss: tensor(0.0009, device='cuda:0') \n",
      "\n",
      "Epoch: 95 Train_RMSELoss: tensor(8.9687e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 95 valid_RMSELoss: tensor(0.0010, device='cuda:0') \n",
      "\n",
      "Epoch: 100 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 100 valid_RMSELoss: tensor(0.0008, device='cuda:0') \n",
      "\n",
      "Epoch: 105 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 105 valid_RMSELoss: tensor(0.0011, device='cuda:0') \n",
      "\n",
      "Epoch: 110 Train_RMSELoss: tensor(5.4692e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 110 valid_RMSELoss: tensor(0.0008, device='cuda:0') \n",
      "\n",
      "Epoch: 115 Train_RMSELoss: tensor(5.2508e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 115 valid_RMSELoss: tensor(0.0008, device='cuda:0') \n",
      "\n",
      "Epoch: 120 Train_RMSELoss: tensor(7.6705e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 120 valid_RMSELoss: tensor(0.0008, device='cuda:0') \n",
      "\n",
      "Epoch: 125 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 125 valid_RMSELoss: tensor(0.0010, device='cuda:0') \n",
      "\n",
      "Epoch: 130 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 130 valid_RMSELoss: tensor(0.0009, device='cuda:0') \n",
      "\n",
      "Epoch: 135 Train_RMSELoss: tensor(8.2665e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 135 valid_RMSELoss: tensor(0.0009, device='cuda:0') \n",
      "\n",
      "Epoch: 140 Train_RMSELoss: tensor(3.8109e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 140 valid_RMSELoss: tensor(0.0008, device='cuda:0') \n",
      "\n",
      "Epoch: 145 Train_RMSELoss: tensor(5.3981e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 145 valid_RMSELoss: tensor(0.0009, device='cuda:0') \n",
      "\n",
      "Epoch: 150 Train_RMSELoss: tensor(6.3191e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 150 valid_RMSELoss: tensor(0.0008, device='cuda:0') \n",
      "\n",
      "Epoch: 155 Train_RMSELoss: tensor(7.2242e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 155 valid_RMSELoss: tensor(0.0008, device='cuda:0') \n",
      "\n",
      "Epoch: 160 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 160 valid_RMSELoss: tensor(0.0010, device='cuda:0') \n",
      "\n",
      "Epoch: 165 Train_RMSELoss: tensor(7.3453e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 165 valid_RMSELoss: tensor(0.0008, device='cuda:0') \n",
      "\n",
      "Epoch: 170 Train_RMSELoss: tensor(4.3473e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 170 valid_RMSELoss: tensor(0.0009, device='cuda:0') \n",
      "\n",
      "Epoch: 175 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 175 valid_RMSELoss: tensor(0.0008, device='cuda:0') \n",
      "\n",
      "Epoch: 180 Train_RMSELoss: tensor(8.1373e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 180 valid_RMSELoss: tensor(0.0008, device='cuda:0') \n",
      "\n",
      "Epoch: 185 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 185 valid_RMSELoss: tensor(0.0008, device='cuda:0') \n",
      "\n",
      "Epoch: 190 Train_RMSELoss: tensor(6.1973e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 190 valid_RMSELoss: tensor(0.0008, device='cuda:0') \n",
      "\n",
      "Epoch: 195 Train_RMSELoss: tensor(6.5739e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 195 valid_RMSELoss: tensor(0.0007, device='cuda:0') \n",
      "\n",
      "Epoch: 200 Train_RMSELoss: tensor(4.1763e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 200 valid_RMSELoss: tensor(0.0011, device='cuda:0') \n",
      "\n",
      "training seed 4:\n",
      "\n",
      "Epoch: 5 Train_RMSELoss: tensor(0.2505, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 5 valid_RMSELoss: tensor(0.2133, device='cuda:0') \n",
      "\n",
      "Epoch: 10 Train_RMSELoss: tensor(0.1463, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 10 valid_RMSELoss: tensor(0.1910, device='cuda:0') \n",
      "\n",
      "Epoch: 15 Train_RMSELoss: tensor(0.0188, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 15 valid_RMSELoss: tensor(0.0347, device='cuda:0') \n",
      "\n",
      "Epoch: 20 Train_RMSELoss: tensor(0.0138, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 20 valid_RMSELoss: tensor(0.0067, device='cuda:0') \n",
      "\n",
      "Epoch: 25 Train_RMSELoss: tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 25 valid_RMSELoss: tensor(0.0100, device='cuda:0') \n",
      "\n",
      "Epoch: 30 Train_RMSELoss: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 30 valid_RMSELoss: tensor(0.0009, device='cuda:0') \n",
      "\n",
      "Epoch: 35 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 35 valid_RMSELoss: tensor(0.0005, device='cuda:0') \n",
      "\n",
      "Epoch: 40 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 40 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 45 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 45 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 50 Train_RMSELoss: tensor(8.2170e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 50 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 55 Train_RMSELoss: tensor(5.7066e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 55 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 60 Train_RMSELoss: tensor(5.3926e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 60 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 65 Train_RMSELoss: tensor(4.3147e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 65 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 70 Train_RMSELoss: tensor(3.6159e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 70 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 75 Train_RMSELoss: tensor(5.2613e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 75 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 80 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 80 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 85 Train_RMSELoss: tensor(5.7597e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 85 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 90 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 90 valid_RMSELoss: tensor(0.0006, device='cuda:0') \n",
      "\n",
      "Epoch: 95 Train_RMSELoss: tensor(6.9122e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 95 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 100 Train_RMSELoss: tensor(6.3700e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 100 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 105 Train_RMSELoss: tensor(3.9211e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 105 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 110 Train_RMSELoss: tensor(3.3305e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 110 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 115 Train_RMSELoss: tensor(3.3122e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 115 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 120 Train_RMSELoss: tensor(5.3581e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 120 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 125 Train_RMSELoss: tensor(3.8446e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 125 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 130 Train_RMSELoss: tensor(5.5551e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 130 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 135 Train_RMSELoss: tensor(3.3877e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 135 valid_RMSELoss: tensor(0.0005, device='cuda:0') \n",
      "\n",
      "Epoch: 140 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 140 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 145 Train_RMSELoss: tensor(3.7631e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 145 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 150 Train_RMSELoss: tensor(7.1886e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 150 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 155 Train_RMSELoss: tensor(6.8234e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 155 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 160 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 160 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 165 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 165 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 170 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 170 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 175 Train_RMSELoss: tensor(9.2076e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 175 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 180 Train_RMSELoss: tensor(5.6267e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 180 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 185 Train_RMSELoss: tensor(2.9140e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 185 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 190 Train_RMSELoss: tensor(4.7725e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 190 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 195 Train_RMSELoss: tensor(8.1674e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 195 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 200 Train_RMSELoss: tensor(5.3957e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 200 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tests_cnn=[]\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "for i in range(5):\n",
    "    test_result=train_conv(seed=i,device=device)\n",
    "    tests_cnn.append(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "93449b77bf8bd216",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T11:06:06.711469Z",
     "start_time": "2025-03-20T11:06:06.699292Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: [0.011600442910434886, 0.01333707612980118, 0.010034469575548535, 0.01059629931538171, 0.00671935656190564, 0.00711514508611243, 0.03012614385218237, 0.030075749351074484]\n",
      "test: [0.95095146, 0.9534142, 0.9666918, 0.9635536, 0.9600384, 0.9575727, 0.9514246, 0.95535034, 0.9521985, 0.94494194, 0.94317806, 0.9407112, 0.9334883, 0.92885816, 0.91703767, 0.91293293, 0.9119651, 0.90840274, 0.90507483, 0.90006775, 0.8893362, 0.8860781, 0.87770396, 0.87873, 0.8770786, 0.8679415, 0.87077534, 0.8654066, 0.85613924, 0.8492343, 0.8499926, 0.8418859, 0.8362718, 0.83706003, 0.8278874, 0.8213, 0.8210532, 0.81690395, 0.82043093, 0.8076516, 0.8093751, 0.799365, 0.796481, 0.79618967, 0.785898, 0.78883886, 0.78968066, 0.7824789, 0.78665286, 0.78452325, 0.78243804, 0.78067, 0.7780045, 0.7728108, 0.7725478, 0.77507097, 0.7685063, 0.7701455, 0.7731438, 0.7682804, 0.9444395, 0.951622, 0.96121895, 0.9576602, 0.95551497, 0.9503033, 0.94293773, 0.95041305, 0.9450012, 0.9419044, 0.93910116, 0.9370576, 0.92693764, 0.9299833, 0.9176099, 0.91683125, 0.91097635, 0.90392774, 0.9028019, 0.89403975, 0.8999127, 0.88280296, 0.8869585, 0.88256294, 0.8746818, 0.8748984, 0.87164164, 0.86178297, 0.86327225, 0.8558821, 0.85557216, 0.84514236, 0.84151787, 0.84092414, 0.83499306, 0.82506996, 0.825691, 0.8220972, 0.8210811, 0.81344473, 0.8114067, 0.81105906, 0.8042638, 0.80153954, 0.78722084, 0.7922666, 0.7925765, 0.7839136, 0.78793424, 0.7872021, 0.7834967, 0.7836331, 0.779367, 0.773783, 0.7773489, 0.7757369, 0.7690759, 0.77182984, 0.7752878, 0.7640226, 0.9722898, 0.9790826, 0.9817071, 0.9715617, 0.9630089, 0.9609817, 0.95419276, 0.95803857, 0.9492078, 0.942963, 0.9462124, 0.9426183, 0.9324399, 0.92800033, 0.912863, 0.9092637, 0.9096687, 0.908429, 0.90796113, 0.90323144, 0.8889735, 0.8866147, 0.87600094, 0.88029593, 0.8801158, 0.86812377, 0.8753795, 0.87012315, 0.857842, 0.8496951, 0.85334826, 0.84339154, 0.8388163, 0.84383273, 0.83416826, 0.8270792, 0.82924354, 0.8242036, 0.83179253, 0.8131564, 0.8178656, 0.8037121, 0.8008939, 0.8024173, 0.7862802, 0.7922361, 0.7925409, 0.7786157, 0.78590274, 0.7816023, 0.7769605, 0.77318233, 0.7679844, 0.76132524, 0.7642915, 0.77057004, 0.76454556, 0.7698369, 0.77659035, 0.77480054, 0.9629445, 0.9764782, 0.97318244, 0.962599, 0.9563911, 0.95009995, 0.94177455, 0.94972277, 0.9386169, 0.9375614, 0.9400405, 0.9370957, 0.9217199, 0.9294046, 0.913765, 0.9149681, 0.9086371, 0.90203905, 0.90500915, 0.8942125, 0.9048525, 0.8814131, 0.8901622, 0.8864857, 0.87642086, 0.879549, 0.877156, 0.86387324, 0.86922705, 0.8605037, 0.8622643, 0.8485516, 0.8466201, 0.84974164, 0.84465957, 0.8327627, 0.8367424, 0.83279276, 0.83326995, 0.82268184, 0.8216161, 0.8229492, 0.81361425, 0.81125695, 0.7886574, 0.7980122, 0.7981249, 0.78132963, 0.7882098, 0.7860173, 0.778715, 0.779016, 0.77059644, 0.76294684, 0.77096856, 0.77164143, 0.7646349, 0.7720375, 0.7796607, 0.77086306, 0.9873307, 0.98398566, 0.97464967, 0.9673699, 0.96630764, 0.96156037, 0.96288776, 0.96187925, 0.95535886, 0.9543388, 0.9503468, 0.94486547, 0.9411509, 0.934031, 0.9201778, 0.916136, 0.91285276, 0.9096397, 0.90949774, 0.9064703, 0.8951926, 0.89412487, 0.8837879, 0.88685393, 0.88402843, 0.87052584, 0.87723756, 0.8761071, 0.862434, 0.85499233, 0.8589542, 0.8480696, 0.84452236, 0.84862375, 0.84663224, 0.8394518, 0.84107184, 0.83447695, 0.84023595, 0.8254758, 0.82910603, 0.81801265, 0.8147676, 0.816388, 0.79966307, 0.8090402, 0.8054824, 0.7926601, 0.80353534, 0.8021076, 0.7964171, 0.792981, 0.787733, 0.7746749, 0.78233826, 0.7883328, 0.78178406, 0.792076, 0.79864085, 0.7975651, 0.9776145, 0.9804784, 0.9641516, 0.9595159, 0.9616256, 0.9531765, 0.95329595, 0.9519768, 0.95067334, 0.9434352, 0.94392705, 0.9409368, 0.92889524, 0.9307282, 0.92094433, 0.9172914, 0.91639435, 0.9074564, 0.9112278, 0.90218484, 0.90268064, 0.8890896, 0.8932047, 0.8933536, 0.8811455, 0.88481236, 0.8825809, 0.86679816, 0.87356865, 0.8667357, 0.86667657, 0.85486776, 0.84977025, 0.853995, 0.8508589, 0.8427502, 0.8470744, 0.84302044, 0.8448595, 0.8344648, 0.8359356, 0.8365105, 0.8262213, 0.8258394, 0.803501, 0.8125106, 0.8132769, 0.7958504, 0.8051104, 0.8019396, 0.7962568, 0.80272293, 0.7925796, 0.77886325, 0.7890812, 0.7903446, 0.7795611, 0.79275405, 0.8017911, 0.79384774, 0.8540997, 0.8901796, 0.921515, 0.9395826, 0.9569399, 0.96628827, 0.96423835, 0.96840274, 0.9613475, 0.9538873, 0.9548915, 0.9522494, 0.9461882, 0.94239575, 0.9285454, 0.9247808, 0.92462176, 0.92306274, 0.9222718, 0.91782016, 0.90583175, 0.9038327, 0.89479923, 0.8985271, 0.8983947, 0.888208, 0.89434713, 0.8898147, 0.87930924, 0.8723272, 0.8756588, 0.8675998, 0.86403614, 0.86851877, 0.8608172, 0.8557388, 0.8581991, 0.85474426, 0.86166245, 0.8470467, 0.8515982, 0.8406681, 0.8390403, 0.8409813, 0.82858473, 0.8339996, 0.83503574, 0.8245495, 0.830914, 0.8280203, 0.8249298, 0.8224153, 0.81856483, 0.8107438, 0.8108261, 0.81455594, 0.8074475, 0.8116745, 0.81731176, 0.8152034, 0.8470092, 0.8881987, 0.91509384, 0.9328728, 0.95187986, 0.9577244, 0.95404416, 0.9613322, 0.95240414, 0.94905096, 0.94957334, 0.947634, 0.9374139, 0.9435325, 0.9293236, 0.9295875, 0.9237774, 0.91758794, 0.91975385, 0.91008633, 0.91939574, 0.8994135, 0.9068399, 0.9037627, 0.8952555, 0.89791226, 0.895866, 0.8845034, 0.8889927, 0.8814826, 0.88313127, 0.8719185, 0.87057877, 0.87346387, 0.8694902, 0.8604017, 0.8643573, 0.8617975, 0.8628764, 0.85486597, 0.8546789, 0.85646105, 0.8494833, 0.84823984, 0.8304525, 0.83874124, 0.8395221, 0.82667476, 0.832784, 0.8317138, 0.82640034, 0.8270711, 0.820741, 0.8124036, 0.81792164, 0.81564957, 0.8077239, 0.8136874, 0.8199841, 0.81126547]\n",
      "real: [0.981547760081002, 0.9783191107815529, 0.9720577829193665, 0.9677396187742875, 0.9637116538750307, 0.9613671533599215, 0.9566656962781115, 0.953212542304319, 0.9498307232149187, 0.9465717478639696, 0.9431893727029631, 0.9396172370027812, 0.9360453538976621, 0.9291805798075792, 0.9209527681953381, 0.9169270262172543, 0.9128542038766607, 0.9088717651351773, 0.9047587318552943, 0.9009867628597049, 0.8975242670665129, 0.89356647886204, 0.889644455237089, 0.886559405548693, 0.882733673476862, 0.8783059377512253, 0.8755645180191589, 0.8720300673473934, 0.8677529298076447, 0.859049156094731, 0.8569053494588545, 0.8518659950843436, 0.8502900122036473, 0.8480130356323287, 0.8446500805166606, 0.841138508684198, 0.8389571854909209, 0.8353695575997965, 0.8323632134517919, 0.828285810677856, 0.8255674607740809, 0.8199044530181538, 0.8132637498839883, 0.8102378979509867, 0.8072248070938493, 0.8059270278970738, 0.8029878307438708, 0.7989619033515942, 0.7983664753623245, 0.795802133196813, 0.7929682964599739, 0.7898693760651792, 0.787094046764988, 0.7830793400015471, 0.7820526502569298, 0.7795097506490353, 0.7759194636010017, 0.7754683610116903, 0.7730019872724594, 0.7737297038317591, 0.9789170845010232, 0.9723672398307521, 0.9678773262663203, 0.9636427140275626, 0.9632185045488699, 0.9580565260869475, 0.9547662648076788, 0.9517189050078657, 0.9486765256146883, 0.9457208157871942, 0.9427227872812818, 0.9399386291466334, 0.9349932513640985, 0.9288261894143705, 0.9254616695294128, 0.9221886563805027, 0.9188509699068458, 0.915816124993008, 0.9126536853065345, 0.9084989643628255, 0.9045647794981047, 0.9001612571956726, 0.8968866389327226, 0.8929720540671963, 0.8882457041155193, 0.8853800684167759, 0.8817096842753251, 0.8775402352158715, 0.8748208528209546, 0.8690810995476573, 0.8664810011514761, 0.8584888288239728, 0.858485841898706, 0.8559350369552029, 0.8523736538708621, 0.8479998113360429, 0.8457039847828337, 0.8419061496798198, 0.8385197021325397, 0.8343807998896714, 0.8321302164642305, 0.8257754683189632, 0.8190368263008624, 0.8156278584531853, 0.8108817253184123, 0.8097847912294613, 0.8066945905966949, 0.8016366439768062, 0.8009507504538506, 0.7978916242141426, 0.7951029470395748, 0.7918041093370152, 0.7888178498047248, 0.7839453521484476, 0.7835187764569512, 0.7806061992059281, 0.7751915070668952, 0.776400843070294, 0.7736816546951972, 0.7739719787425552, 0.981547760081002, 0.9783191107815529, 0.9720577829193665, 0.9677396187742875, 0.9637116538750307, 0.9613671533599215, 0.9566656962781115, 0.953212542304319, 0.9498307232149187, 0.9465717478639696, 0.9431893727029631, 0.9396172370027812, 0.9360453538976621, 0.9291805798075792, 0.9209527681953381, 0.9169270262172543, 0.9128542038766607, 0.9088717651351773, 0.9047587318552943, 0.9009867628597049, 0.8975242670665129, 0.89356647886204, 0.889644455237089, 0.886559405548693, 0.882733673476862, 0.8783059377512253, 0.8755645180191589, 0.8720300673473934, 0.8677529298076447, 0.859049156094731, 0.8569053494588545, 0.8518659950843436, 0.8502900122036473, 0.8480130356323287, 0.8446500805166606, 0.841138508684198, 0.8389571854909209, 0.8353695575997965, 0.8323632134517919, 0.828285810677856, 0.8255674607740809, 0.8199044530181538, 0.8132637498839883, 0.8102378979509867, 0.8072248070938493, 0.8059270278970738, 0.8029878307438708, 0.7989619033515942, 0.7983664753623245, 0.795802133196813, 0.7929682964599739, 0.7898693760651792, 0.787094046764988, 0.7830793400015471, 0.7820526502569298, 0.7795097506490353, 0.7759194636010017, 0.7754683610116903, 0.7730019872724594, 0.7737297038317591, 0.9789170845010232, 0.9723672398307521, 0.9678773262663203, 0.9636427140275626, 0.9632185045488699, 0.9580565260869475, 0.9547662648076788, 0.9517189050078657, 0.9486765256146883, 0.9457208157871942, 0.9427227872812818, 0.9399386291466334, 0.9349932513640985, 0.9288261894143705, 0.9254616695294128, 0.9221886563805027, 0.9188509699068458, 0.915816124993008, 0.9126536853065345, 0.9084989643628255, 0.9045647794981047, 0.9001612571956726, 0.8968866389327226, 0.8929720540671963, 0.8882457041155193, 0.8853800684167759, 0.8817096842753251, 0.8775402352158715, 0.8748208528209546, 0.8690810995476573, 0.8664810011514761, 0.8584888288239728, 0.858485841898706, 0.8559350369552029, 0.8523736538708621, 0.8479998113360429, 0.8457039847828337, 0.8419061496798198, 0.8385197021325397, 0.8343807998896714, 0.8321302164642305, 0.8257754683189632, 0.8190368263008624, 0.8156278584531853, 0.8108817253184123, 0.8097847912294613, 0.8066945905966949, 0.8016366439768062, 0.8009507504538506, 0.7978916242141426, 0.7951029470395748, 0.7918041093370152, 0.7888178498047248, 0.7839453521484476, 0.7835187764569512, 0.7806061992059281, 0.7751915070668952, 0.776400843070294, 0.7736816546951972, 0.7739719787425552, 0.981547760081002, 0.9783191107815529, 0.9720577829193665, 0.9677396187742875, 0.9637116538750307, 0.9613671533599215, 0.9566656962781115, 0.953212542304319, 0.9498307232149187, 0.9465717478639696, 0.9431893727029631, 0.9396172370027812, 0.9360453538976621, 0.9291805798075792, 0.9209527681953381, 0.9169270262172543, 0.9128542038766607, 0.9088717651351773, 0.9047587318552943, 0.9009867628597049, 0.8975242670665129, 0.89356647886204, 0.889644455237089, 0.886559405548693, 0.882733673476862, 0.8783059377512253, 0.8755645180191589, 0.8720300673473934, 0.8677529298076447, 0.859049156094731, 0.8569053494588545, 0.8518659950843436, 0.8502900122036473, 0.8480130356323287, 0.8446500805166606, 0.841138508684198, 0.8389571854909209, 0.8353695575997965, 0.8323632134517919, 0.828285810677856, 0.8255674607740809, 0.8199044530181538, 0.8132637498839883, 0.8102378979509867, 0.8072248070938493, 0.8059270278970738, 0.8029878307438708, 0.7989619033515942, 0.7983664753623245, 0.795802133196813, 0.7929682964599739, 0.7898693760651792, 0.787094046764988, 0.7830793400015471, 0.7820526502569298, 0.7795097506490353, 0.7759194636010017, 0.7754683610116903, 0.7730019872724594, 0.7737297038317591, 0.9789170845010232, 0.9723672398307521, 0.9678773262663203, 0.9636427140275626, 0.9632185045488699, 0.9580565260869475, 0.9547662648076788, 0.9517189050078657, 0.9486765256146883, 0.9457208157871942, 0.9427227872812818, 0.9399386291466334, 0.9349932513640985, 0.9288261894143705, 0.9254616695294128, 0.9221886563805027, 0.9188509699068458, 0.915816124993008, 0.9126536853065345, 0.9084989643628255, 0.9045647794981047, 0.9001612571956726, 0.8968866389327226, 0.8929720540671963, 0.8882457041155193, 0.8853800684167759, 0.8817096842753251, 0.8775402352158715, 0.8748208528209546, 0.8690810995476573, 0.8664810011514761, 0.8584888288239728, 0.858485841898706, 0.8559350369552029, 0.8523736538708621, 0.8479998113360429, 0.8457039847828337, 0.8419061496798198, 0.8385197021325397, 0.8343807998896714, 0.8321302164642305, 0.8257754683189632, 0.8190368263008624, 0.8156278584531853, 0.8108817253184123, 0.8097847912294613, 0.8066945905966949, 0.8016366439768062, 0.8009507504538506, 0.7978916242141426, 0.7951029470395748, 0.7918041093370152, 0.7888178498047248, 0.7839453521484476, 0.7835187764569512, 0.7806061992059281, 0.7751915070668952, 0.776400843070294, 0.7736816546951972, 0.7739719787425552, 0.981547760081002, 0.9783191107815529, 0.9720577829193665, 0.9677396187742875, 0.9637116538750307, 0.9613671533599215, 0.9566656962781115, 0.953212542304319, 0.9498307232149187, 0.9465717478639696, 0.9431893727029631, 0.9396172370027812, 0.9360453538976621, 0.9291805798075792, 0.9209527681953381, 0.9169270262172543, 0.9128542038766607, 0.9088717651351773, 0.9047587318552943, 0.9009867628597049, 0.8975242670665129, 0.89356647886204, 0.889644455237089, 0.886559405548693, 0.882733673476862, 0.8783059377512253, 0.8755645180191589, 0.8720300673473934, 0.8677529298076447, 0.859049156094731, 0.8569053494588545, 0.8518659950843436, 0.8502900122036473, 0.8480130356323287, 0.8446500805166606, 0.841138508684198, 0.8389571854909209, 0.8353695575997965, 0.8323632134517919, 0.828285810677856, 0.8255674607740809, 0.8199044530181538, 0.8132637498839883, 0.8102378979509867, 0.8072248070938493, 0.8059270278970738, 0.8029878307438708, 0.7989619033515942, 0.7983664753623245, 0.795802133196813, 0.7929682964599739, 0.7898693760651792, 0.787094046764988, 0.7830793400015471, 0.7820526502569298, 0.7795097506490353, 0.7759194636010017, 0.7754683610116903, 0.7730019872724594, 0.7737297038317591, 0.9789170845010232, 0.9723672398307521, 0.9678773262663203, 0.9636427140275626, 0.9632185045488699, 0.9580565260869475, 0.9547662648076788, 0.9517189050078657, 0.9486765256146883, 0.9457208157871942, 0.9427227872812818, 0.9399386291466334, 0.9349932513640985, 0.9288261894143705, 0.9254616695294128, 0.9221886563805027, 0.9188509699068458, 0.915816124993008, 0.9126536853065345, 0.9084989643628255, 0.9045647794981047, 0.9001612571956726, 0.8968866389327226, 0.8929720540671963, 0.8882457041155193, 0.8853800684167759, 0.8817096842753251, 0.8775402352158715, 0.8748208528209546, 0.8690810995476573, 0.8664810011514761, 0.8584888288239728, 0.858485841898706, 0.8559350369552029, 0.8523736538708621, 0.8479998113360429, 0.8457039847828337, 0.8419061496798198, 0.8385197021325397, 0.8343807998896714, 0.8321302164642305, 0.8257754683189632, 0.8190368263008624, 0.8156278584531853, 0.8108817253184123, 0.8097847912294613, 0.8066945905966949, 0.8016366439768062, 0.8009507504538506, 0.7978916242141426, 0.7951029470395748, 0.7918041093370152, 0.7888178498047248, 0.7839453521484476, 0.7835187764569512, 0.7806061992059281, 0.7751915070668952, 0.776400843070294, 0.7736816546951972, 0.7739719787425552]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_all=[]\n",
    "mae_all=[]\n",
    "mape_all=[]\n",
    "r2=[]\n",
    "num=0\n",
    "test_csv_c=[]\n",
    "real_csv_c=[]\n",
    "for i in range(4):\n",
    "    for j in range(len(tests[0])):\n",
    "        real,pred=tests_cnn[i][j][0],tests_cnn[i][j][1].reshape(-1)\n",
    "        rmse=evaluation(real,pred)\n",
    "        if rmse>=0.00:\n",
    "            rmse_all.append(rmse)\n",
    "            for pre,rea in zip(pred,real):\n",
    "                test_csv_c.append(pre)\n",
    "                real_csv_c.append(rea)\n",
    "        mae_all.append(calculate_mae(real,pred))\n",
    "        mape_all.append(mape(real,pred))\n",
    "        r2.append(r_squared(real,pred))\n",
    "        num+=1\n",
    "print(\"RMSE:\",rmse_all)\n",
    "print(\"test:\",test_csv_c)\n",
    "print('real:',real_csv_c)\n",
    "len(test_csv_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "95e925a3d012bf5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T11:08:16.942662Z",
     "start_time": "2025-03-20T11:08:16.930206Z"
    }
   },
   "outputs": [],
   "source": [
    "class LSTMNetwork(nn.Module):\n",
    "    def __init__(self, input_size=7, hidden_size=60, num_layers=8, output_size=1):\n",
    "        \"\"\"\n",
    "        LSTM网络初始化\n",
    "        :param input_size: 输入特征的维度 (n)\n",
    "        :param hidden_size: 隐藏层的维度\n",
    "        :param num_layers: LSTM的层数\n",
    "        :param output_size: 输出的维度 (1)\n",
    "        \"\"\"\n",
    "        super(LSTMNetwork, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # 定义LSTM层\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "        # 定义全连接层，将LSTM的输出映射到输出维度\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        :param x: 输入数据，形状为 (batch_size, input_size)\n",
    "        :return: 输出数据，形状为 (batch_size, output_size)\n",
    "        \"\"\"\n",
    "        # 添加序列维度 (sequence_length=1)\n",
    "        x = x.unsqueeze(1)  # 形状变为 (batch_size, 1, input_size)\n",
    "\n",
    "        # 初始化隐藏状态和细胞状态\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # LSTM前向传播\n",
    "        out, _ = self.lstm(x, (h0, c0))  # out的形状为 (batch_size, 1, hidden_size)\n",
    "\n",
    "        # 只取最后一个时间步的输出\n",
    "        out = out[:, -1, :]  # 形状为 (batch_size, hidden_size)\n",
    "\n",
    "        # 全连接层映射到输出维度\n",
    "        out = self.fc(out)  # 形状为 (batch_size, output_size)\n",
    "\n",
    "        return out\n",
    "\n",
    "def train_lstm(lr=0.001,epochs=150, weight_decay=1e-4, seed=0, metric='rmse', device='cpu'):\n",
    "    \"\"\"function for train\"\"\"\n",
    "    \"\"\"function for train\"\"\"\n",
    "    setup_seed(seed)\n",
    "    print(\"training seed \"+str(seed)+':\\n')\n",
    "    train_loader, val_loader, test_35_data, test_36_data=get_data()\n",
    "    test_data=[test_35_data, test_36_data]\n",
    "    model = ConvNet()\n",
    "    model=model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.MSELoss()\n",
    "    len_dataloader = len(train_loader)\n",
    "    test_results=[]\n",
    "    \"\"\"早停止获取最佳模型\"\"\"\n",
    "    val_mse=10\n",
    "    for epoch in range(epochs):\n",
    "        loss_epoch=0\n",
    "        for X,y in train_loader:\n",
    "            X,y = X.to(device), y.to(device)\n",
    "            y_pred= model(X)\n",
    "            y_pred = y_pred.squeeze(1)\n",
    "            loss = criterion(y_pred,y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_epoch += loss\n",
    "        if (epoch+1)%5==0 and epoch!=0:\n",
    "            print('Epoch:',epoch+1,'Train_RMSELoss:',loss_epoch/len_dataloader,'\\n')\n",
    "        if (epoch+1)%5==0 and epoch!=0:\n",
    "            val_loss=0\n",
    "            for val_x,val_y in val_loader:\n",
    "                val_x,val_y=val_x.to(device),val_y.to(device)\n",
    "                pre=model(val_x)\n",
    "                val_loss+=criterion(pre.squeeze(1),val_y).detach()    \n",
    "            print('Epoch:',epoch+1,'valid_RMSELoss:',val_loss/len(val_loader),'\\n')\n",
    "            val_mse=val_loss/len(val_loader)\n",
    "                \n",
    "        if (val_mse<0.5e-4 and epoch>=35)or (epoch+1)==epochs:\n",
    "            model=model.cpu()\n",
    "            \n",
    "            for name in test_data:\n",
    "                X=torch.from_numpy(name[0]).float()\n",
    "                y=name[1]\n",
    "                y_pred=model(X)\n",
    "                y_pred= y_pred.squeeze(0).detach().numpy()\n",
    "                test_results.append([y,y_pred])\n",
    "            break\n",
    "    return test_results\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ad8c59993f9b9c59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T11:08:20.881019Z",
     "start_time": "2025-03-20T11:08:17.548897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training seed 0:\n",
      "\n",
      "Epoch: 5 Train_RMSELoss: tensor(0.2231, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 5 valid_RMSELoss: tensor(0.2034, device='cuda:0') \n",
      "\n",
      "Epoch: 10 Train_RMSELoss: tensor(0.1293, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 10 valid_RMSELoss: tensor(0.1216, device='cuda:0') \n",
      "\n",
      "Epoch: 15 Train_RMSELoss: tensor(0.0328, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 15 valid_RMSELoss: tensor(0.0239, device='cuda:0') \n",
      "\n",
      "Epoch: 20 Train_RMSELoss: tensor(0.0094, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 20 valid_RMSELoss: tensor(0.0094, device='cuda:0') \n",
      "\n",
      "Epoch: 25 Train_RMSELoss: tensor(0.0026, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 25 valid_RMSELoss: tensor(0.0048, device='cuda:0') \n",
      "\n",
      "Epoch: 30 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 30 valid_RMSELoss: tensor(0.0005, device='cuda:0') \n",
      "\n",
      "Epoch: 35 Train_RMSELoss: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 35 valid_RMSELoss: tensor(0.0006, device='cuda:0') \n",
      "\n",
      "Epoch: 40 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 40 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 45 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 45 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 50 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 50 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 55 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 55 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 60 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 60 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 65 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 65 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 70 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 70 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 75 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 75 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 80 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 80 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 85 Train_RMSELoss: tensor(8.7977e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 85 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 90 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 90 valid_RMSELoss: tensor(0.0006, device='cuda:0') \n",
      "\n",
      "Epoch: 95 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 95 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 100 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 100 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 105 Train_RMSELoss: tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 105 valid_RMSELoss: tensor(0.0005, device='cuda:0') \n",
      "\n",
      "Epoch: 110 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 110 valid_RMSELoss: tensor(0.0009, device='cuda:0') \n",
      "\n",
      "Epoch: 115 Train_RMSELoss: tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 115 valid_RMSELoss: tensor(0.0013, device='cuda:0') \n",
      "\n",
      "Epoch: 120 Train_RMSELoss: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 120 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 125 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 125 valid_RMSELoss: tensor(0.0010, device='cuda:0') \n",
      "\n",
      "Epoch: 130 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 130 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 135 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 135 valid_RMSELoss: tensor(0.0005, device='cuda:0') \n",
      "\n",
      "Epoch: 140 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 140 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 145 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 145 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 150 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 150 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "training seed 1:\n",
      "\n",
      "Epoch: 5 Train_RMSELoss: tensor(0.3663, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 5 valid_RMSELoss: tensor(0.2457, device='cuda:0') \n",
      "\n",
      "Epoch: 10 Train_RMSELoss: tensor(0.2548, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 10 valid_RMSELoss: tensor(0.1855, device='cuda:0') \n",
      "\n",
      "Epoch: 15 Train_RMSELoss: tensor(0.1570, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 15 valid_RMSELoss: tensor(0.1177, device='cuda:0') \n",
      "\n",
      "Epoch: 20 Train_RMSELoss: tensor(0.0439, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 20 valid_RMSELoss: tensor(0.0245, device='cuda:0') \n",
      "\n",
      "Epoch: 25 Train_RMSELoss: tensor(0.0081, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 25 valid_RMSELoss: tensor(0.0134, device='cuda:0') \n",
      "\n",
      "Epoch: 30 Train_RMSELoss: tensor(0.0028, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 30 valid_RMSELoss: tensor(0.0026, device='cuda:0') \n",
      "\n",
      "Epoch: 35 Train_RMSELoss: tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 35 valid_RMSELoss: tensor(0.0018, device='cuda:0') \n",
      "\n",
      "Epoch: 40 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 40 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 45 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 45 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 50 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 50 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 55 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 55 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 60 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 60 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 65 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 65 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 70 Train_RMSELoss: tensor(6.8922e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 70 valid_RMSELoss: tensor(8.7305e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 75 Train_RMSELoss: tensor(5.0907e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 75 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 80 Train_RMSELoss: tensor(3.2434e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 80 valid_RMSELoss: tensor(9.5012e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 85 Train_RMSELoss: tensor(3.0133e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 85 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 90 Train_RMSELoss: tensor(3.4075e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 90 valid_RMSELoss: tensor(6.8875e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 95 Train_RMSELoss: tensor(3.1524e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 95 valid_RMSELoss: tensor(8.5847e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 100 Train_RMSELoss: tensor(3.4514e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 100 valid_RMSELoss: tensor(8.1890e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 105 Train_RMSELoss: tensor(5.0725e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 105 valid_RMSELoss: tensor(6.7878e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 110 Train_RMSELoss: tensor(5.1856e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 110 valid_RMSELoss: tensor(6.9924e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 115 Train_RMSELoss: tensor(3.4855e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 115 valid_RMSELoss: tensor(6.3986e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 120 Train_RMSELoss: tensor(2.9549e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 120 valid_RMSELoss: tensor(7.8177e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 125 Train_RMSELoss: tensor(3.5908e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 125 valid_RMSELoss: tensor(6.4459e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 130 Train_RMSELoss: tensor(3.3552e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 130 valid_RMSELoss: tensor(6.3687e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 135 Train_RMSELoss: tensor(4.4981e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 135 valid_RMSELoss: tensor(7.3523e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 140 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 140 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 145 Train_RMSELoss: tensor(7.0764e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 145 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 150 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 150 valid_RMSELoss: tensor(7.7373e-05, device='cuda:0') \n",
      "\n",
      "training seed 2:\n",
      "\n",
      "Epoch: 5 Train_RMSELoss: tensor(0.4086, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 5 valid_RMSELoss: tensor(1.0478, device='cuda:0') \n",
      "\n",
      "Epoch: 10 Train_RMSELoss: tensor(0.3756, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 10 valid_RMSELoss: tensor(0.2270, device='cuda:0') \n",
      "\n",
      "Epoch: 15 Train_RMSELoss: tensor(0.2521, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 15 valid_RMSELoss: tensor(0.4809, device='cuda:0') \n",
      "\n",
      "Epoch: 20 Train_RMSELoss: tensor(0.1344, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 20 valid_RMSELoss: tensor(0.1326, device='cuda:0') \n",
      "\n",
      "Epoch: 25 Train_RMSELoss: tensor(0.0154, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 25 valid_RMSELoss: tensor(0.0158, device='cuda:0') \n",
      "\n",
      "Epoch: 30 Train_RMSELoss: tensor(0.0129, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 30 valid_RMSELoss: tensor(0.0064, device='cuda:0') \n",
      "\n",
      "Epoch: 35 Train_RMSELoss: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 35 valid_RMSELoss: tensor(0.0040, device='cuda:0') \n",
      "\n",
      "Epoch: 40 Train_RMSELoss: tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 40 valid_RMSELoss: tensor(0.0013, device='cuda:0') \n",
      "\n",
      "Epoch: 45 Train_RMSELoss: tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 45 valid_RMSELoss: tensor(0.0014, device='cuda:0') \n",
      "\n",
      "Epoch: 50 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 50 valid_RMSELoss: tensor(0.0005, device='cuda:0') \n",
      "\n",
      "Epoch: 55 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 55 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 60 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 60 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 65 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 65 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 70 Train_RMSELoss: tensor(8.0183e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 70 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 75 Train_RMSELoss: tensor(5.8888e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 75 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 80 Train_RMSELoss: tensor(8.3435e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 80 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 85 Train_RMSELoss: tensor(6.0758e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 85 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 90 Train_RMSELoss: tensor(8.5436e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 90 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 95 Train_RMSELoss: tensor(5.5357e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 95 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 100 Train_RMSELoss: tensor(8.3101e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 100 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 105 Train_RMSELoss: tensor(8.3633e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 105 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 110 Train_RMSELoss: tensor(4.2372e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 110 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 115 Train_RMSELoss: tensor(9.7351e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 115 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 120 Train_RMSELoss: tensor(6.9863e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 120 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 125 Train_RMSELoss: tensor(4.7783e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 125 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 130 Train_RMSELoss: tensor(5.7690e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 130 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 135 Train_RMSELoss: tensor(4.3764e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 135 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 140 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 140 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 145 Train_RMSELoss: tensor(6.5614e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 145 valid_RMSELoss: tensor(9.3286e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 150 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 150 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "training seed 3:\n",
      "\n",
      "Epoch: 5 Train_RMSELoss: tensor(0.1635, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 5 valid_RMSELoss: tensor(0.1801, device='cuda:0') \n",
      "\n",
      "Epoch: 10 Train_RMSELoss: tensor(0.0914, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 10 valid_RMSELoss: tensor(0.1240, device='cuda:0') \n",
      "\n",
      "Epoch: 15 Train_RMSELoss: tensor(0.0377, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 15 valid_RMSELoss: tensor(0.0520, device='cuda:0') \n",
      "\n",
      "Epoch: 20 Train_RMSELoss: tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 20 valid_RMSELoss: tensor(0.0029, device='cuda:0') \n",
      "\n",
      "Epoch: 25 Train_RMSELoss: tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 25 valid_RMSELoss: tensor(0.0021, device='cuda:0') \n",
      "\n",
      "Epoch: 30 Train_RMSELoss: tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 30 valid_RMSELoss: tensor(0.0044, device='cuda:0') \n",
      "\n",
      "Epoch: 35 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 35 valid_RMSELoss: tensor(0.0016, device='cuda:0') \n",
      "\n",
      "Epoch: 40 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 40 valid_RMSELoss: tensor(0.0013, device='cuda:0') \n",
      "\n",
      "Epoch: 45 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 45 valid_RMSELoss: tensor(0.0016, device='cuda:0') \n",
      "\n",
      "Epoch: 50 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 50 valid_RMSELoss: tensor(0.0012, device='cuda:0') \n",
      "\n",
      "Epoch: 55 Train_RMSELoss: tensor(8.5672e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 55 valid_RMSELoss: tensor(0.0011, device='cuda:0') \n",
      "\n",
      "Epoch: 60 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 60 valid_RMSELoss: tensor(0.0010, device='cuda:0') \n",
      "\n",
      "Epoch: 65 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 65 valid_RMSELoss: tensor(0.0009, device='cuda:0') \n",
      "\n",
      "Epoch: 70 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 70 valid_RMSELoss: tensor(0.0011, device='cuda:0') \n",
      "\n",
      "Epoch: 75 Train_RMSELoss: tensor(7.1908e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 75 valid_RMSELoss: tensor(0.0009, device='cuda:0') \n",
      "\n",
      "Epoch: 80 Train_RMSELoss: tensor(5.6419e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 80 valid_RMSELoss: tensor(0.0009, device='cuda:0') \n",
      "\n",
      "Epoch: 85 Train_RMSELoss: tensor(7.3148e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 85 valid_RMSELoss: tensor(0.0009, device='cuda:0') \n",
      "\n",
      "Epoch: 90 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 90 valid_RMSELoss: tensor(0.0009, device='cuda:0') \n",
      "\n",
      "Epoch: 95 Train_RMSELoss: tensor(8.9687e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 95 valid_RMSELoss: tensor(0.0010, device='cuda:0') \n",
      "\n",
      "Epoch: 100 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 100 valid_RMSELoss: tensor(0.0008, device='cuda:0') \n",
      "\n",
      "Epoch: 105 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 105 valid_RMSELoss: tensor(0.0011, device='cuda:0') \n",
      "\n",
      "Epoch: 110 Train_RMSELoss: tensor(5.4692e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 110 valid_RMSELoss: tensor(0.0008, device='cuda:0') \n",
      "\n",
      "Epoch: 115 Train_RMSELoss: tensor(5.2508e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 115 valid_RMSELoss: tensor(0.0008, device='cuda:0') \n",
      "\n",
      "Epoch: 120 Train_RMSELoss: tensor(7.6705e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 120 valid_RMSELoss: tensor(0.0008, device='cuda:0') \n",
      "\n",
      "Epoch: 125 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 125 valid_RMSELoss: tensor(0.0010, device='cuda:0') \n",
      "\n",
      "Epoch: 130 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 130 valid_RMSELoss: tensor(0.0009, device='cuda:0') \n",
      "\n",
      "Epoch: 135 Train_RMSELoss: tensor(8.2665e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 135 valid_RMSELoss: tensor(0.0009, device='cuda:0') \n",
      "\n",
      "Epoch: 140 Train_RMSELoss: tensor(3.8109e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 140 valid_RMSELoss: tensor(0.0008, device='cuda:0') \n",
      "\n",
      "Epoch: 145 Train_RMSELoss: tensor(5.3981e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 145 valid_RMSELoss: tensor(0.0009, device='cuda:0') \n",
      "\n",
      "Epoch: 150 Train_RMSELoss: tensor(6.3191e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 150 valid_RMSELoss: tensor(0.0008, device='cuda:0') \n",
      "\n",
      "training seed 4:\n",
      "\n",
      "Epoch: 5 Train_RMSELoss: tensor(0.2505, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 5 valid_RMSELoss: tensor(0.2133, device='cuda:0') \n",
      "\n",
      "Epoch: 10 Train_RMSELoss: tensor(0.1463, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 10 valid_RMSELoss: tensor(0.1910, device='cuda:0') \n",
      "\n",
      "Epoch: 15 Train_RMSELoss: tensor(0.0188, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 15 valid_RMSELoss: tensor(0.0347, device='cuda:0') \n",
      "\n",
      "Epoch: 20 Train_RMSELoss: tensor(0.0138, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 20 valid_RMSELoss: tensor(0.0067, device='cuda:0') \n",
      "\n",
      "Epoch: 25 Train_RMSELoss: tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 25 valid_RMSELoss: tensor(0.0100, device='cuda:0') \n",
      "\n",
      "Epoch: 30 Train_RMSELoss: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 30 valid_RMSELoss: tensor(0.0009, device='cuda:0') \n",
      "\n",
      "Epoch: 35 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 35 valid_RMSELoss: tensor(0.0005, device='cuda:0') \n",
      "\n",
      "Epoch: 40 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 40 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 45 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 45 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 50 Train_RMSELoss: tensor(8.2170e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 50 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 55 Train_RMSELoss: tensor(5.7066e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 55 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 60 Train_RMSELoss: tensor(5.3926e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 60 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 65 Train_RMSELoss: tensor(4.3147e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 65 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 70 Train_RMSELoss: tensor(3.6159e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 70 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 75 Train_RMSELoss: tensor(5.2613e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 75 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 80 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 80 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 85 Train_RMSELoss: tensor(5.7597e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 85 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 90 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 90 valid_RMSELoss: tensor(0.0006, device='cuda:0') \n",
      "\n",
      "Epoch: 95 Train_RMSELoss: tensor(6.9122e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 95 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 100 Train_RMSELoss: tensor(6.3700e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 100 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 105 Train_RMSELoss: tensor(3.9211e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 105 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 110 Train_RMSELoss: tensor(3.3305e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 110 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 115 Train_RMSELoss: tensor(3.3122e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 115 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 120 Train_RMSELoss: tensor(5.3581e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 120 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 125 Train_RMSELoss: tensor(3.8446e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 125 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 130 Train_RMSELoss: tensor(5.5551e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 130 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 135 Train_RMSELoss: tensor(3.3877e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 135 valid_RMSELoss: tensor(0.0005, device='cuda:0') \n",
      "\n",
      "Epoch: 140 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 140 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 145 Train_RMSELoss: tensor(3.7631e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 145 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 150 Train_RMSELoss: tensor(7.1886e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 150 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tests_lstm=[]\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "for i in range(5):\n",
    "    test_result=train_lstm(seed=i,device=device)\n",
    "    tests_lstm.append(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1e0910ea9306a4dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T11:08:36.509581Z",
     "start_time": "2025-03-20T11:08:36.492894Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: [0.011139777170736768, 0.00943706538333564, 0.009190314113245173, 0.00859194635363915, 0.006808533028591805, 0.007392834235689803, 0.025182748267340627, 0.02528002333529779]\n",
      "test: [0.96285355, 0.96507096, 0.9799489, 0.97558045, 0.9732497, 0.9709543, 0.96489346, 0.9690279, 0.9659172, 0.9587381, 0.957013, 0.9541936, 0.9473741, 0.9427943, 0.9311254, 0.9273033, 0.92681706, 0.9238987, 0.9208176, 0.9154465, 0.9049188, 0.9019022, 0.89380157, 0.8950963, 0.8937149, 0.88482, 0.8879218, 0.88277674, 0.87375724, 0.86705685, 0.8679931, 0.8595048, 0.85411704, 0.85515356, 0.8461671, 0.8398782, 0.8397573, 0.8359028, 0.83971953, 0.82720697, 0.8292171, 0.81947505, 0.81687725, 0.8169235, 0.80739784, 0.8105538, 0.8111073, 0.8033253, 0.8077272, 0.80587435, 0.8040832, 0.8026023, 0.80022407, 0.795323, 0.79533446, 0.79814684, 0.7918786, 0.79378116, 0.7970772, 0.7925036, 0.95625114, 0.9632498, 0.97429895, 0.96957386, 0.9686761, 0.96360207, 0.9563066, 0.964051, 0.9586408, 0.9556184, 0.9528589, 0.9505725, 0.94075346, 0.94390786, 0.9317007, 0.9312383, 0.9257858, 0.91939116, 0.9185102, 0.9093754, 0.9155724, 0.898617, 0.9030689, 0.8989352, 0.8913052, 0.8917843, 0.8887775, 0.8791654, 0.8809099, 0.8737463, 0.87362516, 0.86275446, 0.8593823, 0.85902345, 0.85331714, 0.843663, 0.8444009, 0.8410908, 0.84034777, 0.83299696, 0.8312241, 0.8311633, 0.8246609, 0.8222122, 0.80868566, 0.814039, 0.814095, 0.80480134, 0.8090086, 0.80856776, 0.8051462, 0.80554163, 0.80157495, 0.79629433, 0.8001301, 0.7988045, 0.79240036, 0.79547024, 0.7992135, 0.7882428, 0.979078, 0.98596305, 0.9880764, 0.9780198, 0.97146255, 0.96949303, 0.9623723, 0.9663873, 0.95741093, 0.9503066, 0.95399517, 0.9509115, 0.94127494, 0.9369971, 0.9221867, 0.91911995, 0.9199787, 0.91914296, 0.9189255, 0.91453815, 0.9005632, 0.8984178, 0.88796586, 0.8927334, 0.8929798, 0.881329, 0.8889945, 0.88401884, 0.8720803, 0.86365396, 0.8676061, 0.85793966, 0.85334134, 0.8585242, 0.8488729, 0.84257585, 0.84518135, 0.8405935, 0.8486442, 0.83036524, 0.83552235, 0.8217407, 0.81935674, 0.82130724, 0.8056026, 0.81193215, 0.81273395, 0.7992144, 0.8068723, 0.80287933, 0.79858863, 0.79503083, 0.78987724, 0.78192425, 0.7838355, 0.78988665, 0.78510183, 0.790998, 0.79846287, 0.7962901, 0.9696567, 0.9833458, 0.9795254, 0.96910447, 0.9647698, 0.95847005, 0.9497912, 0.9580248, 0.946616, 0.9449524, 0.9478173, 0.945276, 0.9305528, 0.9384834, 0.9230931, 0.92490494, 0.9188661, 0.9126399, 0.9158835, 0.9054049, 0.9166428, 0.89318913, 0.90226334, 0.8989404, 0.88925433, 0.8927588, 0.89072496, 0.8777939, 0.8835173, 0.8746302, 0.8765983, 0.8631474, 0.8613052, 0.8645229, 0.85943824, 0.8482989, 0.8527066, 0.8491853, 0.8500683, 0.83990127, 0.83922136, 0.84099513, 0.8321013, 0.8301428, 0.80796, 0.81775194, 0.8182823, 0.8019201, 0.80919087, 0.8074098, 0.8003899, 0.80088824, 0.79256743, 0.78365, 0.79102415, 0.7908796, 0.7852634, 0.79311275, 0.8012547, 0.7911636, 0.98631686, 0.9832737, 0.9737131, 0.9661494, 0.9649033, 0.9592089, 0.9610513, 0.9606753, 0.95435613, 0.9536713, 0.94972605, 0.9443591, 0.9407813, 0.9336838, 0.9195625, 0.9150898, 0.91134924, 0.90795225, 0.9073052, 0.9043706, 0.8933112, 0.89219064, 0.8819067, 0.88499576, 0.8821642, 0.8687338, 0.8754656, 0.8745386, 0.8609341, 0.85317844, 0.8568776, 0.8454748, 0.84138644, 0.84478265, 0.84186643, 0.83426434, 0.8358368, 0.82940346, 0.8351735, 0.8208363, 0.82452285, 0.81378466, 0.8106965, 0.81243557, 0.7960188, 0.8055255, 0.8020337, 0.78952867, 0.80052084, 0.79933375, 0.7938112, 0.79056555, 0.7855222, 0.77330434, 0.7811205, 0.78687626, 0.78071755, 0.79141045, 0.79815936, 0.7969689, 0.9765926, 0.979737, 0.96315676, 0.9583357, 0.9602937, 0.9508702, 0.9515814, 0.95074886, 0.9498809, 0.9426369, 0.94332904, 0.94046587, 0.9284803, 0.9302303, 0.9203226, 0.9161019, 0.9150265, 0.9058868, 0.90918666, 0.90025514, 0.9004937, 0.8871805, 0.89116937, 0.89147514, 0.87931484, 0.88306147, 0.88091165, 0.865177, 0.87203187, 0.86502606, 0.8646111, 0.852452, 0.84660035, 0.85032517, 0.8460209, 0.8375114, 0.8417223, 0.8378436, 0.8398358, 0.82969993, 0.83136326, 0.83204156, 0.82197535, 0.82180166, 0.79986787, 0.80889326, 0.80980384, 0.7926938, 0.802051, 0.79902107, 0.79358965, 0.80030733, 0.79037327, 0.7772202, 0.7878273, 0.78893954, 0.77832705, 0.7920005, 0.80120677, 0.79298145, 0.8526509, 0.8892556, 0.92185366, 0.9382361, 0.9555576, 0.96689725, 0.9651685, 0.96877277, 0.96075994, 0.9525696, 0.95258963, 0.94964164, 0.9433318, 0.93935215, 0.9253134, 0.92076635, 0.92001283, 0.91828454, 0.91718936, 0.9124491, 0.89991254, 0.8977115, 0.8884615, 0.8919377, 0.891626, 0.881275, 0.8871473, 0.882311, 0.87164617, 0.8644254, 0.8674774, 0.85923934, 0.8554288, 0.85962087, 0.85143465, 0.8461107, 0.8483304, 0.8446952, 0.85136485, 0.8365238, 0.8408249, 0.8296888, 0.8279029, 0.8295554, 0.8171736, 0.82218325, 0.8231411, 0.8124599, 0.8184156, 0.8152287, 0.81194067, 0.8091893, 0.80511314, 0.79721093, 0.79687494, 0.80044556, 0.79363376, 0.7986356, 0.8049605, 0.8033873, 0.84559625, 0.8872932, 0.9154915, 0.9315523, 0.95047534, 0.95827204, 0.9548898, 0.9617171, 0.95166165, 0.9478673, 0.9473044, 0.94501305, 0.93464625, 0.94063246, 0.92608833, 0.9256808, 0.9190696, 0.9127044, 0.91457295, 0.9046069, 0.91363037, 0.8933133, 0.90054125, 0.8971313, 0.8884837, 0.89085853, 0.8885778, 0.8771091, 0.8812773, 0.8735034, 0.87493026, 0.86349124, 0.8619859, 0.86456233, 0.86021435, 0.85079074, 0.854478, 0.85169643, 0.8524928, 0.8442948, 0.84380776, 0.84535235, 0.8382054, 0.83668935, 0.8189902, 0.82689786, 0.8273957, 0.8145561, 0.82028735, 0.81904113, 0.81344527, 0.81371725, 0.8072221, 0.7987983, 0.80392337, 0.8014831, 0.79391277, 0.8003882, 0.8072587, 0.799484]\n",
      "real: [0.981547760081002, 0.9783191107815529, 0.9720577829193665, 0.9677396187742875, 0.9637116538750307, 0.9613671533599215, 0.9566656962781115, 0.953212542304319, 0.9498307232149187, 0.9465717478639696, 0.9431893727029631, 0.9396172370027812, 0.9360453538976621, 0.9291805798075792, 0.9209527681953381, 0.9169270262172543, 0.9128542038766607, 0.9088717651351773, 0.9047587318552943, 0.9009867628597049, 0.8975242670665129, 0.89356647886204, 0.889644455237089, 0.886559405548693, 0.882733673476862, 0.8783059377512253, 0.8755645180191589, 0.8720300673473934, 0.8677529298076447, 0.859049156094731, 0.8569053494588545, 0.8518659950843436, 0.8502900122036473, 0.8480130356323287, 0.8446500805166606, 0.841138508684198, 0.8389571854909209, 0.8353695575997965, 0.8323632134517919, 0.828285810677856, 0.8255674607740809, 0.8199044530181538, 0.8132637498839883, 0.8102378979509867, 0.8072248070938493, 0.8059270278970738, 0.8029878307438708, 0.7989619033515942, 0.7983664753623245, 0.795802133196813, 0.7929682964599739, 0.7898693760651792, 0.787094046764988, 0.7830793400015471, 0.7820526502569298, 0.7795097506490353, 0.7759194636010017, 0.7754683610116903, 0.7730019872724594, 0.7737297038317591, 0.9789170845010232, 0.9723672398307521, 0.9678773262663203, 0.9636427140275626, 0.9632185045488699, 0.9580565260869475, 0.9547662648076788, 0.9517189050078657, 0.9486765256146883, 0.9457208157871942, 0.9427227872812818, 0.9399386291466334, 0.9349932513640985, 0.9288261894143705, 0.9254616695294128, 0.9221886563805027, 0.9188509699068458, 0.915816124993008, 0.9126536853065345, 0.9084989643628255, 0.9045647794981047, 0.9001612571956726, 0.8968866389327226, 0.8929720540671963, 0.8882457041155193, 0.8853800684167759, 0.8817096842753251, 0.8775402352158715, 0.8748208528209546, 0.8690810995476573, 0.8664810011514761, 0.8584888288239728, 0.858485841898706, 0.8559350369552029, 0.8523736538708621, 0.8479998113360429, 0.8457039847828337, 0.8419061496798198, 0.8385197021325397, 0.8343807998896714, 0.8321302164642305, 0.8257754683189632, 0.8190368263008624, 0.8156278584531853, 0.8108817253184123, 0.8097847912294613, 0.8066945905966949, 0.8016366439768062, 0.8009507504538506, 0.7978916242141426, 0.7951029470395748, 0.7918041093370152, 0.7888178498047248, 0.7839453521484476, 0.7835187764569512, 0.7806061992059281, 0.7751915070668952, 0.776400843070294, 0.7736816546951972, 0.7739719787425552, 0.981547760081002, 0.9783191107815529, 0.9720577829193665, 0.9677396187742875, 0.9637116538750307, 0.9613671533599215, 0.9566656962781115, 0.953212542304319, 0.9498307232149187, 0.9465717478639696, 0.9431893727029631, 0.9396172370027812, 0.9360453538976621, 0.9291805798075792, 0.9209527681953381, 0.9169270262172543, 0.9128542038766607, 0.9088717651351773, 0.9047587318552943, 0.9009867628597049, 0.8975242670665129, 0.89356647886204, 0.889644455237089, 0.886559405548693, 0.882733673476862, 0.8783059377512253, 0.8755645180191589, 0.8720300673473934, 0.8677529298076447, 0.859049156094731, 0.8569053494588545, 0.8518659950843436, 0.8502900122036473, 0.8480130356323287, 0.8446500805166606, 0.841138508684198, 0.8389571854909209, 0.8353695575997965, 0.8323632134517919, 0.828285810677856, 0.8255674607740809, 0.8199044530181538, 0.8132637498839883, 0.8102378979509867, 0.8072248070938493, 0.8059270278970738, 0.8029878307438708, 0.7989619033515942, 0.7983664753623245, 0.795802133196813, 0.7929682964599739, 0.7898693760651792, 0.787094046764988, 0.7830793400015471, 0.7820526502569298, 0.7795097506490353, 0.7759194636010017, 0.7754683610116903, 0.7730019872724594, 0.7737297038317591, 0.9789170845010232, 0.9723672398307521, 0.9678773262663203, 0.9636427140275626, 0.9632185045488699, 0.9580565260869475, 0.9547662648076788, 0.9517189050078657, 0.9486765256146883, 0.9457208157871942, 0.9427227872812818, 0.9399386291466334, 0.9349932513640985, 0.9288261894143705, 0.9254616695294128, 0.9221886563805027, 0.9188509699068458, 0.915816124993008, 0.9126536853065345, 0.9084989643628255, 0.9045647794981047, 0.9001612571956726, 0.8968866389327226, 0.8929720540671963, 0.8882457041155193, 0.8853800684167759, 0.8817096842753251, 0.8775402352158715, 0.8748208528209546, 0.8690810995476573, 0.8664810011514761, 0.8584888288239728, 0.858485841898706, 0.8559350369552029, 0.8523736538708621, 0.8479998113360429, 0.8457039847828337, 0.8419061496798198, 0.8385197021325397, 0.8343807998896714, 0.8321302164642305, 0.8257754683189632, 0.8190368263008624, 0.8156278584531853, 0.8108817253184123, 0.8097847912294613, 0.8066945905966949, 0.8016366439768062, 0.8009507504538506, 0.7978916242141426, 0.7951029470395748, 0.7918041093370152, 0.7888178498047248, 0.7839453521484476, 0.7835187764569512, 0.7806061992059281, 0.7751915070668952, 0.776400843070294, 0.7736816546951972, 0.7739719787425552, 0.981547760081002, 0.9783191107815529, 0.9720577829193665, 0.9677396187742875, 0.9637116538750307, 0.9613671533599215, 0.9566656962781115, 0.953212542304319, 0.9498307232149187, 0.9465717478639696, 0.9431893727029631, 0.9396172370027812, 0.9360453538976621, 0.9291805798075792, 0.9209527681953381, 0.9169270262172543, 0.9128542038766607, 0.9088717651351773, 0.9047587318552943, 0.9009867628597049, 0.8975242670665129, 0.89356647886204, 0.889644455237089, 0.886559405548693, 0.882733673476862, 0.8783059377512253, 0.8755645180191589, 0.8720300673473934, 0.8677529298076447, 0.859049156094731, 0.8569053494588545, 0.8518659950843436, 0.8502900122036473, 0.8480130356323287, 0.8446500805166606, 0.841138508684198, 0.8389571854909209, 0.8353695575997965, 0.8323632134517919, 0.828285810677856, 0.8255674607740809, 0.8199044530181538, 0.8132637498839883, 0.8102378979509867, 0.8072248070938493, 0.8059270278970738, 0.8029878307438708, 0.7989619033515942, 0.7983664753623245, 0.795802133196813, 0.7929682964599739, 0.7898693760651792, 0.787094046764988, 0.7830793400015471, 0.7820526502569298, 0.7795097506490353, 0.7759194636010017, 0.7754683610116903, 0.7730019872724594, 0.7737297038317591, 0.9789170845010232, 0.9723672398307521, 0.9678773262663203, 0.9636427140275626, 0.9632185045488699, 0.9580565260869475, 0.9547662648076788, 0.9517189050078657, 0.9486765256146883, 0.9457208157871942, 0.9427227872812818, 0.9399386291466334, 0.9349932513640985, 0.9288261894143705, 0.9254616695294128, 0.9221886563805027, 0.9188509699068458, 0.915816124993008, 0.9126536853065345, 0.9084989643628255, 0.9045647794981047, 0.9001612571956726, 0.8968866389327226, 0.8929720540671963, 0.8882457041155193, 0.8853800684167759, 0.8817096842753251, 0.8775402352158715, 0.8748208528209546, 0.8690810995476573, 0.8664810011514761, 0.8584888288239728, 0.858485841898706, 0.8559350369552029, 0.8523736538708621, 0.8479998113360429, 0.8457039847828337, 0.8419061496798198, 0.8385197021325397, 0.8343807998896714, 0.8321302164642305, 0.8257754683189632, 0.8190368263008624, 0.8156278584531853, 0.8108817253184123, 0.8097847912294613, 0.8066945905966949, 0.8016366439768062, 0.8009507504538506, 0.7978916242141426, 0.7951029470395748, 0.7918041093370152, 0.7888178498047248, 0.7839453521484476, 0.7835187764569512, 0.7806061992059281, 0.7751915070668952, 0.776400843070294, 0.7736816546951972, 0.7739719787425552, 0.981547760081002, 0.9783191107815529, 0.9720577829193665, 0.9677396187742875, 0.9637116538750307, 0.9613671533599215, 0.9566656962781115, 0.953212542304319, 0.9498307232149187, 0.9465717478639696, 0.9431893727029631, 0.9396172370027812, 0.9360453538976621, 0.9291805798075792, 0.9209527681953381, 0.9169270262172543, 0.9128542038766607, 0.9088717651351773, 0.9047587318552943, 0.9009867628597049, 0.8975242670665129, 0.89356647886204, 0.889644455237089, 0.886559405548693, 0.882733673476862, 0.8783059377512253, 0.8755645180191589, 0.8720300673473934, 0.8677529298076447, 0.859049156094731, 0.8569053494588545, 0.8518659950843436, 0.8502900122036473, 0.8480130356323287, 0.8446500805166606, 0.841138508684198, 0.8389571854909209, 0.8353695575997965, 0.8323632134517919, 0.828285810677856, 0.8255674607740809, 0.8199044530181538, 0.8132637498839883, 0.8102378979509867, 0.8072248070938493, 0.8059270278970738, 0.8029878307438708, 0.7989619033515942, 0.7983664753623245, 0.795802133196813, 0.7929682964599739, 0.7898693760651792, 0.787094046764988, 0.7830793400015471, 0.7820526502569298, 0.7795097506490353, 0.7759194636010017, 0.7754683610116903, 0.7730019872724594, 0.7737297038317591, 0.9789170845010232, 0.9723672398307521, 0.9678773262663203, 0.9636427140275626, 0.9632185045488699, 0.9580565260869475, 0.9547662648076788, 0.9517189050078657, 0.9486765256146883, 0.9457208157871942, 0.9427227872812818, 0.9399386291466334, 0.9349932513640985, 0.9288261894143705, 0.9254616695294128, 0.9221886563805027, 0.9188509699068458, 0.915816124993008, 0.9126536853065345, 0.9084989643628255, 0.9045647794981047, 0.9001612571956726, 0.8968866389327226, 0.8929720540671963, 0.8882457041155193, 0.8853800684167759, 0.8817096842753251, 0.8775402352158715, 0.8748208528209546, 0.8690810995476573, 0.8664810011514761, 0.8584888288239728, 0.858485841898706, 0.8559350369552029, 0.8523736538708621, 0.8479998113360429, 0.8457039847828337, 0.8419061496798198, 0.8385197021325397, 0.8343807998896714, 0.8321302164642305, 0.8257754683189632, 0.8190368263008624, 0.8156278584531853, 0.8108817253184123, 0.8097847912294613, 0.8066945905966949, 0.8016366439768062, 0.8009507504538506, 0.7978916242141426, 0.7951029470395748, 0.7918041093370152, 0.7888178498047248, 0.7839453521484476, 0.7835187764569512, 0.7806061992059281, 0.7751915070668952, 0.776400843070294, 0.7736816546951972, 0.7739719787425552]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_all=[]\n",
    "mae_all=[]\n",
    "mape_all=[]\n",
    "r2=[]\n",
    "num=0\n",
    "test_csv_l=[]\n",
    "real_csv_l=[]\n",
    "for i in range(4):\n",
    "    for j in range(len(tests_lstm[0])):\n",
    "        real,pred=tests_lstm[i][j][0],tests_lstm[i][j][1].reshape(-1)\n",
    "        rmse=evaluation(real,pred)\n",
    "        if rmse>=0.0:\n",
    "            rmse_all.append(rmse)\n",
    "            for pre,rea in zip(pred,real):\n",
    "                test_csv_l.append(pre)\n",
    "                real_csv_l.append(rea)\n",
    "        mae_all.append(calculate_mae(real,pred))\n",
    "        mape_all.append(mape(real,pred))\n",
    "        r2.append(r_squared(real,pred))\n",
    "        num+=1\n",
    "print(\"RMSE:\",rmse_all)\n",
    "print(\"test:\",test_csv_l)\n",
    "print('real:',real_csv_l)\n",
    "len(test_csv_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "707b4420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prop pred  prop real  mlp pred  mlp real  cnn pred  cnn real  lstm pred  \\\n",
      "0     0.962078   0.981548  0.929183  0.981548  0.950951  0.981548   0.962854   \n",
      "1     0.962089   0.978319  0.951857  0.978319  0.953414  0.978319   0.965071   \n",
      "2     0.962256   0.972058  0.972051  0.972058  0.966692  0.972058   0.979949   \n",
      "3     0.962412   0.967740  0.972543  0.967740  0.963554  0.967740   0.975580   \n",
      "4     0.961886   0.963712  0.967451  0.963712  0.960038  0.963712   0.973250   \n",
      "..         ...        ...       ...       ...       ...       ...        ...   \n",
      "475   0.815731   0.780606  0.796938  0.780606  0.815650  0.780606   0.801483   \n",
      "476   0.814962   0.775192  0.790979  0.775192  0.807724  0.775192   0.793913   \n",
      "477   0.814319   0.776401  0.797688  0.776401  0.813687  0.776401   0.800388   \n",
      "478   0.813737   0.773682  0.802601  0.773682  0.819984  0.773682   0.807259   \n",
      "479   0.813217   0.773972  0.795328  0.773972  0.811265  0.773972   0.799484   \n",
      "\n",
      "     lstm real  \n",
      "0     0.981548  \n",
      "1     0.978319  \n",
      "2     0.972058  \n",
      "3     0.967740  \n",
      "4     0.963712  \n",
      "..         ...  \n",
      "475   0.780606  \n",
      "476   0.775192  \n",
      "477   0.776401  \n",
      "478   0.773682  \n",
      "479   0.773972  \n",
      "\n",
      "[480 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data={\n",
    "    'prop pred':test_csv_p,\n",
    "    'prop real':real_csv_p,\n",
    "    'mlp pred': test_csv_m,\n",
    "    'mlp real':real_csv_m,\n",
    "    'cnn pred': test_csv_c,\n",
    "    'cnn real':real_csv_c,\n",
    "    'lstm pred':test_csv_l,\n",
    "    'lstm real':real_csv_l,\n",
    "}\n",
    "df=pd.DataFrame(data)\n",
    "print(df)\n",
    "df.to_csv('../csv_results/oxford.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15e8c80e7b64fde0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T11:08:23.299084Z",
     "start_time": "2025-03-20T11:08:23.275339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: [0.014090784054268298]\n",
      "MAE: [0.01106635]\n"
     ]
    }
   ],
   "source": [
    "rmse_all=0\n",
    "mae_all=0\n",
    "num=0\n",
    "for i in range(len(tests_cnn)):\n",
    "    for j in range(len(tests_cnn[0])):\n",
    "        real,pred=tests_cnn[i][j][0],tests_cnn[i][j][1]\n",
    "        rmse=evaluation(real,pred)\n",
    "        rmse_all+=(rmse)\n",
    "        mae_all+=calculate_mae(real,pred)\n",
    "        num+=1\n",
    "print('RMSE:',[rmse_all/num])\n",
    "print('MAE:',mae_all/num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f16b89cc65ff1a",
   "metadata": {},
   "source": [
    "## 取出一组画图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "161d5e5cb7fe7a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T02:44:58.338147Z",
     "start_time": "2025-03-05T02:44:56.418240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training seed 0:\n",
      "\n",
      "Epoch: 5 Train_RMSELoss: tensor(0.0477, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 5 valid_RMSELoss: tensor(0.0166, device='cuda:0') \n",
      "\n",
      "Epoch: 10 Train_RMSELoss: tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 10 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 15 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 15 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 20 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 20 valid_RMSELoss: tensor(0.0005, device='cuda:0') \n",
      "\n",
      "Epoch: 25 Train_RMSELoss: tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 25 valid_RMSELoss: tensor(0.0015, device='cuda:0') \n",
      "\n",
      "Epoch: 30 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 30 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 35 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 35 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 40 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 40 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 45 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 45 valid_RMSELoss: tensor(0.0009, device='cuda:0') \n",
      "\n",
      "Epoch: 50 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 50 valid_RMSELoss: tensor(0.0006, device='cuda:0') \n",
      "\n",
      "Epoch: 55 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 55 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 60 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 60 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 65 Train_RMSELoss: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 65 valid_RMSELoss: tensor(0.0011, device='cuda:0') \n",
      "\n",
      "Epoch: 70 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 70 valid_RMSELoss: tensor(0.0006, device='cuda:0') \n",
      "\n",
      "Epoch: 75 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 75 valid_RMSELoss: tensor(0.0008, device='cuda:0') \n",
      "\n",
      "Epoch: 80 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 80 valid_RMSELoss: tensor(8.8969e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 85 Train_RMSELoss: tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 85 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 90 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 90 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 95 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 95 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 100 Train_RMSELoss: tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 100 valid_RMSELoss: tensor(0.0008, device='cuda:0') \n",
      "\n",
      "Epoch: 105 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 105 valid_RMSELoss: tensor(9.3598e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 110 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 110 valid_RMSELoss: tensor(0.0011, device='cuda:0') \n",
      "\n",
      "Epoch: 115 Train_RMSELoss: tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 115 valid_RMSELoss: tensor(0.0003, device='cuda:0') \n",
      "\n",
      "Epoch: 120 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 120 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 125 Train_RMSELoss: tensor(7.9020e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 125 valid_RMSELoss: tensor(8.8479e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 130 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 130 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 135 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 135 valid_RMSELoss: tensor(7.9560e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 140 Train_RMSELoss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 140 valid_RMSELoss: tensor(7.9233e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 145 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 145 valid_RMSELoss: tensor(9.6964e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 150 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 150 valid_RMSELoss: tensor(0.0004, device='cuda:0') \n",
      "\n",
      "Epoch: 155 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 155 valid_RMSELoss: tensor(8.2168e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 160 Train_RMSELoss: tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 160 valid_RMSELoss: tensor(0.0009, device='cuda:0') \n",
      "\n",
      "Epoch: 165 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 165 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 170 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 170 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 175 Train_RMSELoss: tensor(9.2529e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 175 valid_RMSELoss: tensor(9.5604e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 180 Train_RMSELoss: tensor(9.9456e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 180 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 185 Train_RMSELoss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 185 valid_RMSELoss: tensor(7.9715e-05, device='cuda:0') \n",
      "\n",
      "Epoch: 190 Train_RMSELoss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 190 valid_RMSELoss: tensor(0.0001, device='cuda:0') \n",
      "\n",
      "Epoch: 195 Train_RMSELoss: tensor(9.7217e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 195 valid_RMSELoss: tensor(0.0002, device='cuda:0') \n",
      "\n",
      "Epoch: 200 Train_RMSELoss: tensor(9.0669e-05, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 200 valid_RMSELoss: tensor(7.5770e-05, device='cuda:0') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_results_conv=train_conv(seed=0,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d83a56eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T02:58:23.687766Z",
     "start_time": "2025-03-05T02:58:23.526862Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"621.150625pt\" height=\"404.4pt\" viewBox=\"0 0 621.150625 404.4\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2025-03-05T10:58:23.635052</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 404.4 \n",
       "L 621.150625 404.4 \n",
       "L 621.150625 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 55.950625 361.036875 \n",
       "L 613.950625 361.036875 \n",
       "L 613.950625 28.396875 \n",
       "L 55.950625 28.396875 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"mf4c6b4999d\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#mf4c6b4999d\" x=\"72.716419\" y=\"361.036875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(69.535169 375.635312) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mf4c6b4999d\" x=\"158.694847\" y=\"361.036875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(152.332347 375.635312) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mf4c6b4999d\" x=\"244.673275\" y=\"361.036875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(238.310775 375.635312) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mf4c6b4999d\" x=\"330.651704\" y=\"361.036875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 30 -->\n",
       "      <g transform=\"translate(324.289204 375.635312) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \n",
       "Q 3050 2419 3304 2112 \n",
       "Q 3559 1806 3559 1356 \n",
       "Q 3559 666 3084 287 \n",
       "Q 2609 -91 1734 -91 \n",
       "Q 1441 -91 1130 -33 \n",
       "Q 819 25 488 141 \n",
       "L 488 750 \n",
       "Q 750 597 1062 519 \n",
       "Q 1375 441 1716 441 \n",
       "Q 2309 441 2620 675 \n",
       "Q 2931 909 2931 1356 \n",
       "Q 2931 1769 2642 2001 \n",
       "Q 2353 2234 1838 2234 \n",
       "L 1294 2234 \n",
       "L 1294 2753 \n",
       "L 1863 2753 \n",
       "Q 2328 2753 2575 2939 \n",
       "Q 2822 3125 2822 3475 \n",
       "Q 2822 3834 2567 4026 \n",
       "Q 2313 4219 1838 4219 \n",
       "Q 1578 4219 1281 4162 \n",
       "Q 984 4106 628 3988 \n",
       "L 628 4550 \n",
       "Q 988 4650 1302 4700 \n",
       "Q 1616 4750 1894 4750 \n",
       "Q 2613 4750 3031 4423 \n",
       "Q 3450 4097 3450 3541 \n",
       "Q 3450 3153 3228 2886 \n",
       "Q 3006 2619 2597 2516 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mf4c6b4999d\" x=\"416.630132\" y=\"361.036875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 40 -->\n",
       "      <g transform=\"translate(410.267632 375.635312) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mf4c6b4999d\" x=\"502.60856\" y=\"361.036875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 50 -->\n",
       "      <g transform=\"translate(496.24606 375.635312) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_7\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mf4c6b4999d\" x=\"588.586989\" y=\"361.036875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 60 -->\n",
       "      <g transform=\"translate(582.224489 375.635312) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
       "Q 1688 2584 1439 2293 \n",
       "Q 1191 2003 1191 1497 \n",
       "Q 1191 994 1439 701 \n",
       "Q 1688 409 2113 409 \n",
       "Q 2538 409 2786 701 \n",
       "Q 3034 994 3034 1497 \n",
       "Q 3034 2003 2786 2293 \n",
       "Q 2538 2584 2113 2584 \n",
       "z\n",
       "M 3366 4563 \n",
       "L 3366 3988 \n",
       "Q 3128 4100 2886 4159 \n",
       "Q 2644 4219 2406 4219 \n",
       "Q 1781 4219 1451 3797 \n",
       "Q 1122 3375 1075 2522 \n",
       "Q 1259 2794 1537 2939 \n",
       "Q 1816 3084 2150 3084 \n",
       "Q 2853 3084 3261 2657 \n",
       "Q 3669 2231 3669 1497 \n",
       "Q 3669 778 3244 343 \n",
       "Q 2819 -91 2113 -91 \n",
       "Q 1303 -91 875 529 \n",
       "Q 447 1150 447 2328 \n",
       "Q 447 3434 972 4092 \n",
       "Q 1497 4750 2381 4750 \n",
       "Q 2619 4750 2861 4703 \n",
       "Q 3103 4656 3366 4563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-36\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_8\">\n",
       "     <!-- cycle -->\n",
       "     <g transform=\"translate(314.273125 393.8725) scale(0.16 -0.16)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
       "L 3122 2828 \n",
       "Q 2878 2963 2633 3030 \n",
       "Q 2388 3097 2138 3097 \n",
       "Q 1578 3097 1268 2742 \n",
       "Q 959 2388 959 1747 \n",
       "Q 959 1106 1268 751 \n",
       "Q 1578 397 2138 397 \n",
       "Q 2388 397 2633 464 \n",
       "Q 2878 531 3122 666 \n",
       "L 3122 134 \n",
       "Q 2881 22 2623 -34 \n",
       "Q 2366 -91 2075 -91 \n",
       "Q 1284 -91 818 406 \n",
       "Q 353 903 353 1747 \n",
       "Q 353 2603 823 3093 \n",
       "Q 1294 3584 2113 3584 \n",
       "Q 2378 3584 2631 3529 \n",
       "Q 2884 3475 3122 3366 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-79\" d=\"M 2059 -325 \n",
       "Q 1816 -950 1584 -1140 \n",
       "Q 1353 -1331 966 -1331 \n",
       "L 506 -1331 \n",
       "L 506 -850 \n",
       "L 844 -850 \n",
       "Q 1081 -850 1212 -737 \n",
       "Q 1344 -625 1503 -206 \n",
       "L 1606 56 \n",
       "L 191 3500 \n",
       "L 800 3500 \n",
       "L 1894 763 \n",
       "L 2988 3500 \n",
       "L 3597 3500 \n",
       "L 2059 -325 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-63\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-79\" x=\"54.980469\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"114.160156\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" x=\"169.140625\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"196.923828\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <defs>\n",
       "       <path id=\"m35d169254c\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m35d169254c\" x=\"55.950625\" y=\"304.696709\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.80 -->\n",
       "      <g transform=\"translate(26.685 308.495927) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
       "L 1344 794 \n",
       "L 1344 0 \n",
       "L 684 0 \n",
       "L 684 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \n",
       "Q 1584 2216 1326 1975 \n",
       "Q 1069 1734 1069 1313 \n",
       "Q 1069 891 1326 650 \n",
       "Q 1584 409 2034 409 \n",
       "Q 2484 409 2743 651 \n",
       "Q 3003 894 3003 1313 \n",
       "Q 3003 1734 2745 1975 \n",
       "Q 2488 2216 2034 2216 \n",
       "z\n",
       "M 1403 2484 \n",
       "Q 997 2584 770 2862 \n",
       "Q 544 3141 544 3541 \n",
       "Q 544 4100 942 4425 \n",
       "Q 1341 4750 2034 4750 \n",
       "Q 2731 4750 3128 4425 \n",
       "Q 3525 4100 3525 3541 \n",
       "Q 3525 3141 3298 2862 \n",
       "Q 3072 2584 2669 2484 \n",
       "Q 3125 2378 3379 2068 \n",
       "Q 3634 1759 3634 1313 \n",
       "Q 3634 634 3220 271 \n",
       "Q 2806 -91 2034 -91 \n",
       "Q 1263 -91 848 271 \n",
       "Q 434 634 434 1313 \n",
       "Q 434 1759 690 2068 \n",
       "Q 947 2378 1403 2484 \n",
       "z\n",
       "M 1172 3481 \n",
       "Q 1172 3119 1398 2916 \n",
       "Q 1625 2713 2034 2713 \n",
       "Q 2441 2713 2670 2916 \n",
       "Q 2900 3119 2900 3481 \n",
       "Q 2900 3844 2670 4047 \n",
       "Q 2441 4250 2034 4250 \n",
       "Q 1625 4250 1398 4047 \n",
       "Q 1172 3844 1172 3481 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m35d169254c\" x=\"55.950625\" y=\"232.343727\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.85 -->\n",
       "      <g transform=\"translate(26.685 236.142946) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m35d169254c\" x=\"55.950625\" y=\"159.990746\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0.90 -->\n",
       "      <g transform=\"translate(26.685 163.789965) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-39\" d=\"M 703 97 \n",
       "L 703 672 \n",
       "Q 941 559 1184 500 \n",
       "Q 1428 441 1663 441 \n",
       "Q 2288 441 2617 861 \n",
       "Q 2947 1281 2994 2138 \n",
       "Q 2813 1869 2534 1725 \n",
       "Q 2256 1581 1919 1581 \n",
       "Q 1219 1581 811 2004 \n",
       "Q 403 2428 403 3163 \n",
       "Q 403 3881 828 4315 \n",
       "Q 1253 4750 1959 4750 \n",
       "Q 2769 4750 3195 4129 \n",
       "Q 3622 3509 3622 2328 \n",
       "Q 3622 1225 3098 567 \n",
       "Q 2575 -91 1691 -91 \n",
       "Q 1453 -91 1209 -44 \n",
       "Q 966 3 703 97 \n",
       "z\n",
       "M 1959 2075 \n",
       "Q 2384 2075 2632 2365 \n",
       "Q 2881 2656 2881 3163 \n",
       "Q 2881 3666 2632 3958 \n",
       "Q 2384 4250 1959 4250 \n",
       "Q 1534 4250 1286 3958 \n",
       "Q 1038 3666 1038 3163 \n",
       "Q 1038 2656 1286 2365 \n",
       "Q 1534 2075 1959 2075 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-39\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m35d169254c\" x=\"55.950625\" y=\"87.637765\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 0.95 -->\n",
       "      <g transform=\"translate(26.685 91.436983) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-39\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_13\">\n",
       "     <!-- SOH -->\n",
       "     <g transform=\"translate(19.3575 212.109375) rotate(-90) scale(0.16 -0.16)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-53\" d=\"M 3425 4513 \n",
       "L 3425 3897 \n",
       "Q 3066 4069 2747 4153 \n",
       "Q 2428 4238 2131 4238 \n",
       "Q 1616 4238 1336 4038 \n",
       "Q 1056 3838 1056 3469 \n",
       "Q 1056 3159 1242 3001 \n",
       "Q 1428 2844 1947 2747 \n",
       "L 2328 2669 \n",
       "Q 3034 2534 3370 2195 \n",
       "Q 3706 1856 3706 1288 \n",
       "Q 3706 609 3251 259 \n",
       "Q 2797 -91 1919 -91 \n",
       "Q 1588 -91 1214 -16 \n",
       "Q 841 59 441 206 \n",
       "L 441 856 \n",
       "Q 825 641 1194 531 \n",
       "Q 1563 422 1919 422 \n",
       "Q 2459 422 2753 634 \n",
       "Q 3047 847 3047 1241 \n",
       "Q 3047 1584 2836 1778 \n",
       "Q 2625 1972 2144 2069 \n",
       "L 1759 2144 \n",
       "Q 1053 2284 737 2584 \n",
       "Q 422 2884 422 3419 \n",
       "Q 422 4038 858 4394 \n",
       "Q 1294 4750 2059 4750 \n",
       "Q 2388 4750 2728 4690 \n",
       "Q 3069 4631 3425 4513 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-4f\" d=\"M 2522 4238 \n",
       "Q 1834 4238 1429 3725 \n",
       "Q 1025 3213 1025 2328 \n",
       "Q 1025 1447 1429 934 \n",
       "Q 1834 422 2522 422 \n",
       "Q 3209 422 3611 934 \n",
       "Q 4013 1447 4013 2328 \n",
       "Q 4013 3213 3611 3725 \n",
       "Q 3209 4238 2522 4238 \n",
       "z\n",
       "M 2522 4750 \n",
       "Q 3503 4750 4090 4092 \n",
       "Q 4678 3434 4678 2328 \n",
       "Q 4678 1225 4090 567 \n",
       "Q 3503 -91 2522 -91 \n",
       "Q 1538 -91 948 565 \n",
       "Q 359 1222 359 2328 \n",
       "Q 359 3434 948 4092 \n",
       "Q 1538 4750 2522 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-48\" d=\"M 628 4666 \n",
       "L 1259 4666 \n",
       "L 1259 2753 \n",
       "L 3553 2753 \n",
       "L 3553 4666 \n",
       "L 4184 4666 \n",
       "L 4184 0 \n",
       "L 3553 0 \n",
       "L 3553 2222 \n",
       "L 1259 2222 \n",
       "L 1259 0 \n",
       "L 628 0 \n",
       "L 628 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-53\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-4f\" x=\"63.476562\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-48\" x=\"142.1875\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_12\">\n",
       "    <path d=\"M 81.314261 45.793019 \n",
       "L 89.912104 55.271035 \n",
       "L 98.509947 61.768208 \n",
       "L 107.10779 67.895944 \n",
       "L 115.705633 68.509801 \n",
       "L 124.303476 75.979491 \n",
       "L 132.901318 80.740695 \n",
       "L 141.499161 85.150407 \n",
       "L 150.097004 89.552911 \n",
       "L 158.694847 93.829999 \n",
       "L 167.29269 98.168325 \n",
       "L 175.890533 102.197168 \n",
       "L 184.488375 109.353425 \n",
       "L 193.086218 118.277531 \n",
       "L 201.684061 123.146192 \n",
       "L 210.281904 127.882437 \n",
       "L 218.879747 132.712269 \n",
       "L 227.47759 137.10387 \n",
       "L 236.075432 141.680109 \n",
       "L 244.673275 147.692238 \n",
       "L 253.271118 153.385238 \n",
       "L 261.868961 159.757397 \n",
       "L 270.466804 164.495965 \n",
       "L 279.064647 170.160603 \n",
       "L 287.662489 176.999913 \n",
       "L 296.260332 181.146659 \n",
       "L 304.858175 186.457923 \n",
       "L 313.456018 192.491365 \n",
       "L 322.053861 196.426473 \n",
       "L 330.651704 204.732239 \n",
       "L 339.249546 208.494736 \n",
       "L 347.847389 220.059886 \n",
       "L 356.445232 220.064208 \n",
       "L 365.043075 223.755375 \n",
       "L 373.640918 228.908909 \n",
       "L 382.238761 235.23812 \n",
       "L 390.836603 238.560317 \n",
       "L 399.434446 244.056011 \n",
       "L 408.032289 248.956403 \n",
       "L 416.630132 254.945641 \n",
       "L 425.227975 258.20237 \n",
       "L 433.825818 267.398069 \n",
       "L 442.42366 277.149286 \n",
       "L 451.021503 282.082266 \n",
       "L 459.619346 288.950203 \n",
       "L 468.217189 290.537532 \n",
       "L 476.815032 295.009237 \n",
       "L 485.412875 302.328387 \n",
       "L 494.010717 303.320916 \n",
       "L 502.60856 307.747654 \n",
       "L 511.206403 311.783036 \n",
       "L 519.804246 316.556651 \n",
       "L 528.402089 320.877947 \n",
       "L 536.999932 327.928741 \n",
       "L 545.597774 328.546022 \n",
       "L 554.195617 332.760695 \n",
       "L 562.79346 340.596077 \n",
       "L 571.391303 338.846096 \n",
       "L 579.989146 342.780924 \n",
       "L 588.586989 342.360807 \n",
       "\" clip-path=\"url(#pc25178599c)\" style=\"fill: none; stroke: #0000ff; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_13\">\n",
       "    <path d=\"M 81.314261 66.457611 \n",
       "L 89.912104 60.615799 \n",
       "L 98.509947 77.815119 \n",
       "L 107.10779 96.381439 \n",
       "L 115.705633 103.613711 \n",
       "L 124.303476 111.154419 \n",
       "L 132.901318 116.114741 \n",
       "L 141.499161 123.924036 \n",
       "L 150.097004 123.941977 \n",
       "L 158.694847 125.847444 \n",
       "L 167.29269 124.541252 \n",
       "L 175.890533 125.381341 \n",
       "L 184.488375 131.46828 \n",
       "L 193.086218 135.653719 \n",
       "L 201.684061 145.308278 \n",
       "L 210.281904 152.934892 \n",
       "L 218.879747 157.274722 \n",
       "L 227.47759 165.206235 \n",
       "L 236.075432 166.077892 \n",
       "L 244.673275 173.604023 \n",
       "L 253.271118 177.210543 \n",
       "L 261.868961 186.62101 \n",
       "L 270.466804 188.30921 \n",
       "L 279.064647 191.69389 \n",
       "L 287.662489 202.424954 \n",
       "L 296.260332 203.767889 \n",
       "L 304.858175 208.487915 \n",
       "L 313.456018 221.192412 \n",
       "L 322.053861 220.265726 \n",
       "L 330.651704 227.070278 \n",
       "L 339.249546 230.526892 \n",
       "L 347.847389 240.105118 \n",
       "L 356.445232 246.266492 \n",
       "L 365.043075 246.639702 \n",
       "L 373.640918 251.468577 \n",
       "L 382.238761 258.962968 \n",
       "L 390.836603 259.526621 \n",
       "L 399.434446 264.635383 \n",
       "L 408.032289 266.324876 \n",
       "L 416.630132 274.932256 \n",
       "L 425.227975 276.703171 \n",
       "L 433.825818 279.27312 \n",
       "L 442.42366 287.664958 \n",
       "L 451.021503 290.35816 \n",
       "L 459.619346 305.269056 \n",
       "L 468.217189 302.953722 \n",
       "L 476.815032 304.918789 \n",
       "L 485.412875 316.983128 \n",
       "L 494.010717 314.109056 \n",
       "L 502.60856 318.136741 \n",
       "L 511.206403 323.256715 \n",
       "L 519.804246 321.288974 \n",
       "L 528.402089 329.150623 \n",
       "L 536.999932 339.050568 \n",
       "L 545.597774 335.40558 \n",
       "L 554.195617 337.434215 \n",
       "L 562.79346 345.916875 \n",
       "L 571.391303 337.795177 \n",
       "L 579.989146 333.33934 \n",
       "L 588.586989 340.798281 \n",
       "\" clip-path=\"url(#pc25178599c)\" style=\"fill: none; stroke: #008000; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_14\">\n",
       "    <path d=\"M 81.314261 43.516875 \n",
       "L 89.912104 47.997898 \n",
       "L 98.509947 53.962187 \n",
       "L 107.10779 60.966411 \n",
       "L 115.705633 65.069911 \n",
       "L 124.303476 78.891537 \n",
       "L 132.901318 92.280958 \n",
       "L 141.499161 81.866265 \n",
       "L 150.097004 91.125533 \n",
       "L 158.694847 90.867382 \n",
       "L 167.29269 90.404126 \n",
       "L 175.890533 95.631655 \n",
       "L 184.488375 113.277327 \n",
       "L 193.086218 109.319592 \n",
       "L 201.684061 126.225139 \n",
       "L 210.281904 125.399972 \n",
       "L 218.879747 131.132935 \n",
       "L 227.47759 138.071521 \n",
       "L 236.075432 135.91532 \n",
       "L 244.673275 147.670102 \n",
       "L 253.271118 138.369002 \n",
       "L 261.868961 162.490003 \n",
       "L 270.466804 155.080743 \n",
       "L 279.064647 160.606616 \n",
       "L 287.662489 173.567366 \n",
       "L 296.260332 172.425742 \n",
       "L 304.858175 176.45291 \n",
       "L 313.456018 191.165341 \n",
       "L 322.053861 186.712005 \n",
       "L 330.651704 196.561492 \n",
       "L 339.249546 195.713381 \n",
       "L 347.847389 209.999903 \n",
       "L 356.445232 212.945564 \n",
       "L 365.043075 210.558813 \n",
       "L 373.640918 216.433746 \n",
       "L 382.238761 228.406485 \n",
       "L 390.836603 224.890875 \n",
       "L 399.434446 229.656269 \n",
       "L 408.032289 230.162048 \n",
       "L 416.630132 242.065097 \n",
       "L 425.227975 244.055091 \n",
       "L 433.825818 243.856281 \n",
       "L 442.42366 254.769594 \n",
       "L 451.021503 257.66497 \n",
       "L 459.619346 280.320213 \n",
       "L 468.217189 271.522563 \n",
       "L 476.815032 271.744229 \n",
       "L 485.412875 288.765354 \n",
       "L 494.010717 282.094061 \n",
       "L 502.60856 284.732407 \n",
       "L 511.206403 292.223176 \n",
       "L 519.804246 291.884811 \n",
       "L 528.402089 301.001937 \n",
       "L 536.999932 312.769053 \n",
       "L 545.597774 306.697294 \n",
       "L 554.195617 310.504262 \n",
       "L 562.79346 325.268099 \n",
       "L 571.391303 319.19151 \n",
       "L 579.989146 313.998654 \n",
       "L 588.586989 335.37315 \n",
       "\" clip-path=\"url(#pc25178599c)\" style=\"fill: none; stroke: #ff0000; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_15\">\n",
       "    <path d=\"M 81.314261 56.687561 \n",
       "L 89.912104 59.28399 \n",
       "L 98.509947 64.145123 \n",
       "L 107.10779 69.152711 \n",
       "L 115.705633 73.429663 \n",
       "L 124.303476 80.403353 \n",
       "L 132.901318 85.275182 \n",
       "L 141.499161 89.956998 \n",
       "L 150.097004 94.760256 \n",
       "L 158.694847 101.192978 \n",
       "L 167.29269 105.380832 \n",
       "L 175.890533 110.600857 \n",
       "L 184.488375 118.42999 \n",
       "L 193.086218 122.135698 \n",
       "L 201.684061 129.332608 \n",
       "L 210.281904 134.654151 \n",
       "L 218.879747 139.207194 \n",
       "L 227.47759 145.964824 \n",
       "L 236.075432 149.110329 \n",
       "L 244.673275 155.92687 \n",
       "L 253.271118 159.852519 \n",
       "L 261.868961 168.097643 \n",
       "L 270.466804 171.121016 \n",
       "L 279.064647 175.386065 \n",
       "L 287.662489 183.117044 \n",
       "L 296.260332 186.253061 \n",
       "L 304.858175 190.997927 \n",
       "L 313.456018 199.51043 \n",
       "L 322.053861 201.751416 \n",
       "L 330.651704 207.790399 \n",
       "L 339.249546 211.905285 \n",
       "L 347.847389 219.285478 \n",
       "L 356.445232 224.742092 \n",
       "L 365.043075 227.648249 \n",
       "L 373.640918 232.813332 \n",
       "L 382.238761 239.946674 \n",
       "L 390.836603 243.215432 \n",
       "L 399.434446 249.07622 \n",
       "L 408.032289 253.121501 \n",
       "L 416.630132 261.125034 \n",
       "L 425.227975 265.508161 \n",
       "L 433.825818 270.141763 \n",
       "L 442.42366 277.70895 \n",
       "L 451.021503 280.314089 \n",
       "L 459.619346 286.715156 \n",
       "L 468.217189 287.676947 \n",
       "L 476.815032 290.07215 \n",
       "L 485.412875 295.617171 \n",
       "L 494.010717 296.547997 \n",
       "L 502.60856 299.617256 \n",
       "L 511.206403 303.13761 \n",
       "L 519.804246 304.573783 \n",
       "L 528.402089 308.850562 \n",
       "L 536.999932 313.790788 \n",
       "L 545.597774 314.673486 \n",
       "L 554.195617 317.706519 \n",
       "L 562.79346 323.63717 \n",
       "L 571.391303 324.03755 \n",
       "L 579.989146 325.631391 \n",
       "L 588.586989 330.290695 \n",
       "\" clip-path=\"url(#pc25178599c)\" style=\"fill: none; stroke: #800080; stroke-width: 2; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 55.950625 361.036875 \n",
       "L 55.950625 28.396875 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 613.950625 361.036875 \n",
       "L 613.950625 28.396875 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 55.950625 361.036875 \n",
       "L 613.950625 361.036875 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 55.950625 28.396875 \n",
       "L 613.950625 28.396875 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_14\">\n",
       "    <!-- Cell8 -->\n",
       "    <g transform=\"translate(309.895938 22.396875) scale(0.2 -0.2)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-43\" d=\"M 4122 4306 \n",
       "L 4122 3641 \n",
       "Q 3803 3938 3442 4084 \n",
       "Q 3081 4231 2675 4231 \n",
       "Q 1875 4231 1450 3742 \n",
       "Q 1025 3253 1025 2328 \n",
       "Q 1025 1406 1450 917 \n",
       "Q 1875 428 2675 428 \n",
       "Q 3081 428 3442 575 \n",
       "Q 3803 722 4122 1019 \n",
       "L 4122 359 \n",
       "Q 3791 134 3420 21 \n",
       "Q 3050 -91 2638 -91 \n",
       "Q 1578 -91 968 557 \n",
       "Q 359 1206 359 2328 \n",
       "Q 359 3453 968 4101 \n",
       "Q 1578 4750 2638 4750 \n",
       "Q 3056 4750 3426 4639 \n",
       "Q 3797 4528 4122 4306 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-43\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"69.824219\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"131.347656\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"159.130859\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-38\" x=\"186.914062\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 528.913125 95.109375 \n",
       "L 606.950625 95.109375 \n",
       "Q 608.950625 95.109375 608.950625 93.109375 \n",
       "L 608.950625 35.396875 \n",
       "Q 608.950625 33.396875 606.950625 33.396875 \n",
       "L 528.913125 33.396875 \n",
       "Q 526.913125 33.396875 526.913125 35.396875 \n",
       "L 526.913125 93.109375 \n",
       "Q 526.913125 95.109375 528.913125 95.109375 \n",
       "z\n",
       "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_16\">\n",
       "     <path d=\"M 530.913125 41.495312 \n",
       "L 540.913125 41.495312 \n",
       "L 550.913125 41.495312 \n",
       "\" style=\"fill: none; stroke: #0000ff; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_15\">\n",
       "     <!-- Real -->\n",
       "     <g transform=\"translate(558.913125 44.995312) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-52\" d=\"M 2841 2188 \n",
       "Q 3044 2119 3236 1894 \n",
       "Q 3428 1669 3622 1275 \n",
       "L 4263 0 \n",
       "L 3584 0 \n",
       "L 2988 1197 \n",
       "Q 2756 1666 2539 1819 \n",
       "Q 2322 1972 1947 1972 \n",
       "L 1259 1972 \n",
       "L 1259 0 \n",
       "L 628 0 \n",
       "L 628 4666 \n",
       "L 2053 4666 \n",
       "Q 2853 4666 3247 4331 \n",
       "Q 3641 3997 3641 3322 \n",
       "Q 3641 2881 3436 2590 \n",
       "Q 3231 2300 2841 2188 \n",
       "z\n",
       "M 1259 4147 \n",
       "L 1259 2491 \n",
       "L 2053 2491 \n",
       "Q 2509 2491 2742 2702 \n",
       "Q 2975 2913 2975 3322 \n",
       "Q 2975 3731 2742 3939 \n",
       "Q 2509 4147 2053 4147 \n",
       "L 1259 4147 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-52\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"64.982422\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"126.505859\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" x=\"187.785156\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_17\">\n",
       "     <path d=\"M 530.913125 56.173437 \n",
       "L 540.913125 56.173437 \n",
       "L 550.913125 56.173437 \n",
       "\" style=\"fill: none; stroke: #008000; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_16\">\n",
       "     <!-- MLP -->\n",
       "     <g transform=\"translate(558.913125 59.673437) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-4d\" d=\"M 628 4666 \n",
       "L 1569 4666 \n",
       "L 2759 1491 \n",
       "L 3956 4666 \n",
       "L 4897 4666 \n",
       "L 4897 0 \n",
       "L 4281 0 \n",
       "L 4281 4097 \n",
       "L 3078 897 \n",
       "L 2444 897 \n",
       "L 1241 4097 \n",
       "L 1241 0 \n",
       "L 628 0 \n",
       "L 628 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-4c\" d=\"M 628 4666 \n",
       "L 1259 4666 \n",
       "L 1259 531 \n",
       "L 3531 531 \n",
       "L 3531 0 \n",
       "L 628 0 \n",
       "L 628 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-50\" d=\"M 1259 4147 \n",
       "L 1259 2394 \n",
       "L 2053 2394 \n",
       "Q 2494 2394 2734 2622 \n",
       "Q 2975 2850 2975 3272 \n",
       "Q 2975 3691 2734 3919 \n",
       "Q 2494 4147 2053 4147 \n",
       "L 1259 4147 \n",
       "z\n",
       "M 628 4666 \n",
       "L 2053 4666 \n",
       "Q 2838 4666 3239 4311 \n",
       "Q 3641 3956 3641 3272 \n",
       "Q 3641 2581 3239 2228 \n",
       "Q 2838 1875 2053 1875 \n",
       "L 1259 1875 \n",
       "L 1259 0 \n",
       "L 628 0 \n",
       "L 628 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-4d\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-4c\" x=\"86.279297\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-50\" x=\"141.992188\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_18\">\n",
       "     <path d=\"M 530.913125 70.851562 \n",
       "L 540.913125 70.851562 \n",
       "L 550.913125 70.851562 \n",
       "\" style=\"fill: none; stroke: #ff0000; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_17\">\n",
       "     <!-- CNN -->\n",
       "     <g transform=\"translate(558.913125 74.351562) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-4e\" d=\"M 628 4666 \n",
       "L 1478 4666 \n",
       "L 3547 763 \n",
       "L 3547 4666 \n",
       "L 4159 4666 \n",
       "L 4159 0 \n",
       "L 3309 0 \n",
       "L 1241 3903 \n",
       "L 1241 0 \n",
       "L 628 0 \n",
       "L 628 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-43\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-4e\" x=\"69.824219\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-4e\" x=\"144.628906\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_19\">\n",
       "     <path d=\"M 530.913125 85.529687 \n",
       "L 540.913125 85.529687 \n",
       "L 550.913125 85.529687 \n",
       "\" style=\"fill: none; stroke: #800080; stroke-width: 2; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_18\">\n",
       "     <!-- Proposed -->\n",
       "     <g transform=\"translate(558.913125 89.029687) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \n",
       "L 1159 -1331 \n",
       "L 581 -1331 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "z\n",
       "M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \n",
       "L 2906 4863 \n",
       "L 3481 4863 \n",
       "L 3481 0 \n",
       "L 2906 0 \n",
       "L 2906 525 \n",
       "Q 2725 213 2448 61 \n",
       "Q 2172 -91 1784 -91 \n",
       "Q 1150 -91 751 415 \n",
       "Q 353 922 353 1747 \n",
       "Q 353 2572 751 3078 \n",
       "Q 1150 3584 1784 3584 \n",
       "Q 2172 3584 2448 3432 \n",
       "Q 2725 3281 2906 2969 \n",
       "z\n",
       "M 947 1747 \n",
       "Q 947 1113 1208 752 \n",
       "Q 1469 391 1925 391 \n",
       "Q 2381 391 2643 752 \n",
       "Q 2906 1113 2906 1747 \n",
       "Q 2906 2381 2643 2742 \n",
       "Q 2381 3103 1925 3103 \n",
       "Q 1469 3103 1208 2742 \n",
       "Q 947 2381 947 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"58.552734\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"97.416016\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-70\" x=\"158.597656\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"222.074219\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"283.255859\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"335.355469\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-64\" x=\"396.878906\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_2\">\n",
       "   <g id=\"patch_8\">\n",
       "    <path d=\"M 109.950625 322.156875 \n",
       "L 253.950625 322.156875 \n",
       "L 253.950625 235.756875 \n",
       "L 109.950625 235.756875 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_3\">\n",
       "    <g id=\"xtick_8\">\n",
       "     <g id=\"line2d_20\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mf4c6b4999d\" x=\"138.750625\" y=\"322.156875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_19\">\n",
       "      <!-- 25 -->\n",
       "      <g transform=\"translate(132.388125 336.755312) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_9\">\n",
       "     <g id=\"line2d_21\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mf4c6b4999d\" x=\"174.750625\" y=\"322.156875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_20\">\n",
       "      <!-- 30 -->\n",
       "      <g transform=\"translate(168.388125 336.755312) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_10\">\n",
       "     <g id=\"line2d_22\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mf4c6b4999d\" x=\"210.750625\" y=\"322.156875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_21\">\n",
       "      <!-- 35 -->\n",
       "      <g transform=\"translate(204.388125 336.755312) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_11\">\n",
       "     <g id=\"line2d_23\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mf4c6b4999d\" x=\"246.750625\" y=\"322.156875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_22\">\n",
       "      <!-- 40 -->\n",
       "      <g transform=\"translate(240.388125 336.755312) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_4\">\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_24\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m35d169254c\" x=\"109.950625\" y=\"321.563656\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_23\">\n",
       "      <!-- 0.825 -->\n",
       "      <g transform=\"translate(74.3225 325.362874) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"159.033203\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"222.65625\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_25\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m35d169254c\" x=\"109.950625\" y=\"297.612617\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_24\">\n",
       "      <!-- 0.850 -->\n",
       "      <g transform=\"translate(74.3225 301.411835) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"222.65625\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_26\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m35d169254c\" x=\"109.950625\" y=\"273.661578\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_25\">\n",
       "      <!-- 0.875 -->\n",
       "      <g transform=\"translate(74.3225 277.460797) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-37\" d=\"M 525 4666 \n",
       "L 3525 4666 \n",
       "L 3525 4397 \n",
       "L 1831 0 \n",
       "L 1172 0 \n",
       "L 2766 4134 \n",
       "L 525 4134 \n",
       "L 525 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-37\" x=\"159.033203\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"222.65625\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_8\">\n",
       "     <g id=\"line2d_27\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m35d169254c\" x=\"109.950625\" y=\"249.710539\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_26\">\n",
       "      <!-- 0.900 -->\n",
       "      <g transform=\"translate(74.3225 253.509758) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-39\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"222.65625\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_28\">\n",
       "    <path d=\"M -1 192.063309 \n",
       "L 1.950625 194.089974 \n",
       "L 9.150625 197.242182 \n",
       "L 16.350625 200.161679 \n",
       "L 23.550625 203.076405 \n",
       "L 30.750625 205.908098 \n",
       "L 37.950625 208.780333 \n",
       "L 45.150625 211.447673 \n",
       "L 52.350625 216.18555 \n",
       "L 59.550625 222.093852 \n",
       "L 66.750625 225.317202 \n",
       "L 73.950625 228.452884 \n",
       "L 81.150625 231.650526 \n",
       "L 88.350625 234.558034 \n",
       "L 95.550625 237.587783 \n",
       "L 102.750625 241.568178 \n",
       "L 109.950625 245.337291 \n",
       "L 117.150625 249.556048 \n",
       "L 124.350625 252.693268 \n",
       "L 131.550625 256.443603 \n",
       "L 138.750625 260.971643 \n",
       "L 145.950625 263.717041 \n",
       "L 153.150625 267.233421 \n",
       "L 160.350625 271.227927 \n",
       "L 167.550625 273.833208 \n",
       "L 174.750625 279.33213 \n",
       "L 181.950625 281.823133 \n",
       "L 189.150625 289.479966 \n",
       "L 196.350625 289.482828 \n",
       "L 203.550625 291.926605 \n",
       "L 210.750625 295.338558 \n",
       "L 217.950625 299.528881 \n",
       "L 225.150625 301.728378 \n",
       "L 232.350625 305.366862 \n",
       "L 239.550625 308.611219 \n",
       "L 246.750625 312.576459 \n",
       "L 253.950625 314.732612 \n",
       "L 261.150625 320.820725 \n",
       "L 268.350625 327.276624 \n",
       "L 275.550625 330.542557 \n",
       "L 282.750625 335.089549 \n",
       "L 289.950625 336.140458 \n",
       "L 297.150625 339.100998 \n",
       "L 304.350625 343.946721 \n",
       "L 311.550625 344.603836 \n",
       "L 318.750625 347.534606 \n",
       "L 325.950625 350.206275 \n",
       "L 333.150625 353.366698 \n",
       "L 340.350625 356.227659 \n",
       "L 347.550625 360.895714 \n",
       "L 354.750625 361.304391 \n",
       "L 361.950625 364.094761 \n",
       "L 369.150625 369.282262 \n",
       "L 376.350625 368.123667 \n",
       "L 383.550625 370.728763 \n",
       "L 390.750625 370.45062 \n",
       "\" clip-path=\"url(#pde6cea62ed)\" style=\"fill: none; stroke: #0000ff; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_29\">\n",
       "    <path d=\"M -1 215.331984 \n",
       "L 1.950625 217.377918 \n",
       "L 9.150625 220.661953 \n",
       "L 16.350625 225.832182 \n",
       "L 23.550625 225.844059 \n",
       "L 30.750625 227.105595 \n",
       "L 37.950625 226.240816 \n",
       "L 45.150625 226.797006 \n",
       "L 52.350625 230.826931 \n",
       "L 59.550625 233.597946 \n",
       "L 66.750625 239.989852 \n",
       "L 73.950625 245.039134 \n",
       "L 81.150625 247.912365 \n",
       "L 88.350625 253.16351 \n",
       "L 95.550625 253.7406 \n",
       "L 102.750625 258.723357 \n",
       "L 109.950625 261.111092 \n",
       "L 117.150625 267.341394 \n",
       "L 124.350625 268.459086 \n",
       "L 131.550625 270.69995 \n",
       "L 138.750625 277.804567 \n",
       "L 145.950625 278.693672 \n",
       "L 153.150625 281.818617 \n",
       "L 160.350625 290.229767 \n",
       "L 167.550625 289.616245 \n",
       "L 174.750625 294.121272 \n",
       "L 181.950625 296.409761 \n",
       "L 189.150625 302.75113 \n",
       "L 196.350625 306.830335 \n",
       "L 203.550625 307.077422 \n",
       "L 210.750625 310.274432 \n",
       "L 217.950625 315.236174 \n",
       "L 225.150625 315.609347 \n",
       "L 232.350625 318.991658 \n",
       "L 239.550625 320.110206 \n",
       "L 246.750625 325.808815 \n",
       "L 253.950625 326.981269 \n",
       "L 261.150625 328.682731 \n",
       "L 268.350625 334.238639 \n",
       "L 275.550625 336.021702 \n",
       "L 282.750625 345.893623 \n",
       "L 289.950625 344.360731 \n",
       "L 297.150625 345.661725 \n",
       "L 304.350625 353.649052 \n",
       "L 311.550625 351.746241 \n",
       "L 318.750625 354.412814 \n",
       "L 325.950625 357.802548 \n",
       "L 333.150625 356.499784 \n",
       "L 340.350625 361.704674 \n",
       "L 347.550625 368.25904 \n",
       "L 354.750625 365.845837 \n",
       "L 361.950625 367.188916 \n",
       "L 369.150625 372.804954 \n",
       "L 376.350625 367.427895 \n",
       "L 383.550625 364.47786 \n",
       "L 390.750625 369.416133 \n",
       "\" clip-path=\"url(#pde6cea62ed)\" style=\"fill: none; stroke: #008000; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_30\">\n",
       "    <path d=\"M -1 192.267863 \n",
       "L 1.950625 196.017926 \n",
       "L 9.150625 204.882538 \n",
       "L 16.350625 197.987377 \n",
       "L 23.550625 204.117576 \n",
       "L 30.750625 203.946665 \n",
       "L 37.950625 203.639961 \n",
       "L 45.150625 207.100903 \n",
       "L 52.350625 218.783412 \n",
       "L 59.550625 216.16315 \n",
       "L 66.750625 227.355652 \n",
       "L 73.950625 226.809341 \n",
       "L 81.150625 230.604911 \n",
       "L 88.350625 235.198678 \n",
       "L 95.550625 233.771142 \n",
       "L 102.750625 241.553523 \n",
       "L 109.950625 235.395628 \n",
       "L 117.150625 251.365199 \n",
       "L 124.350625 246.459818 \n",
       "L 131.550625 250.118282 \n",
       "L 138.750625 258.699088 \n",
       "L 145.950625 257.943263 \n",
       "L 153.150625 260.609493 \n",
       "L 160.350625 270.350019 \n",
       "L 167.550625 267.401639 \n",
       "L 174.750625 273.922599 \n",
       "L 181.950625 273.361098 \n",
       "L 189.150625 282.819645 \n",
       "L 196.350625 284.769852 \n",
       "L 203.550625 283.189677 \n",
       "L 210.750625 287.07924 \n",
       "L 217.950625 295.005923 \n",
       "L 225.150625 292.678375 \n",
       "L 232.350625 295.833356 \n",
       "L 239.550625 296.168212 \n",
       "L 246.750625 304.048755 \n",
       "L 253.950625 305.366252 \n",
       "L 261.150625 305.234628 \n",
       "L 268.350625 312.459905 \n",
       "L 275.550625 314.37682 \n",
       "L 282.750625 329.375971 \n",
       "L 289.950625 323.551391 \n",
       "L 297.150625 323.698147 \n",
       "L 304.350625 334.967168 \n",
       "L 311.550625 330.550366 \n",
       "L 318.750625 332.297112 \n",
       "L 325.950625 337.256456 \n",
       "L 333.150625 337.032438 \n",
       "L 340.350625 343.068531 \n",
       "L 347.550625 350.859078 \n",
       "L 354.750625 346.839204 \n",
       "L 361.950625 349.359648 \n",
       "L 369.150625 359.134207 \n",
       "L 376.350625 355.111136 \n",
       "L 383.550625 351.673149 \n",
       "L 390.750625 365.824366 \n",
       "\" clip-path=\"url(#pde6cea62ed)\" style=\"fill: none; stroke: #ff0000; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_31\">\n",
       "    <path d=\"M -1 195.126749 \n",
       "L 1.950625 197.018841 \n",
       "L 9.150625 200.244287 \n",
       "L 16.350625 203.343935 \n",
       "L 23.550625 206.523984 \n",
       "L 30.750625 210.782837 \n",
       "L 37.950625 213.555452 \n",
       "L 45.150625 217.011426 \n",
       "L 52.350625 222.194789 \n",
       "L 59.550625 224.648193 \n",
       "L 66.750625 229.412985 \n",
       "L 73.950625 232.936171 \n",
       "L 81.150625 235.950562 \n",
       "L 88.350625 240.424525 \n",
       "L 95.550625 242.507041 \n",
       "L 102.750625 247.020006 \n",
       "L 109.950625 249.619025 \n",
       "L 117.150625 255.077798 \n",
       "L 124.350625 257.079455 \n",
       "L 131.550625 259.903177 \n",
       "L 138.750625 265.021556 \n",
       "L 145.950625 267.09779 \n",
       "L 153.150625 270.23918 \n",
       "L 160.350625 275.874975 \n",
       "L 167.550625 277.358644 \n",
       "L 174.750625 281.356819 \n",
       "L 181.950625 284.081124 \n",
       "L 189.150625 288.967261 \n",
       "L 196.350625 292.579871 \n",
       "L 203.550625 294.503924 \n",
       "L 210.750625 297.923524 \n",
       "L 217.950625 302.64623 \n",
       "L 225.150625 304.810347 \n",
       "L 232.350625 308.690545 \n",
       "L 239.550625 311.368767 \n",
       "L 246.750625 316.667593 \n",
       "L 253.950625 319.569491 \n",
       "L 261.150625 322.637217 \n",
       "L 268.350625 327.647155 \n",
       "L 275.550625 329.371916 \n",
       "L 282.750625 333.609812 \n",
       "L 289.950625 334.246576 \n",
       "L 297.150625 335.832346 \n",
       "L 304.350625 339.503488 \n",
       "L 311.550625 340.119751 \n",
       "L 318.750625 342.151787 \n",
       "L 325.950625 344.482476 \n",
       "L 333.150625 345.43331 \n",
       "L 340.350625 348.264798 \n",
       "L 347.550625 351.535529 \n",
       "L 354.750625 352.119928 \n",
       "L 361.950625 354.127981 \n",
       "L 369.150625 358.054433 \n",
       "L 376.350625 358.319508 \n",
       "L 383.550625 359.374728 \n",
       "L 390.750625 362.459471 \n",
       "\" clip-path=\"url(#pde6cea62ed)\" style=\"fill: none; stroke: #800080; stroke-width: 2; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_9\">\n",
       "    <path d=\"M 109.950625 322.156875 \n",
       "L 109.950625 235.756875 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_10\">\n",
       "    <path d=\"M 253.950625 322.156875 \n",
       "L 253.950625 235.756875 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_11\">\n",
       "    <path d=\"M 109.950625 322.156875 \n",
       "L 253.950625 322.156875 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_12\">\n",
       "    <path d=\"M 109.950625 235.756875 \n",
       "L 253.950625 235.756875 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_27\">\n",
       "    <!-- zoomed view -->\n",
       "    <g transform=\"translate(142.39 229.756875) scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-7a\" d=\"M 353 3500 \n",
       "L 3084 3500 \n",
       "L 3084 2975 \n",
       "L 922 459 \n",
       "L 3084 459 \n",
       "L 3084 0 \n",
       "L 275 0 \n",
       "L 275 525 \n",
       "L 2438 3041 \n",
       "L 353 3041 \n",
       "L 353 3500 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \n",
       "Q 3544 3216 3844 3400 \n",
       "Q 4144 3584 4550 3584 \n",
       "Q 5097 3584 5394 3201 \n",
       "Q 5691 2819 5691 2113 \n",
       "L 5691 0 \n",
       "L 5113 0 \n",
       "L 5113 2094 \n",
       "Q 5113 2597 4934 2840 \n",
       "Q 4756 3084 4391 3084 \n",
       "Q 3944 3084 3684 2787 \n",
       "Q 3425 2491 3425 1978 \n",
       "L 3425 0 \n",
       "L 2847 0 \n",
       "L 2847 2094 \n",
       "Q 2847 2600 2669 2842 \n",
       "Q 2491 3084 2119 3084 \n",
       "Q 1678 3084 1418 2786 \n",
       "Q 1159 2488 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1356 3278 1631 3431 \n",
       "Q 1906 3584 2284 3584 \n",
       "Q 2666 3584 2933 3390 \n",
       "Q 3200 3197 3328 2828 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-76\" d=\"M 191 3500 \n",
       "L 800 3500 \n",
       "L 1894 563 \n",
       "L 2988 3500 \n",
       "L 3597 3500 \n",
       "L 2284 0 \n",
       "L 1503 0 \n",
       "L 191 3500 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-69\" d=\"M 603 3500 \n",
       "L 1178 3500 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 3500 \n",
       "z\n",
       "M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 4134 \n",
       "L 603 4134 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-77\" d=\"M 269 3500 \n",
       "L 844 3500 \n",
       "L 1563 769 \n",
       "L 2278 3500 \n",
       "L 2956 3500 \n",
       "L 3675 769 \n",
       "L 4391 3500 \n",
       "L 4966 3500 \n",
       "L 4050 0 \n",
       "L 3372 0 \n",
       "L 2619 2869 \n",
       "L 1863 0 \n",
       "L 1184 0 \n",
       "L 269 3500 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-7a\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"52.490234\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"113.671875\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6d\" x=\"174.853516\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"272.265625\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-64\" x=\"333.789062\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"397.265625\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-76\" x=\"429.052734\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" x=\"488.232422\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"516.015625\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-77\" x=\"577.539062\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pc25178599c\">\n",
       "   <rect x=\"55.950625\" y=\"28.396875\" width=\"558\" height=\"332.64\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"pde6cea62ed\">\n",
       "   <rect x=\"109.950625\" y=\"235.756875\" width=\"144\" height=\"86.4\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_curves_with_zoom( y_real, y_mlp, y_cnn ,y_proposed,zoom='zoomed view',title='CS2_35 Battery'):\n",
    "    # 创建主图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    x_real = np.arange(1, len(y_real) + 1)\n",
    "    # 绘制主图中的四条曲线\n",
    "    plt.plot(x_real, y_real, label='Real', color='blue', linewidth=1)\n",
    "    plt.plot(x_real, y_mlp, label='MLP', color='green', linewidth=1)\n",
    "    plt.plot(x_real, y_cnn, label='CNN', color='red', linewidth=1)\n",
    "    plt.plot(x_real, y_proposed, label='Proposed', color='purple', linewidth=2)\n",
    "    \n",
    "    # 设置主图标题和标签\n",
    "    plt.title(title,fontsize=20)\n",
    "    plt.xlabel('cycle',fontsize=16)\n",
    "    plt.ylabel('SOH',fontsize=16)\n",
    "    plt.legend(loc='upper right')  # 图例在右上角\n",
    "    \n",
    "    # 添加放大图\n",
    "    ax_inset = plt.axes([0.2, 0.2, 0.2, 0.2])  # 放大图的位置和大小\n",
    "    ax_inset.plot(x_real, y_real, color='blue', linewidth=1)\n",
    "    ax_inset.plot(x_real, y_mlp, color='green', linewidth=1)\n",
    "    ax_inset.plot(x_real, y_cnn, color='red', linewidth=1)\n",
    "    ax_inset.plot(x_real, y_proposed, color='purple', linewidth=2)\n",
    "    \n",
    "    # 设置放大图的显示范围（取中间一小段）\n",
    "    mid_point = len(x_real) // 2\n",
    "    zoom_range = 10  # 放大范围\n",
    "    ax_inset.set_xlim(x_real[mid_point - zoom_range], x_real[mid_point + zoom_range])\n",
    "    ax_inset.set_ylim(min(y_real[mid_point - zoom_range:mid_point + zoom_range]) - 0.01,\n",
    "                      max(y_real[mid_point - zoom_range:mid_point + zoom_range]) + 0.01)\n",
    "    \n",
    "    # 设置放大图标题\n",
    "    ax_inset.set_title(zoom)\n",
    "    \n",
    "    # 显示图像\n",
    "    plt.show()\n",
    "\n",
    "# 示例数据\n",
    "x = np.linspace(0, 10, 500)\n",
    "y_real = np.sin(x)\n",
    "y_mlp = np.sin(x) + 0.1 * np.random.normal(size=len(x))\n",
    "y_cnn = np.sin(x) + 0.05 * np.random.normal(size=len(x))\n",
    "y_proposed = np.sin(x) + 0.02 * np.random.normal(size=len(x))\n",
    "\n",
    "# 调用函数\n",
    "plot_curves_with_zoom(test_results[1][0],test_results_mlp[1][1], \n",
    "                      test_results_conv[1][1],test_results[1][1],title='Cell8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c15e0d3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T03:05:21.647857Z",
     "start_time": "2025-03-05T03:05:21.529303Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"629.530313pt\" height=\"404.4pt\" viewBox=\"0 0 629.530313 404.4\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2025-03-05T11:05:21.600415</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 404.4 \n",
       "L 629.530313 404.4 \n",
       "L 629.530313 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 64.330313 361.036875 \n",
       "L 622.330312 361.036875 \n",
       "L 622.330312 28.396875 \n",
       "L 64.330313 28.396875 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"m09fde08fff\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m09fde08fff\" x=\"81.096106\" y=\"361.036875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(77.914856 375.635312) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m09fde08fff\" x=\"167.074534\" y=\"361.036875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(160.712034 375.635312) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m09fde08fff\" x=\"253.052963\" y=\"361.036875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(246.690463 375.635312) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m09fde08fff\" x=\"339.031391\" y=\"361.036875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 30 -->\n",
       "      <g transform=\"translate(332.668891 375.635312) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \n",
       "Q 3050 2419 3304 2112 \n",
       "Q 3559 1806 3559 1356 \n",
       "Q 3559 666 3084 287 \n",
       "Q 2609 -91 1734 -91 \n",
       "Q 1441 -91 1130 -33 \n",
       "Q 819 25 488 141 \n",
       "L 488 750 \n",
       "Q 750 597 1062 519 \n",
       "Q 1375 441 1716 441 \n",
       "Q 2309 441 2620 675 \n",
       "Q 2931 909 2931 1356 \n",
       "Q 2931 1769 2642 2001 \n",
       "Q 2353 2234 1838 2234 \n",
       "L 1294 2234 \n",
       "L 1294 2753 \n",
       "L 1863 2753 \n",
       "Q 2328 2753 2575 2939 \n",
       "Q 2822 3125 2822 3475 \n",
       "Q 2822 3834 2567 4026 \n",
       "Q 2313 4219 1838 4219 \n",
       "Q 1578 4219 1281 4162 \n",
       "Q 984 4106 628 3988 \n",
       "L 628 4550 \n",
       "Q 988 4650 1302 4700 \n",
       "Q 1616 4750 1894 4750 \n",
       "Q 2613 4750 3031 4423 \n",
       "Q 3450 4097 3450 3541 \n",
       "Q 3450 3153 3228 2886 \n",
       "Q 3006 2619 2597 2516 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m09fde08fff\" x=\"425.009819\" y=\"361.036875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 40 -->\n",
       "      <g transform=\"translate(418.647319 375.635312) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m09fde08fff\" x=\"510.988248\" y=\"361.036875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 50 -->\n",
       "      <g transform=\"translate(504.625748 375.635312) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_7\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m09fde08fff\" x=\"596.966676\" y=\"361.036875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 60 -->\n",
       "      <g transform=\"translate(590.604176 375.635312) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
       "Q 1688 2584 1439 2293 \n",
       "Q 1191 2003 1191 1497 \n",
       "Q 1191 994 1439 701 \n",
       "Q 1688 409 2113 409 \n",
       "Q 2538 409 2786 701 \n",
       "Q 3034 994 3034 1497 \n",
       "Q 3034 2003 2786 2293 \n",
       "Q 2538 2584 2113 2584 \n",
       "z\n",
       "M 3366 4563 \n",
       "L 3366 3988 \n",
       "Q 3128 4100 2886 4159 \n",
       "Q 2644 4219 2406 4219 \n",
       "Q 1781 4219 1451 3797 \n",
       "Q 1122 3375 1075 2522 \n",
       "Q 1259 2794 1537 2939 \n",
       "Q 1816 3084 2150 3084 \n",
       "Q 2853 3084 3261 2657 \n",
       "Q 3669 2231 3669 1497 \n",
       "Q 3669 778 3244 343 \n",
       "Q 2819 -91 2113 -91 \n",
       "Q 1303 -91 875 529 \n",
       "Q 447 1150 447 2328 \n",
       "Q 447 3434 972 4092 \n",
       "Q 1497 4750 2381 4750 \n",
       "Q 2619 4750 2861 4703 \n",
       "Q 3103 4656 3366 4563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-36\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_8\">\n",
       "     <!-- cycle -->\n",
       "     <g transform=\"translate(322.652812 393.8725) scale(0.16 -0.16)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
       "L 3122 2828 \n",
       "Q 2878 2963 2633 3030 \n",
       "Q 2388 3097 2138 3097 \n",
       "Q 1578 3097 1268 2742 \n",
       "Q 959 2388 959 1747 \n",
       "Q 959 1106 1268 751 \n",
       "Q 1578 397 2138 397 \n",
       "Q 2388 397 2633 464 \n",
       "Q 2878 531 3122 666 \n",
       "L 3122 134 \n",
       "Q 2881 22 2623 -34 \n",
       "Q 2366 -91 2075 -91 \n",
       "Q 1284 -91 818 406 \n",
       "Q 353 903 353 1747 \n",
       "Q 353 2603 823 3093 \n",
       "Q 1294 3584 2113 3584 \n",
       "Q 2378 3584 2631 3529 \n",
       "Q 2884 3475 3122 3366 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-79\" d=\"M 2059 -325 \n",
       "Q 1816 -950 1584 -1140 \n",
       "Q 1353 -1331 966 -1331 \n",
       "L 506 -1331 \n",
       "L 506 -850 \n",
       "L 844 -850 \n",
       "Q 1081 -850 1212 -737 \n",
       "Q 1344 -625 1503 -206 \n",
       "L 1606 56 \n",
       "L 191 3500 \n",
       "L 800 3500 \n",
       "L 1894 763 \n",
       "L 2988 3500 \n",
       "L 3597 3500 \n",
       "L 2059 -325 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-63\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-79\" x=\"54.980469\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"114.160156\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" x=\"169.140625\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"196.923828\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <defs>\n",
       "       <path id=\"m6e6c9aadf0\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m6e6c9aadf0\" x=\"64.330313\" y=\"313.656529\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- −0.02 -->\n",
       "      <g transform=\"translate(26.685 317.455748) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \n",
       "L 4684 2272 \n",
       "L 4684 1741 \n",
       "L 678 1741 \n",
       "L 678 2272 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
       "L 1344 794 \n",
       "L 1344 0 \n",
       "L 684 0 \n",
       "L 684 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"179.199219\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"242.822266\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m6e6c9aadf0\" x=\"64.330313\" y=\"242.400017\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- −0.01 -->\n",
       "      <g transform=\"translate(26.685 246.199236) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"179.199219\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-31\" x=\"242.822266\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m6e6c9aadf0\" x=\"64.330313\" y=\"171.143505\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0.00 -->\n",
       "      <g transform=\"translate(35.064688 174.942724) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m6e6c9aadf0\" x=\"64.330313\" y=\"99.886993\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 0.01 -->\n",
       "      <g transform=\"translate(35.064688 103.686212) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-31\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m6e6c9aadf0\" x=\"64.330313\" y=\"28.630481\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 0.02 -->\n",
       "      <g transform=\"translate(35.064688 32.4297) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_14\">\n",
       "     <!-- SOH error -->\n",
       "     <g transform=\"translate(19.3575 234.015625) rotate(-90) scale(0.16 -0.16)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-53\" d=\"M 3425 4513 \n",
       "L 3425 3897 \n",
       "Q 3066 4069 2747 4153 \n",
       "Q 2428 4238 2131 4238 \n",
       "Q 1616 4238 1336 4038 \n",
       "Q 1056 3838 1056 3469 \n",
       "Q 1056 3159 1242 3001 \n",
       "Q 1428 2844 1947 2747 \n",
       "L 2328 2669 \n",
       "Q 3034 2534 3370 2195 \n",
       "Q 3706 1856 3706 1288 \n",
       "Q 3706 609 3251 259 \n",
       "Q 2797 -91 1919 -91 \n",
       "Q 1588 -91 1214 -16 \n",
       "Q 841 59 441 206 \n",
       "L 441 856 \n",
       "Q 825 641 1194 531 \n",
       "Q 1563 422 1919 422 \n",
       "Q 2459 422 2753 634 \n",
       "Q 3047 847 3047 1241 \n",
       "Q 3047 1584 2836 1778 \n",
       "Q 2625 1972 2144 2069 \n",
       "L 1759 2144 \n",
       "Q 1053 2284 737 2584 \n",
       "Q 422 2884 422 3419 \n",
       "Q 422 4038 858 4394 \n",
       "Q 1294 4750 2059 4750 \n",
       "Q 2388 4750 2728 4690 \n",
       "Q 3069 4631 3425 4513 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-4f\" d=\"M 2522 4238 \n",
       "Q 1834 4238 1429 3725 \n",
       "Q 1025 3213 1025 2328 \n",
       "Q 1025 1447 1429 934 \n",
       "Q 1834 422 2522 422 \n",
       "Q 3209 422 3611 934 \n",
       "Q 4013 1447 4013 2328 \n",
       "Q 4013 3213 3611 3725 \n",
       "Q 3209 4238 2522 4238 \n",
       "z\n",
       "M 2522 4750 \n",
       "Q 3503 4750 4090 4092 \n",
       "Q 4678 3434 4678 2328 \n",
       "Q 4678 1225 4090 567 \n",
       "Q 3503 -91 2522 -91 \n",
       "Q 1538 -91 948 565 \n",
       "Q 359 1222 359 2328 \n",
       "Q 359 3434 948 4092 \n",
       "Q 1538 4750 2522 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-48\" d=\"M 628 4666 \n",
       "L 1259 4666 \n",
       "L 1259 2753 \n",
       "L 3553 2753 \n",
       "L 3553 4666 \n",
       "L 4184 4666 \n",
       "L 4184 0 \n",
       "L 3553 0 \n",
       "L 3553 2222 \n",
       "L 1259 2222 \n",
       "L 1259 0 \n",
       "L 628 0 \n",
       "L 628 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-53\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-4f\" x=\"63.476562\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-48\" x=\"142.1875\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" x=\"217.382812\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"249.169922\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"310.693359\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"350.056641\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"388.919922\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"450.101562\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_13\">\n",
       "    <path d=\"M 89.693949 263.503865 \n",
       "L 98.291792 230.331493 \n",
       "L 106.889635 251.549474 \n",
       "L 115.487477 315.375505 \n",
       "L 124.08532 335.747275 \n",
       "L 132.683163 344.292599 \n",
       "L 141.281006 332.977429 \n",
       "L 149.878849 345.916875 \n",
       "L 158.476692 339.820625 \n",
       "L 167.074534 309.133391 \n",
       "L 175.672377 289.617063 \n",
       "L 184.27022 274.5027 \n",
       "L 192.868063 254.130381 \n",
       "L 201.465906 247.331519 \n",
       "L 210.063749 250.336948 \n",
       "L 218.661591 257.825329 \n",
       "L 227.259434 261.394429 \n",
       "L 235.857277 256.50578 \n",
       "L 244.45512 242.244787 \n",
       "L 253.052963 236.346615 \n",
       "L 261.650806 253.958541 \n",
       "L 270.248648 242.61521 \n",
       "L 278.846491 260.761182 \n",
       "L 287.444334 250.179854 \n",
       "L 296.042177 249.501092 \n",
       "L 304.64002 274.143424 \n",
       "L 313.237863 252.935618 \n",
       "L 321.835705 244.851783 \n",
       "L 330.433548 269.471868 \n",
       "L 339.031391 243.365022 \n",
       "L 347.629234 232.548159 \n",
       "L 356.227077 242.723504 \n",
       "L 364.82492 254.954388 \n",
       "L 373.422762 242.520515 \n",
       "L 382.020605 235.789937 \n",
       "L 390.618448 247.24834 \n",
       "L 399.216291 242.015116 \n",
       "L 407.814134 249.313788 \n",
       "L 416.411977 227.204004 \n",
       "L 425.009819 250.515942 \n",
       "L 433.607662 235.873508 \n",
       "L 442.205505 237.662647 \n",
       "L 450.803348 212.295489 \n",
       "L 459.401191 199.20158 \n",
       "L 467.999034 236.345517 \n",
       "L 476.596876 212.686331 \n",
       "L 485.194719 215.757264 \n",
       "L 493.792562 233.176021 \n",
       "L 502.390405 209.782923 \n",
       "L 510.988248 204.694957 \n",
       "L 519.586091 211.116799 \n",
       "L 528.183933 208.81682 \n",
       "L 536.781776 213.757059 \n",
       "L 545.379619 233.13474 \n",
       "L 553.977462 216.616032 \n",
       "L 562.575305 193.22287 \n",
       "L 571.173148 193.804305 \n",
       "L 579.77099 160.407043 \n",
       "L 588.368833 130.542346 \n",
       "L 596.966676 150.375185 \n",
       "\" clip-path=\"url(#p92a30026e7)\" style=\"fill: none; stroke: #008000; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_14\">\n",
       "    <path d=\"M 89.693949 128.847908 \n",
       "L 98.291792 163.650578 \n",
       "L 106.889635 118.082738 \n",
       "L 115.487477 124.371692 \n",
       "L 124.08532 123.267399 \n",
       "L 132.683163 154.683148 \n",
       "L 141.281006 181.237033 \n",
       "L 149.878849 125.600455 \n",
       "L 158.476692 134.942421 \n",
       "L 167.074534 138.017181 \n",
       "L 175.672377 105.743482 \n",
       "L 184.27022 108.151021 \n",
       "L 192.868063 143.828403 \n",
       "L 201.465906 134.049691 \n",
       "L 210.063749 158.622074 \n",
       "L 218.661591 147.719997 \n",
       "L 227.259434 117.202615 \n",
       "L 235.857277 95.534477 \n",
       "L 244.45512 73.36856 \n",
       "L 253.052963 73.607195 \n",
       "L 261.650806 123.434703 \n",
       "L 270.248648 111.376565 \n",
       "L 278.846491 143.27928 \n",
       "L 287.444334 110.167304 \n",
       "L 296.042177 96.138258 \n",
       "L 304.64002 136.697043 \n",
       "L 313.237863 88.351207 \n",
       "L 321.835705 93.385758 \n",
       "L 330.433548 129.638125 \n",
       "L 339.031391 113.381855 \n",
       "L 347.629234 83.503048 \n",
       "L 356.227077 100.275598 \n",
       "L 364.82492 115.255708 \n",
       "L 373.422762 78.757091 \n",
       "L 382.020605 103.76768 \n",
       "L 390.618448 115.568833 \n",
       "L 399.216291 91.793525 \n",
       "L 407.814134 96.777463 \n",
       "L 416.411977 43.516875 \n",
       "L 425.009819 111.927909 \n",
       "L 433.607662 74.786257 \n",
       "L 442.205505 110.411716 \n",
       "L 450.803348 82.689051 \n",
       "L 459.401191 55.885118 \n",
       "L 467.999034 115.09803 \n",
       "L 476.596876 77.207263 \n",
       "L 485.194719 58.373588 \n",
       "L 493.792562 98.629217 \n",
       "L 502.390405 58.94506 \n",
       "L 510.988248 62.284852 \n",
       "L 519.586091 67.135647 \n",
       "L 528.183933 65.948015 \n",
       "L 536.781776 75.281577 \n",
       "L 545.379619 102.628315 \n",
       "L 553.977462 95.50743 \n",
       "L 562.575305 60.946204 \n",
       "L 571.173148 98.877259 \n",
       "L 579.77099 80.901225 \n",
       "L 588.368833 44.466505 \n",
       "L 596.966676 99.130363 \n",
       "\" clip-path=\"url(#p92a30026e7)\" style=\"fill: none; stroke: #ff0000; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_15\">\n",
       "    <path d=\"M 89.693949 230.618497 \n",
       "L 98.291792 228.831375 \n",
       "L 106.889635 199.013922 \n",
       "L 115.487477 195.58269 \n",
       "L 124.08532 192.238839 \n",
       "L 132.683163 204.00313 \n",
       "L 141.281006 192.946616 \n",
       "L 149.878849 191.222113 \n",
       "L 158.476692 198.000458 \n",
       "L 167.074534 197.910616 \n",
       "L 175.672377 200.699833 \n",
       "L 184.27022 204.491966 \n",
       "L 192.868063 205.730347 \n",
       "L 201.465906 188.071345 \n",
       "L 210.063749 170.60178 \n",
       "L 218.661591 168.827826 \n",
       "L 227.259434 165.355886 \n",
       "L 235.857277 161.991139 \n",
       "L 244.45512 153.804944 \n",
       "L 253.052963 151.820159 \n",
       "L 261.650806 163.928115 \n",
       "L 270.248648 158.038212 \n",
       "L 278.846491 165.825218 \n",
       "L 287.444334 160.362213 \n",
       "L 296.042177 157.895796 \n",
       "L 304.64002 165.418862 \n",
       "L 313.237863 156.951015 \n",
       "L 321.835705 153.72515 \n",
       "L 330.433548 162.316229 \n",
       "L 339.031391 130.838775 \n",
       "L 347.629234 130.328214 \n",
       "L 356.227077 129.408123 \n",
       "L 364.82492 143.005763 \n",
       "L 373.422762 141.437126 \n",
       "L 382.020605 141.879676 \n",
       "L 390.618448 150.514102 \n",
       "L 399.216291 155.272037 \n",
       "L 407.814134 162.388079 \n",
       "L 416.411977 154.728183 \n",
       "L 425.009819 172.438464 \n",
       "L 433.607662 171.052025 \n",
       "L 442.205505 172.234662 \n",
       "L 450.803348 142.584608 \n",
       "L 459.401191 132.074282 \n",
       "L 467.999034 137.314809 \n",
       "L 476.596876 132.583355 \n",
       "L 485.194719 127.024787 \n",
       "L 493.792562 121.752777 \n",
       "L 502.390405 120.742948 \n",
       "L 510.988248 116.198626 \n",
       "L 519.586091 113.278709 \n",
       "L 528.183933 106.57394 \n",
       "L 536.781776 103.727752 \n",
       "L 545.379619 99.208454 \n",
       "L 553.977462 99.637001 \n",
       "L 562.575305 91.419152 \n",
       "L 571.173148 89.963621 \n",
       "L 579.77099 92.458333 \n",
       "L 588.368833 86.074811 \n",
       "L 596.966676 109.574699 \n",
       "\" clip-path=\"url(#p92a30026e7)\" style=\"fill: none; stroke: #800080; stroke-width: 2; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_16\">\n",
       "    <path d=\"M 89.693949 171.143505 \n",
       "L 98.291792 171.143505 \n",
       "L 106.889635 171.143505 \n",
       "L 115.487477 171.143505 \n",
       "L 124.08532 171.143505 \n",
       "L 132.683163 171.143505 \n",
       "L 141.281006 171.143505 \n",
       "L 149.878849 171.143505 \n",
       "L 158.476692 171.143505 \n",
       "L 167.074534 171.143505 \n",
       "L 175.672377 171.143505 \n",
       "L 184.27022 171.143505 \n",
       "L 192.868063 171.143505 \n",
       "L 201.465906 171.143505 \n",
       "L 210.063749 171.143505 \n",
       "L 218.661591 171.143505 \n",
       "L 227.259434 171.143505 \n",
       "L 235.857277 171.143505 \n",
       "L 244.45512 171.143505 \n",
       "L 253.052963 171.143505 \n",
       "L 261.650806 171.143505 \n",
       "L 270.248648 171.143505 \n",
       "L 278.846491 171.143505 \n",
       "L 287.444334 171.143505 \n",
       "L 296.042177 171.143505 \n",
       "L 304.64002 171.143505 \n",
       "L 313.237863 171.143505 \n",
       "L 321.835705 171.143505 \n",
       "L 330.433548 171.143505 \n",
       "L 339.031391 171.143505 \n",
       "L 347.629234 171.143505 \n",
       "L 356.227077 171.143505 \n",
       "L 364.82492 171.143505 \n",
       "L 373.422762 171.143505 \n",
       "L 382.020605 171.143505 \n",
       "L 390.618448 171.143505 \n",
       "L 399.216291 171.143505 \n",
       "L 407.814134 171.143505 \n",
       "L 416.411977 171.143505 \n",
       "L 425.009819 171.143505 \n",
       "L 433.607662 171.143505 \n",
       "L 442.205505 171.143505 \n",
       "L 450.803348 171.143505 \n",
       "L 459.401191 171.143505 \n",
       "L 467.999034 171.143505 \n",
       "L 476.596876 171.143505 \n",
       "L 485.194719 171.143505 \n",
       "L 493.792562 171.143505 \n",
       "L 502.390405 171.143505 \n",
       "L 510.988248 171.143505 \n",
       "L 519.586091 171.143505 \n",
       "L 528.183933 171.143505 \n",
       "L 536.781776 171.143505 \n",
       "L 545.379619 171.143505 \n",
       "L 553.977462 171.143505 \n",
       "L 562.575305 171.143505 \n",
       "L 571.173148 171.143505 \n",
       "L 579.77099 171.143505 \n",
       "L 588.368833 171.143505 \n",
       "L 596.966676 171.143505 \n",
       "\" clip-path=\"url(#p92a30026e7)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #000000; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 64.330313 361.036875 \n",
       "L 64.330313 28.396875 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 622.330312 361.036875 \n",
       "L 622.330312 28.396875 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 64.330313 361.036875 \n",
       "L 622.330312 361.036875 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 64.330313 28.396875 \n",
       "L 622.330312 28.396875 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_15\">\n",
       "    <!-- Cell7 -->\n",
       "    <g transform=\"translate(318.275625 22.396875) scale(0.2 -0.2)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-43\" d=\"M 4122 4306 \n",
       "L 4122 3641 \n",
       "Q 3803 3938 3442 4084 \n",
       "Q 3081 4231 2675 4231 \n",
       "Q 1875 4231 1450 3742 \n",
       "Q 1025 3253 1025 2328 \n",
       "Q 1025 1406 1450 917 \n",
       "Q 1875 428 2675 428 \n",
       "Q 3081 428 3442 575 \n",
       "Q 3803 722 4122 1019 \n",
       "L 4122 359 \n",
       "Q 3791 134 3420 21 \n",
       "Q 3050 -91 2638 -91 \n",
       "Q 1578 -91 968 557 \n",
       "Q 359 1206 359 2328 \n",
       "Q 359 3453 968 4101 \n",
       "Q 1578 4750 2638 4750 \n",
       "Q 3056 4750 3426 4639 \n",
       "Q 3797 4528 4122 4306 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-37\" d=\"M 525 4666 \n",
       "L 3525 4666 \n",
       "L 3525 4397 \n",
       "L 1831 0 \n",
       "L 1172 0 \n",
       "L 2766 4134 \n",
       "L 525 4134 \n",
       "L 525 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-43\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"69.824219\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"131.347656\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"159.130859\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-37\" x=\"186.914062\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 537.292812 80.43125 \n",
       "L 615.330312 80.43125 \n",
       "Q 617.330312 80.43125 617.330312 78.43125 \n",
       "L 617.330312 35.396875 \n",
       "Q 617.330312 33.396875 615.330312 33.396875 \n",
       "L 537.292812 33.396875 \n",
       "Q 535.292812 33.396875 535.292812 35.396875 \n",
       "L 535.292812 78.43125 \n",
       "Q 535.292812 80.43125 537.292812 80.43125 \n",
       "z\n",
       "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_17\">\n",
       "     <path d=\"M 539.292812 41.495312 \n",
       "L 549.292812 41.495312 \n",
       "L 559.292812 41.495312 \n",
       "\" style=\"fill: none; stroke: #008000; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_16\">\n",
       "     <!-- MLP -->\n",
       "     <g transform=\"translate(567.292812 44.995312) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-4d\" d=\"M 628 4666 \n",
       "L 1569 4666 \n",
       "L 2759 1491 \n",
       "L 3956 4666 \n",
       "L 4897 4666 \n",
       "L 4897 0 \n",
       "L 4281 0 \n",
       "L 4281 4097 \n",
       "L 3078 897 \n",
       "L 2444 897 \n",
       "L 1241 4097 \n",
       "L 1241 0 \n",
       "L 628 0 \n",
       "L 628 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-4c\" d=\"M 628 4666 \n",
       "L 1259 4666 \n",
       "L 1259 531 \n",
       "L 3531 531 \n",
       "L 3531 0 \n",
       "L 628 0 \n",
       "L 628 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-50\" d=\"M 1259 4147 \n",
       "L 1259 2394 \n",
       "L 2053 2394 \n",
       "Q 2494 2394 2734 2622 \n",
       "Q 2975 2850 2975 3272 \n",
       "Q 2975 3691 2734 3919 \n",
       "Q 2494 4147 2053 4147 \n",
       "L 1259 4147 \n",
       "z\n",
       "M 628 4666 \n",
       "L 2053 4666 \n",
       "Q 2838 4666 3239 4311 \n",
       "Q 3641 3956 3641 3272 \n",
       "Q 3641 2581 3239 2228 \n",
       "Q 2838 1875 2053 1875 \n",
       "L 1259 1875 \n",
       "L 1259 0 \n",
       "L 628 0 \n",
       "L 628 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-4d\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-4c\" x=\"86.279297\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-50\" x=\"141.992188\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_18\">\n",
       "     <path d=\"M 539.292812 56.173437 \n",
       "L 549.292812 56.173437 \n",
       "L 559.292812 56.173437 \n",
       "\" style=\"fill: none; stroke: #ff0000; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_17\">\n",
       "     <!-- CNN -->\n",
       "     <g transform=\"translate(567.292812 59.673437) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-4e\" d=\"M 628 4666 \n",
       "L 1478 4666 \n",
       "L 3547 763 \n",
       "L 3547 4666 \n",
       "L 4159 4666 \n",
       "L 4159 0 \n",
       "L 3309 0 \n",
       "L 1241 3903 \n",
       "L 1241 0 \n",
       "L 628 0 \n",
       "L 628 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-43\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-4e\" x=\"69.824219\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-4e\" x=\"144.628906\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_19\">\n",
       "     <path d=\"M 539.292812 70.851562 \n",
       "L 549.292812 70.851562 \n",
       "L 559.292812 70.851562 \n",
       "\" style=\"fill: none; stroke: #800080; stroke-width: 2; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_18\">\n",
       "     <!-- Proposed -->\n",
       "     <g transform=\"translate(567.292812 74.351562) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \n",
       "L 1159 -1331 \n",
       "L 581 -1331 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "z\n",
       "M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \n",
       "L 2906 4863 \n",
       "L 3481 4863 \n",
       "L 3481 0 \n",
       "L 2906 0 \n",
       "L 2906 525 \n",
       "Q 2725 213 2448 61 \n",
       "Q 2172 -91 1784 -91 \n",
       "Q 1150 -91 751 415 \n",
       "Q 353 922 353 1747 \n",
       "Q 353 2572 751 3078 \n",
       "Q 1150 3584 1784 3584 \n",
       "Q 2172 3584 2448 3432 \n",
       "Q 2725 3281 2906 2969 \n",
       "z\n",
       "M 947 1747 \n",
       "Q 947 1113 1208 752 \n",
       "Q 1469 391 1925 391 \n",
       "Q 2381 391 2643 752 \n",
       "Q 2906 1113 2906 1747 \n",
       "Q 2906 2381 2643 2742 \n",
       "Q 2381 3103 1925 3103 \n",
       "Q 1469 3103 1208 2742 \n",
       "Q 947 2381 947 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"58.552734\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"97.416016\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-70\" x=\"158.597656\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"222.074219\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"283.255859\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"335.355469\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-64\" x=\"396.878906\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p92a30026e7\">\n",
       "   <rect x=\"64.330313\" y=\"28.396875\" width=\"558\" height=\"332.64\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def subtract_lists(list1, list2):\n",
    "    if len(list1) != len(list2):\n",
    "        raise ValueError(\"两个列表的长度必须相同！\")\n",
    "    return [x - y for x, y in zip(list1, list2)]\n",
    "def plot_difference_curves(y_real, y_mlp, y_cnn, y_proposed,title='C2S'):\n",
    "    # 生成 x 值（从 1 开始递增）\n",
    "    # 创建主图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    x_real = np.arange(1, len(y_real) + 1)\n",
    "    # 绘制主图中的四条曲线\n",
    "    plt.plot(x_real, y_mlp-y_real, label='MLP', color='green', linewidth=1)\n",
    "    plt.plot(x_real, y_cnn-y_real, label='CNN', color='red', linewidth=1)\n",
    "    \n",
    "    plt.plot(x_real, y_proposed-y_real, label='Proposed', color='purple', linewidth=2)\n",
    "    plt.plot(x_real,0*y_mlp,color='black',linestyle='--')\n",
    "    # 设置主图标题和标签\n",
    "    plt.title(title,fontsize=20)\n",
    "    plt.xlabel('cycle',fontsize=16)\n",
    "    plt.ylabel('SOH error',fontsize=16)\n",
    "    plt.legend(loc='upper right')  # 图例在右上角\n",
    "    plt.show()\n",
    "plot_difference_curves(test_results[0][0],test_results_mlp[0][1].reshape(-1), \n",
    "                       test_results_conv[0][1].reshape(-1),\n",
    "                       test_results[0][1].reshape(-1),title='Cell7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e512be99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
